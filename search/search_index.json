{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Start","text":"<ul> <li>Course name in Hungarian: Auton\u00f3m j\u00e1rm\u0171vek \u00e9s robotok programoz\u00e1sa</li> <li>Course name in English: Autonomous robots and vehicles software engineering</li> <li>Neptun course code: <code>GKNB_AUTM078</code></li> </ul> <p>The course is offered in several engineering programs and builds on minimal existing programming knowledge. It starts with the following prerequisites: Vehicle Engineering (BSc) <code>GKNB_INTM023</code> Basics of Programming, Software Engineering (BSc) <code>GKNB_MSTM032</code> Python Programming, Computer Engineering (BSc) <code>GKNB_INTM114</code> Programming, Mechatronics Engineering (BSc) <code>GKNB_MSTM032</code> Python Programming, Electrical Engineering (BSc) <code>GKNB_INTM023</code> Basics of Programming.</p> <p>Course Objective</p> <p>After successfully completing the course, students will have a comprehensive understanding of the software modules and other essential components of autonomous vehicles.</p> <p>They will be able to develop simpler related software modules in C++ and Python. Additionally, students will be capable of applying the appropriate code, interpreting its functions, and further developing it within the ROS 2 framework.</p> <p>The course content is based on the curricula of internationally recognized universities such as MIT, ETH Zurich, TU Munich, University of Virginia, and Stanford University. Certain parts of the curriculum were adopted or used as inspiration, adhering to the appropriate licenses, detailed here. In 2023, the course uses the ROS 2 Humble version, which is supported until May 2027.</p> <p>Completing the course can be advantageous for employment at the following automotive/autonomous vehicle companies (in alphabetical order):</p> <ul> <li>AiMotive Kft. (Budapest)</li> <li>AVL Hungary Kft. (Budapest, \u00c9rd, Kecskem\u00e9t)</li> <li>Bosch: Robert Bosch Kft. (Budapest, Gy\u0151r, Zalaegerszeg)</li> <li>Continental Autonomous Mobility Hungary Kft. (Budapest, Gy\u0151r, Debrecen)</li> <li>Vehicle Industry Research Center, SZE (Gy\u0151r)</li> </ul> <p>Further career-related insights can be found on statista, glassdoor, and linkedin.</p> <p>Note</p> <p>Based on the knowledge presented in the course, students can prepare theses, dissertations, project work, and TDK papers, and there is also an opportunity to complete the mandatory internship.</p> <p> Instructors . Dr. Ern\u0151 Horv\u00e1th  Course Leader github.com/horverno Dr. \u00c1ron Ballagi  Curriculum, not teaching github.com/aronball Rudolf Krecht  Simulation, Robotics github.com/rudolfkrecht Mikl\u00f3s Unger  Environmental Sensing github.com/umiklos Gerg\u0151 Ign\u00e9czi  Control Engineering github.com/gfigneczi1 Norbert Mark\u00f3  AI, Neural Networks github.com/norbertmarko <p></p> <p>In the fall semester of 2023/24, classes will be held in room <code>A2</code> and the computer lab <code>B6</code>.</p>"},{"location":"#theory","title":"Theory","text":"Class Date Material 1 Sep. 6 Introduction: Course structure. Knowledge of robotics and autonomous vehicles. Sensing, perception, planning, control, actuation. 2 Sep. 13 ROS2 Concepts: Introduction to university robots and vehicles. Basics of <code>ROS 2</code>. 3 Sep. 20 Sensing: Operation and signal processing of sensors such as cameras, LIDAR, GNSS (GPS), IMU, CAN. Main <code>ROS 2</code> topics, <code>ROS 2</code> time management. 4 Sep. 27 Midterm Assignment: Introduction to the midterm assignment, grading criteria, ideas, Q&amp;A. 5 Oct. 4 Transformations: Rigid body motion, matrix multiplication review, demonstration of homogeneous coordinates with short code snippets, concept of quaternions. 6 Oct. 11 Perception: Object recognition, object classification, object tracking and prediction, SLAM and LOAM. 7 Oct. 25 Simulation: Overview of ROS 2 compatible simulators (e.g., Gazebo, Carla, SVL, OSSDC SIM, AirSim, AWSIM, CoppeliaSim, MVSim). 8 Nov. 8 Planning: Global planning, local planning. Local planning: lateral and longitudinal planning. 9 Nov. 15 Control: Vehicle control solutions (inverse models, predictive models, closed-loop models). 10 Nov. 22 Artificial Intelligence: Neural networks with a focus on vehicles and robotics."},{"location":"#practice","title":"Practice","text":"Class Date Material 1 Sep. 6 Introduction + Linux + Computer Lab Knowledge: Using WSL2 on Windows OS. Basic computer lab knowledge. Linux commands that may be needed later. 2 Sep. 13 Installation + Setting Up Development Environment + ROS2 Communication: First <code>ROS 2</code> nodes, using ROS commands, build and source. 3 Sep. 20 Sensing Practice: Common formats of sensor data: <code>sensor_msgs/PointCloud2</code>, <code>sensor_msgs/Image</code>, <code>geometry_msgs/Pose</code>, etc. Handling and playing back bag <code>.mcap</code> files. Creating a simple package that subscribes to position data. 4 Sep. 27 Version Control, Git, Copilot, VS Code, ROS 2 Launch: Using Copilot for ROS 2 development, introduction to the template repo, using it, writing launch files in Python. 5 Oct. 4 Transformations Practice: Creating a node that advertises transformations. Displaying markers, independent task with launch. 6 Oct. 11 Perception Practice: Simple LIDAR filtering based on X, Y, and Z coordinates. 7 Oct. 25 Simulation Introduction: Gazebo Fortress and ROS 2, Simulation Practice: Creating your own robot simulation. 8 Nov. 8 Planning Practice: Implementing a polynomial-based local planner. Using Nav2 with a simulator. 9 Nov. 15 Control Practice: PID tuning. Trajectory following with Gazebo simulator. Custom-developed controller and vehicle model. 10 Nov. 22 Artificial Intelligence Practice: Neural networks practice."},{"location":"#grades","title":"Grades","text":"<ul> <li>Signature: Completion of a small assignment (simple home programming task)</li> <li>1 (fail): \\(0\\% \\leq ZH_{average} &lt; 60\\%\\)</li> <li>2 (pass): \\(60\\% \\leq ZH_{average} &lt; 85\\%\\)</li> <li>3 (satisfactory): \\(85\\% \\leq  ZH_{average} \\leq 100\\%\\) </li> <li>4 (good): Large midterm assignment completed with major errors according to the specified guidelines</li> <li>5 (excellent): Large midterm assignment completed with only a few minor errors according to the specified guidelines</li> </ul>"},{"location":"#conventions","title":"Conventions","text":"<ul> <li>  practical material</li> <li>  theoretical material</li> <li>  supplementary material, may be necessary for a complete understanding</li> </ul>"},{"location":"#topics-covered-not-in-the-order-of-processing","title":"Topics Covered (not in the order of processing)","text":"<ul> <li>Introduction: Introduction to autonomous vehicles: current status, past, and future. Sensors, actuators, communication technologies. (LIDAR, radar, active and passive cameras, GPS, odometry, IMU, CAN) Foxglove studio and own measurements for illustration.</li> <li>Software System: Software for autonomous vehicles: sensing, perception, planning, tracking. Simulation technologies, user interfaces. Frameworks: ROS/ROS2/MATLAB/LabVIEW roles, real-time systems (FPGA, real-time operating systems).</li> <li>Sensing: SLAM, object detection, object tracking and prediction. Curb detection, lane detection, road defect detection, vehicle and pedestrian detection/tracking, etc. Advantages and disadvantages of artificial intelligence (especially neural networks) and traditional (e.g., C++ based) algorithms, their fusion.</li> <li>Technological Knowledge: Linux, Git: Linux knowledge: Terminal handling, Git handling, VS code, ROS installation.</li> <li>Technological Knowledge: ROS 2 Basics: topics and messages, MCAP (Rosbag) playback, handling topics, accessing topic content from Python, rviz, rqt_plot, creating MCAP (Rosbag).  ROS 2 ecosystem and development: Creating ROS 2 nodes in Python and C++: ROS 2 nodes, rqt_graph, Publisher / Subscriber node in Python, Publisher / Subscriber node in C++.  First consultation on the individual project task.</li> <li>ROS 2 Programming: Processing ROS sensor data with a C++ node: Writing ROS nodes, <code>visualization_msgs</code>, LIDAR sensor data: <code>sensor_msgs/PointCloud2</code>, <code>sensor_msgs/LaserScan</code>, etc.</li> <li>Simulation and Control: Simulation: Using ROS nodes for simulation (gazebo) F1/10, rviz, finalizing individual project tasks. Planning block: types of trajectory planners, kinematic challenges, Control block: vehicle modeling, introduction to controllers, vehicle and actuator-level control, implementing motion (braking systems, steering systems, etc.).</li> <li>Outlook, Doctoral Research, University Student Teams: Nissan Leaf, Lexus, and Szenergy autonomous projects, introduction with selected code snippets. Sensing: point cloud handling or object detection based on camera. Perception / Planning: route determination, free space determination, trajectory planning. Control: closed-loop modeled vehicle, building a controller (e.g., PID or pure pursuit).</li> <li>Artificial Intelligence: Software for autonomous vehicles, summary, outlook on neural networks (artificial intelligence, AI).</li> <li>Technological Knowledge: Using ROS 2, its innovations compared to ROS.</li> <li>Project Work: Presentation of individual project tasks.</li> </ul> <p> sze-info.github.io/avr <p></p> <p></p>"},{"location":"ai/","title":"Artificial Intelligence","text":"<p>AI can appear not only in perception but also in planning or control.</p> <p></p> <p>Although its most important autonomous application area is perception, as shown in the figure above, it also has planning and control applications.</p> <p>The Artificial Intelligence (AI) class presentation can be found here: Link</p> <p>Example videos:</p>"},{"location":"ai/practice/","title":"Artificial Intelligence Practice","text":""},{"location":"ai/practice/#downloading-practical-material","title":"Downloading Practical Material","text":"<p>To update the practical material, issue the following commands:</p> <p><pre><code>cd ~/ros2_ws/src/arj_packages\n</code></pre> <pre><code>git checkout -- .\n</code></pre> <pre><code>git pull\n</code></pre></p>"},{"location":"ai/practice/#installing-conda-environment","title":"Installing Conda Environment","text":"<p>Anaconda (miniconda) provides an isolated virtual environment where we can install the required version of Python packages for the current work.</p> <p><pre><code>mkdir -p ~/miniconda3\n</code></pre> <pre><code>wget https://repo.anaconda.com/miniconda/Miniconda3-latest-Linux-x86_64.sh -O ~/miniconda3/miniconda.sh\n</code></pre> <pre><code>bash ~/miniconda3/miniconda.sh -b -u -p ~/miniconda3\n</code></pre> <pre><code>rm -rf ~/miniconda3/miniconda.sh\n</code></pre> <pre><code>~/miniconda3/bin/conda init bash\n</code></pre></p> <p>The solver coordinates the versions among the packages required for the predefined environment (<code>environment.yml</code>). The <code>libmamba-solver</code> allows for faster coordination compared to the default solver. <pre><code>source ~/.bashrc\n</code></pre> <pre><code>conda config --set auto_activate_base false\n</code></pre> <pre><code>conda update -n base conda\n</code></pre> <pre><code>conda install -n base conda-libmamba-solver\n</code></pre> <pre><code>conda config --set solver libmamba\n</code></pre></p> <p>Once Conda is installed, we create our own virtual environment: <pre><code>cd ~/ros2_ws/src/arj_packages/arj_ai\n</code></pre> <pre><code>conda env create -f environment.yml\n</code></pre></p>"},{"location":"ai/practice/#opening-the-practice","title":"Opening the Practice","text":"<p>The material can be opened as follows: <pre><code>conda activate practice\n</code></pre> <pre><code>cd ~/ros2_ws/src/arj_packages/arj_ai \n</code></pre> <pre><code>code .\n</code></pre></p> <p></p> <p>Select the environment:</p> <p></p>"},{"location":"ai/practice/#troubleshooting","title":"Troubleshooting","text":"<p>TODO</p> <pre><code>ImportError                               Traceback (most recent call last)\nCell In[1], line 10\n    8 import matplotlib.patches as patches\n    9 import matplotlib.pyplot as plt\n---&gt; 10 import torch\n     11 import torchvision.transforms as transforms\n     12 from PIL import Image\n\nFile ~/miniconda3/envs/practice/lib/python3.8/site-packages/torch/__init__.py:189\n    187     if USE_GLOBAL_DEPS:\n    188         _load_global_deps()\n--&gt; 189     from torch._C import *\n    191 # Appease the type checker; ordinarily this binding is inserted by the\n    192 # torch._C module initialization code in C\n    193 if False:\n\nImportError: /home/he/miniconda3/envs/practice/lib/python3.8/site-packages/torch/lib/libtorch_cpu.so: undefined symbol: iJIT_IsProfilingActive\n</code></pre>"},{"location":"ai/practice/#deactivating-conda","title":"Deactivating Conda","text":"<pre><code>conda deactivate\n</code></pre>"},{"location":"assignments/","title":"Small Assignment and Large Semester Project","text":"<p>The purpose of the small assignment is for students to gain practical experience with ROS 2 and GitHub alongside the basic theoretical knowledge acquired in class. The small assignment can be completed in a relatively short time: an instructor can finish it in a few hours, and an average student can complete it in a few afternoons. Its length can be short, around 30-100 lines of code per node.</p> <p>In contrast, the large semester project takes a bit more time but allows for much more interesting tasks and time. Moreover, good and excellent grades can only be achieved this way.</p> <p>Another way to earn grades is through midterms (ZH), but only modest grades can be obtained this way.</p> <pre><code>flowchart TD\n\nK([Mandatory&lt;/br&gt;small assignment]):::light ------&gt; |unsuccessful| X0\nK --&gt; A([Signature]):::green \nA --&gt;|Midterm direction| ZH1([1st Midterm]):::light\nA --&gt; |Semester direction| N([Large Semester Project]):::light\nPZH --&gt; |unsuccessful| X1\nZH2 --&gt; |unsuccessful| PZH([Make-up Midterm]):::light\nZH1 --&gt; ZH2([2nd Midterm]):::light\nZH2 --&gt; |successful| OK1\nPZH --&gt; |successful| OK1\nN ----&gt; |successful| OK2\nX0([Signature Denied]):::red\nX1([1, Fail]):::red\nOK2([4/5 Grade]):::green\nOK1([2/3 Grade]):::green\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\nclassDef green fill:#138b7b,stroke:#152742,stroke-width:2px,color:#fff\n</code></pre>"},{"location":"assignments/#deadlines-and-semester-schedule","title":"Deadlines and Semester Schedule","text":"<p>It is important to know that the small assignment is a requirement for the signature. Missing the GitHub registration or the submission of the assignment link can result in an unsuccessful semester relatively early in the semester. These are small tasks, but their completion is strictly monitored.</p> <pre><code>flowchart LR\n\nH2([2nd session]) --- H2A([Github&lt;br&gt;registration])--- H2B([Copilot registration&lt;br&gt;initiation])\nH3([3rd session]) --- H3A([Assignment Github&lt;br&gt;link submission]) --- H3B([Copilot&lt;br&gt;registration complete])\nH5([5th session]) --- H5A([Finalization of&lt;br&gt;small assignment])\nH7([7th session]) --- H7A([1st Midterm]) --- H7B([Large Semester Project Github&lt;br&gt;link submission])\nH10([10th session]) --- H10A([2nd Midterm])\nH13([13th session]) --- H13A([Make-up Midterm])\nV2([2nd week of exam period]) --- V2A([Finalization of&lt;br&gt;large semester project])\n\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\nclassDef green fill:#138b7b,stroke:#152742,stroke-width:2px,color:#fff\n\nclass H2,H3,H5,H7,H10,H13,V2 white\nclass H2A,H2B,H3B,H7A,H7B,H10A,V2A light\nclass H3A,H5A,H13A, red</code></pre>"},{"location":"assignments/semester_project/","title":"Large Semester Project","text":"<p>The preparation of the large semester project requires more time, but it allows for much more interesting tasks to be developed over many weeks. Based on the semester project, after completing the course, a thesis, diploma work, project work, or TDK paper can be prepared, and there is also an opportunity to complete the mandatory professional practice.</p>"},{"location":"assignments/semester_project/#examples","title":"Examples","text":"<p>Example of a large semester project created by the instructors:</p> <ul> <li>github.com/horverno/simple_random_trees: The package is a simple random tree algorithm that can be used for path planning. This implementation focuses on visualization rather than a comprehensive random tree-based path planning system. The <code>/display_tree node</code> advertises a <code>/path_marker_topic</code>, which is of type <code>visualization_msgs/marker_array</code>. The functions implementing the tree data structure are placed in a separate header file. Implemented under <code>ROS 2 Humble</code>.</li> </ul> <p>The following examples were not necessarily created as semester projects but would be acceptable as such:</p> <ul> <li>github.com/jkk-research/wayp_plan_tools</li> <li>github.com/jkk-research/sim_wayp_plan_tools</li> <li>github.com/jkk-research/pointcloud_to_grid</li> <li>github.com/jkk-research/urban_road_filter</li> <li>github.com/dobaybalazs/curb_detection</li> <li>github.com/kkira07/Szakdolgozat</li> <li>github.com/szenergy/rviz_markers</li> <li>github.com/linklab-uva/f1tenth_gtc_tutorial</li> <li>github.com/Farraj007/Jkk-task</li> <li>github.com/leander-dsouza/breakout_gazebo</li> <li>github.com/fjp/ros-turtle-pong</li> </ul> <p>Note: In the course, we use the ROS 2 Humble version, but the semester project (with justification) can be accepted in other versions as well.</p>"},{"location":"assignments/semester_project/#positive-aspects-for-the-semester-task","title":"Positive Aspects for the Semester Task:","text":"<ul> <li>\ud83d\udc4d Well-documented in Hungarian and/or English, illustrated with images. Use of Markdown.</li> <li>\ud83d\udc4d Basic information in the <code>README.md</code>, (optional) documentation in the <code>/wiki</code>.</li> <li>\ud83d\udc4d Issues.</li> <li>\ud83d\udc4d Branches.</li> <li>\ud83d\udc4d Gitignore.</li> <li>\ud83d\udc4d License.</li> <li>\ud83d\udc4d Repository topics, including the course code and SZE. Based on the topics, the repository can be listed here: github.com/topics/sze.</li> <li>\ud83d\udc4d Extra points can be given if the current material is supplemented or corrected (of course, through a pull request).</li> </ul>"},{"location":"assignments/semester_project/#serious-mistakes-that-can-significantly-lower-the-grade-of-the-semester-project","title":"Serious Mistakes that can significantly lower the grade of the Semester project:","text":"<ul> <li>\ud83d\ude21 Compressed files in the GitHub repository (e.g., <code>zip</code> and even worse if <code>rar</code>). An exception can be if the goal is to handle compressed files directly, but source code, images, etc., should never be uploaded this way.</li> <li>\ud83d\ude21 Not original work, or the borrowed code is not referenced.</li> <li>\ud83d\ude21 In a team, only one student commits. (This obviously does not apply to single-person tasks).</li> <li>\ud83d\ude21 Few commits. The appropriate number of commits is important because it helps us judge how the workflow progressed, who worked on what and when.</li> <li>\ud83d\ude21 No <code>README.md</code>, missing short documentation or images.</li> <li>\ud83d\ude21 Documentation uploaded as pdf/docx instead of in the <code>/wiki</code>.</li> <li>\ud83d\ude21 File upload instead of commit.</li> <li>\ud83d\ude21 Source code screenshotted instead of using markdown syntax highlighting. (Since the code cannot be copied, searched, etc., as an image).</li> </ul>"},{"location":"assignments/semester_project/#ideas-for-topic-selection","title":"Ideas for Topic Selection","text":"<ul> <li>Inspiration can come from previous or current theses/diploma works: horverno.github.io/temaajanlatok</li> <li>It is advisable to choose a topic that you would enjoy working on for weeks/months. If, for example, visualization, algorithm practice, 3D, or artificial intelligence is attractive, then it is advisable to choose a topic accordingly.</li> <li>Previous theses, semester projects are available and can be requested here. It is important that these must not be shared further, they are available for educational purposes only.</li> <li>Numerous ROS 2 projects here: github.com/fkromer/awesome-ros2</li> </ul> <p>Tip</p> <p>It is highly recommended to obtain the GitHub Student Developer Pack, which includes Copilot among other things.</p> <p></p>"},{"location":"assignments/semester_project/#evaluation-criteria","title":"Evaluation Criteria","text":"<p>The criteria were based on the evaluation criteria of a similar course at \u00d3buda University. - Ratio of own work to used codebase (with proper references) - Work producing evaluable results - Quality of the presentation (ppt, videos, live demo, any additional tools used) - Completeness of the solution - Proper <code>ROS 2</code> communication / best practice application - Structure of the program - Quality of the implementation - Documentation of the code - Consultation - Difficulty of the chosen task</p>"},{"location":"assignments/semester_project/#recommended-method-for-creating-the-semester-project-repo-template","title":"Recommended Method for Creating the Semester Project Repo: <code>Template</code>","text":"<p>We have created a so-called template repo in both C++ and Python, which makes it easier to create the first repository containing a package:</p> <ul> <li>github.com/sze-info/ros2_cpp_template</li> <li>github.com/sze-info/ros2_py_template</li> </ul> <p>Info</p> <p>You can read about it here.</p> <p></p>"},{"location":"assignments/semester_project/#meme","title":"Meme","text":"<p>Credit: pycoders</p> <p></p> <p>Credit: knowyourmeme</p>"},{"location":"assignments/small_assignment/","title":"Small Assignment","text":"<p>The purpose of the small assignment is for students to gain practical experience with ROS 2 and GitHub alongside the basic theoretical knowledge acquired in class. The small assignment can be completed in a relatively short time: an instructor can finish it in a few hours, and an average student can complete it in a few afternoons. It is important to note that the assignment is a requirement for the signature.</p> <p>Expected qualities:</p> <ul> <li>One package, 1 or 2 nodes</li> <li>At least 1 publisher or 1 subscriber (more is allowed)</li> <li>Short documentation that includes the build process and node-topic relationships, with the level of detail as shown in the examples</li> <li>Correct naming</li> <li>Use of a template recommended method for creating the small assignment repo or your own solution, but with the level of detail as shown in the examples</li> <li>Preferably compiles without errors, but <code>build warnings</code> are often acceptable, the main point is learning</li> <li>As many commits as possible to show the workflow</li> <li>Short length: 30-100 lines of code per node + CMakeLists.txt, package.xml, README.md, launch files (longer is acceptable but not required)</li> <li>Preferably illustrated with images (see examples)</li> <li>Preferably a mermaid diagram showing the relationships between nodes and topics (see examples, description)</li> </ul> <p>Danger</p> <p>The small assignment will be acceptable if the node can be built and produces the output as specified in the task! If this is not met, the student will have one week to correct it from the time the issue is posted!</p>"},{"location":"assignments/small_assignment/#examples","title":"Examples","text":"<p>Example of a small assignment created by the instructors:</p> <ul> <li>github.com/szepilot/sze_sw1_szinusz: The package consists of two nodes. The <code>/gen_node</code> generates sine waves and random numbers, which are advertised in two <code>std_msgs/float32</code> topics. The <code>/sum_node</code> sums the generated topics and advertises them in a new <code>std_msgs/float32</code> topic. Implemented under <code>ROS 2 Humble</code>.</li> <li>github.com/horverno/hor_d20_batman_turtle: The package consists of one node, which can draw a \"Batman logo\" in the turtlesim simulator by plotting the trajectory. The advertised topic is of type <code>geometry_msgs/twist</code>. Implemented under <code>ROS 2 Humble</code>.</li> <li>The package consists of one node. This <code>/array_sorter</code> node subscribes to a <code>std_msgs/msg/float32_multi_array</code> type topic, then advertises the sorted version of the same type in ascending order. Implemented under <code>ROS 2 Humble</code>.</li> <li>The package consists of two nodes. The <code>/sensor_node</code> generates simulated sensor data: temperature and humidity, which are advertised in two separate <code>sensor_msgs/Temperature</code> and <code>sensor_msgs/RelativeHumidity</code> type topics. The <code>/monitor_node</code> monitors these data, and if the temperature exceeds a certain threshold or the humidity exceeds another, it sends an alert in a <code>std_msgs/String</code> type topic. Implemented under <code>ROS 2 Humble</code>.</li> <li>The package consists of one node. The <code>/minecraft_node</code> advertises a <code>visualization_msgs/Marker</code> type topic. By subscribing to the topic, a Minecraft character can be displayed in RViz2. Implemented under <code>ROS 2 Humble</code>.</li> <li>github.com/umiklos/ung_isl_ajr_point_and_orientation: The package consists of two nodes. One node generates a <code>geometry_msgs/Point</code> type, and the other node advertises a <code>geometry_msgs/Pose</code> type by adding orientation to it. Implemented under <code>ROS 2 Humble</code>.</li> <li>github.com/umiklos/ung_isl_ajr_data_generation_and_control: The package consists of two nodes. The <code>/sensor_data_generator</code> generates simulated data with a fictitious sensor, such as distance and speed, which are advertised in two separate <code>sensor_msgs/Range</code> and <code>geometry_msgs/Twist</code> type topics. The other node, the <code>/control_node</code>, monitors these data and makes control decisions for the robot, which are printed in the terminal. Implemented under <code>ROS 2 Humble</code>.</li> <li>The package consists of two nodes. The <code>/imu_data_publisher</code> provides accelerometer and gyroscope sensor data, which are advertised in a <code>sensor_msgs/Imu</code> type topic. The other node, the <code>/imu_data_analyzer</code>, analyzes these IMU data and generates reports on the robot's status in a <code>diagnostic_msgs/DiagnosticArray</code> type topic. Implemented under <code>ROS 2 Humble</code>.</li> </ul> <p>It is advisable, but not mandatory, to choose from <code>diagnostic_msgs</code>, <code>geometry_msgs</code>, <code>nav_msgs</code>, <code>sensor_msgs</code>, <code>shape_msgs</code>, <code>std_msgs</code>, <code>trajectory_msgs</code>, <code>visualization_msgs</code>.</p>"},{"location":"assignments/small_assignment/#recommended-method-for-creating-the-small-assignment-repo-template","title":"Recommended Method for Creating the Small Assignment Repo: <code>Template</code>","text":"<p>We have created a so-called template repo in both C++ and Python, which makes it easier to create the first repository containing a package:</p> <ul> <li>github.com/sze-info/ros2_cpp_template</li> <li>github.com/sze-info/ros2_py_template</li> </ul> <p>Tip</p> <p>You can read about it here.</p> <p></p>"},{"location":"assignments/small_assignment/#repo-name","title":"Repo Name","text":"<ul> <li>The repository name should follow this pattern: <code>VVV_NNN_optional</code>, where</li> <li><code>VVV</code> is the first 3 characters of the last name</li> <li><code>NNN</code> is the first 3 characters of the Neptun code</li> <li><code>optional</code> is an optional addition</li> <li>The above should be separated by an underscore <code>_</code> and all lowercase</li> <li>For example: Istv\u00e1n Szab\u00f3, with Neptun code F99AXW, could have a URL for a small assignment dealing with random numbers like: <code>github.com/szaboistvan/sza_f99_random</code>.</li> </ul>"},{"location":"control/","title":"Control","text":"<p>The goal of control is to execute the planned trajectory.</p> <p></p>"},{"location":"control/#1-motivation-behind-closed-loop-control-introduction","title":"1. Motivation behind closed-loop control - introduction","text":"<p>We can achieve the planned target state of a system by intervening in the system considering the target value. For example, in the case of a vehicle, the target speed can be achieved by manipulating the gas and brake pedals, indirectly changing the engine torque and braking force. As an initial example, let's consider a driver: the driver is usually aware of the maximum allowed speed and applies a tolerance range that is suitable for them. Within this range, they determine a safe and comfortable speed they want to maintain. The driver accelerates until they reach the desired speed, then slightly releases the gas pedal to maintain the speed.</p> <p>Is it correct to say that once we have reached the desired speed, we can release the pedal and have nothing more to do? Of course not. Why not? Because the vehicle will slow down due to losses, and it may even accelerate when going downhill. To maintain the speed, the driver must continuously monitor the vehicle's movement and the environment and intervene through the pedals accordingly.</p> <p>This simple example covers most of the design and control components. In terms of control, we can make the following observations: - the driver senses the current state of the vehicle (with some accuracy) - the driver knows what effect will be achieved by intervening with the gas or brake pedal, i.e., how much the car will slow down or speed up (with some accuracy) - the driver can roughly (!) determine the desired gas pedal position without any special sensing (i.e., without knowing, for example, what force is acting on the car)</p> <p>The last point is often referred to as the feedforward branch (see subsection 3), or open-loop control (if we have no information from sensing). A very rough comparison is shown in Figure 1. Imagine a situation where we have no information about how fast the vehicle is going, we can only control the pedal. The task is to accelerate from a standstill to 90 km/h and then maintain that speed. If we don't know how fast we are going, how do we know whether to press the pedal more or not? In this case, we can rely on knowing the road conditions (e.g., flat terrain, asphalt road), knowing our car (what kind of engine, what torque characteristics, etc.). Thus, we can roughly determine how long to press the gas pedal, and when we have roughly reached the speed, how much to keep our foot on the pedal to avoid slowing down or speeding up. The result will likely resemble the desired speed curve, but it will be far from accurate. We know the road and our car inaccurately, and acceleration is influenced by temperature, slope, headwind, etc. Therefore, we generally do not use this open-loop approach alone, but rather correct the predetermined pedal positions with the help of more accurate sensors, thus handling any disturbance. This latter approach is called closed-loop control, and the information obtained from sensing is called feedback.</p> <p>Note</p> <p>In Hungarian terminology, open-loop control is often referred to as control, and closed-loop control is simply called regulation. Together, they are referred to as control. In English terminology, both are called control, specifically closed-loop control and open-loop control. Feedback is called feedback, and feedforward is called feed-forward.</p> <p></p> <p>Figure 1: Motivation behind closed-loop control. Source: Autonomous Driving Software Engineering - Lecture 08: Control</p>"},{"location":"control/#2-architectural-overview-and-retrospective","title":"2. Architectural Overview and Retrospective","text":"<p>As we have seen in previous chapters, the entire vehicle control chain is modular. The main tasks are: - sensing - perception - planning - control</p> <p>This chapter focuses on control. The basics of control are covered in subsection 3. The planning provides the input for the control layer. So, let's take a look at the architecture with some additions! This is shown in Figure 2.</p> <p><pre><code>flowchart LR\n\nGP1[Global Planning\n    Inputs:\n    - Driver Profile\n    - Map\n    Output:\n    - Route Plan\n    Goal: to plan a global route\n    from point A to point B,\n    considering traffic data,\n    fuel consumption, etc.]:::light\n\nGP2[I want to travel\n    from point A to point B\n    with a robotaxi]:::dark\n\nBP1[Behavior Planning\n      Inputs:\n      - Route Plan\n      - Perception Information\n      about the environment\n      Output:\n      - Behavior Strategy\n      Goal: to plan how the\n      vehicle should behave,\n      what motion characteristics\n      it should follow]:::light\n\nBP2[I want to follow\n  the middle lane,\n  then switch to the\n  inner lane]:::dark\n\nLP1[Local Planning\n      Inputs:\n      - Behavior Strategy\n      - Map\n      - Pose\n      - Predicted Objects\n      Output:\n      - Local Trajectory\n      Goal: to generate a\n      kinematically feasible,\n      safe trajectory]:::light\nLP2[Plan a safe and\n  smooth path within\n  the lane]:::dark\n\nVC1[Vehicle-Level Control\n      High-Level Control\n      Inputs:\n      - Local Trajectory\n      - Vehicle State Variables\n      - Localization Information\n      Outputs:\n      - Vehicle-Level Target\n      Quantities\n      - Control Constraints\n      Goal: to calculate the\n      vehicle's target state,\n      which the low-level\n      control will implement]:::light\nVC2[Guide the vehicle\n  along the planned\n  trajectory at the\n  appropriate speed]:::dark\n\nAC1[Actuator Control\n  Low-Level Control\n  Inputs:\n  - Vehicle-Level Target\n  Quantities\n  - Control Constraints\n  - Actuator State Variables\n  Outputs:\n  - Actuator Target States\n  Goal: to decompose\n  vehicle-level quantities\n  and implement them\n  through the actuators]:::light\n  AC2[Calculate the\nrequired motor\ntorque and steering\nangle reference]:::dark\n\nsubgraph Plan [Planning]\n  GP1\n  BP1\n  LP1\nend\nsubgraph Control [Control]\n  VC1\n  AC1\nend\nGP1--&gt;BP1--&gt;LP1--&gt;VC1--&gt;AC1\nGP2-.-BP2-.-LP2-.-VC2-.-AC2\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre> Figure 2: The main planning and control layers in the architecture.</p> <p>The control layer is usually divided into multiple levels. We distinguish at least two such levels: - vehicle-level control - actuator control</p> <p>Each layer has its own tasks. The task of vehicle-level control is to guide the vehicle along the planned trajectory at the appropriate speed. It determines target values at the vehicle level. As a rule of thumb, quantities at the vehicle level are those that are not yet associated with a specific actuator. For example, every car has an acceleration or angular velocity, regardless of its propulsion (electric, hybrid, internal combustion) or steering (electric servo, hydraulic servo, tracked, etc.). This control layer is generally the \"slowest,\" with a cycle time of 10-50ms in an embedded environment.</p> <p>The task of actuator control is to decompose vehicle-level quantities and implement them through the actuators. For example, longitudinal acceleration can be influenced through the engine and brakes. In the case of the engine, acceleration is achieved by controlling the engine torque, which is controlled by the throttle position. The throttle position is controlled by the position of the servo motor that moves it, which is controlled by the voltage applied to the servo motor. In the case of the braking system, we can influence the braking force, which means controlling the brake pressure (e.g., through the ESP valves), which is achieved by the pressure of the hydraulic brake system's motor pump. This is influenced by the pump motor's speed, which is controlled by the voltage applied to the motor, and so on. We see that depending on the actuators, we are talking about multiple (even 4-6) nested control loops.</p> <p>It is advisable to approach the problem from the inside out, as the innermost control cycle time can be as low as 1 ms (or less), while as we move outward, it increases to the range of 5-10-20ms. It is important that in the case of automated driving systems' motion control, actuator control layers are often not considered, assuming that their performance, accuracy, and speed are adequate, \"nearly ideal.\" Of course, in practice, it is often difficult to separate these, but we strive to design only the vehicle-level control.</p> <p>The task of the highest-level control is to follow the trajectory. Generally, we distinguish two dimensions: - longitudinal motion: determining the vehicle's longitudinal acceleration, and finally the braking and engine forces. - lateral motion: determining the vehicle's target angular velocity, and finally the steering angle.</p> <p>The trajectory is usually a speed trajectory described over time or a set of target points given in space, i.e., a curve (or its representation). The goal is to follow the curve with minimal position error and maintain the speed as accurately as possible, without exceeding any limits (e.g., excessive acceleration, leaving the path, etc.).</p> <p>Before we move on to existing vehicle control solutions, we will provide an overview of the basics of control in subsection 3.</p>"},{"location":"control/#3-basics-of-control","title":"3. Basics of Control","text":"<p>In this chapter, we introduce the basic concepts related to control engineering and provide examples from the field of vehicle control.</p>"},{"location":"control/#31-definitions","title":"3.1. Definitions","text":"<p>Real physical system: A physical object that changes measurably under measurable external constraints.</p> <p>Inputs: Physical constraints acting on the real physical system that can change over time. Outputs: Any change in the real physical system due to physical constraints can be considered a physical output. We consider it a physical output if it is directly or indirectly measured in the given study. Example: This is always defined according to the control task. For example, vehicle-level control: the system is the vehicle itself, with inputs such as longitudinal and lateral acceleration. Outputs can be position, speed, etc. Example: In low-level control, this can be, for example, brake control, where the input is the position of the master cylinder, and the output is the force between the brake disc and the brake pad, or the torque acting on the wheel, etc.</p> <p>Abstract system: An abstract model of a real physical system with a certain accuracy and valid for a specific operating range, creating a mathematical relationship between input and output signals. This is essentially the result of a modeling process, where the model is the mathematical description of the real physical system, typically in the form of differential equations. Example: The kinematic bicycle model of a vehicle.</p> <p>System parameters: The coefficients of the equations describing the real physical system. Time invariance: A system is time-invariant if the response to an excitation U(t) is Q(t), and the response to a time-shifted excitation U(t-tau) is Y(t-tau). This also means that the system model does not change over time, i.e., the system parameters are constant. Example: The parameters of the kinematic bicycle model of a vehicle, such as the wheelbase, which (hopefully) does not change over time, making this parameter time-invariant. If all parameters of the system model are time-invariant, the abstract system itself is invariant. Example: A parameter of the dynamic bicycle model of a vehicle is the vehicle's mass. This can change \"on the go,\" as more people get in the car, luggage is loaded, the fuel level changes, etc., making this parameter not time-invariant, and thus the physical system is not time-invariant. However, under certain conditions, we can consider it time-invariant, increasing the model's inaccuracy.</p> <p>State: In dynamic systems with memory, the state is the cumulative effect of the past. The state of the system must have the following two properties: - At any time T, the output can be uniquely determined by knowing the state and input at that moment. The relationship that determines the output from the state and input is called the output equation. - The state at a given time T can be uniquely determined by knowing the input over the time range t\u2264T. The equation describing the state change is called the state equation.</p> <p>State variable: State variables are used to uniquely describe the state. A state variable can be a time function to describe quantitative changes in the state or a logical variable to describe qualitative changes in the state.</p> <p>System dimension: The number of state variables minimally required to uniquely describe the state of a system is called the system dimension.</p> <p>Canonical state variables: Canonical state variables are the smallest set of state variables that can uniquely describe the state. Non-canonical state variables are called derived state variables.</p> <p>Lyapunov stability: A nonlinear autonomous system is said to be Lyapunov stable if, for any neighborhood of the equilibrium state, there exists a maximum deviation greater than zero, within which the system is guaranteed to return to the originally defined neighborhood.</p> <p>BIBO stability: A system is BIBO (Bounded Input Bounded Output) stable if a bounded input always results in a bounded output. A system meeting this condition is called a BIBO stable system.</p> <p>These concepts are sufficient to understand the basics of vehicle control. The control task is often divided into two parts: - modeling, creating the abstract mathematical model - control, designing the controller.</p>"},{"location":"control/#32-formulating-the-control-task","title":"3.2. Formulating the Control Task","text":"<p>The goal is always to control the real physical system so that it behaves according to the prescribed target value. It is important to define measurable quantities for each goal to determine the \"goodness\" of the control. The most commonly (but not exclusively) used quantities are: - settling time (speed) - overshoot - steady-state error - control energy.</p> <p>The control chain can be described as shown in Figure 3. The following notations are used:</p> <ul> <li>\\(r(t)\\): the target value or reference signal</li> <li>\\(y(t)\\): the feedback value</li> <li>\\(m(t)\\): the measured value of the real system. Note: sensors are often considered ideal, so \\(y(t)=m(t)\\), making the feedback value also the output of the abstract system.</li> <li>\\(e(t)\\): error signal, the input to the controller.</li> <li>\\(i(t)\\): the control signal determined by the controller.</li> <li>\\(f(t)\\): feedforward branch.</li> <li>\\(u(t)\\): the system input</li> <li>\\(d(t)\\): external disturbances.</li> </ul> <p> Figure 3: Block diagram of the control chain.</p> <p>The controller's task is to minimize the error at its input. The entire control chain's task is to ensure that the output of the real physical system follows the reference signal as accurately as possible. In the following, we illustrate the modeling of a system, the effect of disturbances, and provide an example of a controller and the possibility of feedforward. The example is created in MATLAB/Simulink.</p>"},{"location":"control/#33-example-of-control-basics","title":"3.3. Example of Control Basics","text":"<p>In this example, we will build a simple model to illustrate closed-loop control. The task is to control the speed of a vehicle. We will create a simple model of the vehicle. 1. Task: Determine the inputs and outputs of the system! We want to influence the system with the accelerating force acting on the vehicle, so this is the input. The output is the vehicle's speed, as we want to control it to a given target value. Since this system has 1 input and 1 output, it is often called a SISO (Single Input Single Output) system. By analogy, there are also MIMO (Multiple Inputs Multiple Outputs) systems. Note: In reality, we influence the vehicle with the gas pedal and the brake pedal, but these actually affect the vehicle's acceleration, so for simplicity, we do not model this part of the section. This, of course, introduces an error into the model but increases its generality.</p> <ol> <li>Task: Create the mathematical model / abstract model of the vehicle! We are looking for a system of equations that connects the input and output. Here we need to determine how accurate we want the model to be. For simplicity, let's use the following constraints:</li> <li>we disregard the longitudinal wheel slip</li> <li>we disregard the dynamic behavior of the actuators, i.e., the requested acceleration is realized immediately</li> <li>we disregard the errors affecting the measured quantities, i.e., the inaccuracies of the sensors.</li> <li>we disregard the dynamic properties of the chassis and suspension.</li> </ol> <p>Thus, our equation simplifies to the linear motion of a concentrated mass point. Include the following quantities in the model: - the mass of the vehicle - the aerodynamic drag of the vehicle - the speed-dependent friction of the vehicle.</p> <p>According to Newton's second law, write the following dynamic equilibrium equation:  $$ \\ddot I = \\sum F $$</p> <p>That is:</p> \\[ m*\\ddot v(t) = F_{prop}(t) - F_{aero}(t) - F_{fric}(t) \\] <p>We see that both the input and output appear in our equation, so we have indeed found the model of the system. Further transform it so that only the input and output appear in it:</p> \\[ m*\\ddot v(t) = F_{prop}(t) - \\frac{1}{2}*v(t)^2*\\rho*c*A - v(t)*b \\] <p>In this form, the time-varying signals are the input and output (the speed and the driving force), and there are time-invariant parameters:</p> <ul> <li>\\(\\rho\\): air density</li> <li>\\(A\\): frontal area</li> <li>\\(c\\): vehicle drag coefficient</li> <li>\\(b\\): Coulomb friction coefficient</li> </ul> <p> Figure 4: Modeled force balance of the vehicle.</p> <p>To obtain the speed as the chosen output, we need to solve the differential equation. This is done numerically in Simulink. The solution is shown in Figure 5.</p> <p> Figure 5: Numerical solution of the differential equation.</p> <p>The block diagram of the entire control chain is shown in Figure 6. In this figure, we do not use the feedback branch. The initial speed is set to 20 m/s. The driving force is zero in this case, so the vehicle rolls due to its inertia and continuously slows down proportionally to the load.</p> <p> Figure 6: Block diagram of the entire control chain.</p> <p>The following parameter values were chosen for the simulation:</p> <ul> <li>\\(A = 1.2m^2\\)</li> <li>\\(b = 10 Ns/m\\)</li> <li>\\(c = 0.4\\)</li> <li>\\(\\rho = 1 kg/m^3\\)</li> <li>\\(m = 1250 kg\\)</li> </ul> <p>The result of the run is shown in Figure 7. The simulation ran for 100s, during which the vehicle slowed down from 20 m/s to about 7 m/s.</p> <p> Figure 7: Block diagram of the entire control chain.</p> <p>In Figure 8, we choose a proportional controller (P controller) for the feedback controller, which determines the control signal proportional to the error. The gain is chosen to be 100, i.e., a 1 m/s speed error results in 100N driving force. The initial speed is 15 m/s, the target speed is 20 m/s, so initially, we will have 500N driving force.</p> <p> Figure 8: Proportional controller with a gain of 100.</p> <p>Figure 9 shows the characteristics of the controller with a P controller and a gain of 100. The steady-state error is relatively large (more than 10%). The reason is that the proportional controller produces an input signal proportional to the error, and since there is an opposing force acting on the vehicle, the controller will balance with it. If we increase the gain, the steady-state error decreases. In theory, infinite gain reduces this error to zero, but infinite gain means infinite control signal, which is not feasible. In practice, we reach the limits much sooner, as the actuators can only exert finite force. This must be taken into account when designing the controller.</p> <p> Figure 9: Characteristics of the proportional controller.</p> <p>We can eliminate the steady-state error by adding a controller term that \"notices\" if a given error persists for a long time and increases the control signal accordingly. The longer the error persists, the more we increase the control signal. This practically means a control term proportional to the time integral of the error. This is called the I term. The resulting controller is called a PI controller. The arrangement of the controller is shown in Figure 10, and the output characteristics in Figure 11. We see that the error has indeed disappeared, but the initial transient phase has also changed. Overshoot and oscillation around the target value have appeared, and the settling time has also increased.</p> <p> Figure 10: Proportional controller with a gain of 100 and integrator with a gain of 10.</p> <p> Figure 11: Proportional controller with a gain of 100 and integrator with a gain of 10.</p> <p>We can improve the above settling oscillation and overshoot by changing the parameters or adding a controller term that reacts to the change in error. This speeds up the settling and compensates for the overshoot more quickly. This practically means a term proportional to the change in error, equivalent to considering the derivative of the error. This term is called the D term, and the resulting controller is called a PID controller. However, the gain of the D term must be chosen carefully, as it can easily make the system unstable. The structure of the controller is shown in Figure 12, and its characteristics in Figure 13.</p> <p> Figure 12: Proportional controller with a gain of 100, integrator with a gain of 10, and D term with a gain of 10.</p> <p> Figure 13: Proportional controller with a gain of 100, integrator with a gain of 10, and D term with a gain of 10.</p> <p>Empirically, considering the amount of overshoot, settling time, and steady-state error, choose the following parameter values:</p> \\[ P=175,  I=10,  D=50 \\] <p>With this, the settling is very nice, as shown in Figure 14. Figure 14: Proportional controller with a gain of 170, integrator with a gain of 10, and D term with a gain of 50.</p> <p>Figure 15 shows the effect of adding an extra accelerating force caused by a 3\u00b0 slope. The overshoot is larger because the controller was tuned with a model assuming a vehicle moving on flat terrain.</p> <p> Figure 15: Effect of slope on the closed-loop controller.</p> <p>We can compensate for this by creating a feedforward branch proportional to the slope. However, estimating the slope is difficult; we can generally infer it from the vehicle's motion, which only indicates the slope magnitude with a delay. Add a slope compensation with a 1s delay and a 5% error. The block diagram is shown in Figure 16, and the result in Figure 17.</p> <p> Figure 16: Control system with added feedforward branch.</p> <p> Figure 17: Effect of feedforward branch on the controller.</p>"},{"location":"control/#34-interactive-pid-tuning","title":"3.4 Interactive PID Tuning","text":"<p>Next, you can interactively tune a PID controller in another control example (temperature control):</p> <p>This interactive visualization is a solution by Mario Theers - CC BY 4.0 License.</p> <p>A similar interactive visualization is available on Viktor.ai, where you can also tune the parameters: cloud.viktor.ai/public/control-application</p>"},{"location":"control/#summary","title":"Summary","text":"<p>In this chapter, we reviewed the basic concepts of control engineering and provided examples from the field of vehicle control. Additionally, we created a simple mathematical model that describes the longitudinal motion of a vehicle as a mass point. Through this, we conducted a speed control simulation using MATLAB/Simulink. We introduced one of the most common controllers, the PID controller. Key points to remember: - A closed-loop control system typically consists of the controlled section (which is the abstract mathematical model of the real physical system) and the controller. - The real physical system is described by a mathematical model, which also serves as the basis for designing the controller. The accuracy of the model affects the quality of the designed controller. - The mathematical model is usually presented in the form of differential equations. - PID controllers aim to minimize the error. The P term speeds up the system, the I term eliminates the steady-state error, and the D term also speeds up the controller's response but can cause instability. - In reality, vehicle control is complex due to varying parameters (e.g., vehicle mass), road conditions, and nested control loops.</p>"},{"location":"control/#4-vehicle-control-solutions","title":"4. Vehicle Control Solutions","text":"<p>In the field of vehicle control, as seen in subsection 2, multiple nested control loops are used. Each typically contains a feedforward and a feedback branch. In automated driving systems, the highest-level, vehicle-level control is usually considered first. We will not delve into lower-level controllers here, but we will summarize them in a list. It should be noted that these low-level controllers depend heavily on the available actuators in the vehicle, as various braking systems, drives, and steering systems may be available. This division greatly supports modular design, allowing vehicle-level control to be developed independently of low-level controls. This, for example, greatly facilitates reusability in mass-produced software. The low-level, actuator control loops can include (without being exhaustive): - Steering servo motor angle control - Steering servo motor torque control - Engine torque control - Brake force control (brake pressure control).</p> <p>From this point on, all statements apply to the vehicle level. It is important to note that we always think in two dimensions: longitudinal and lateral control. We saw an example of longitudinal control in subsection 3. This generally means speed control or possibly acceleration control. Although longitudinal control also poses significant challenges (engine inertia, separation of braking and driving forces, etc.), most vehicle control solutions primarily focus on lateral control. Since the task of automatic vehicle control is very similar to human driving (i.e., influencing the vehicle's movement using the steering wheel and pedals), these control solutions are often referred to as driver models. Short summaries of each model can be found under the recommended literature. According to [1], driver models can be divided into three groups: - Inverse models - Predictive models - Closed-loop models.</p> <p> Figure 18: Illustration of vehicle control solutions.</p>"},{"location":"control/#inverse-models","title":"Inverse Models","text":"<p>Inverse models are also known as pursuit models in English terminology, which can be best translated as forward-looking or forward-pushing. The essence is that the target value for steering is determined based on two pieces of information: - What is the target state of the vehicle at a look-ahead point? - The pre-established model of the vehicle. This can be considered as a feedforward control branch or open-loop control, i.e., control. If the latter is the case (i.e., there is no feedback branch), it is called pure pursuit control.</p> <p>Warning</p> <p>Pure-pursuit control is one of the oldest control solutions in the field of vehicles. It was developed by the Robotics Institute of Pittsburgh in the 1980s [4]. The essence is that at a given look-ahead distance (which is the most important parameter of the control), we determine the desired position of the vehicle (e.g., based on the previously planned trajectory).</p> <p>Based on the coordinates of this point, we can determine the curvature of the circular arc we need to follow to reach the target point from the current point. It is important to note that pure-pursuit control always uses circular arcs. The geometric relationships are illustrated in Figure 19. Based on simple trigonometric considerations, the following relationship can be established between the look-ahead point and the target curvature:</p> \\[ \\kappa_{target}=\\frac{2x}{l^2} \\] <p>As we can see, we have formulated a quantity (curvature) at the vehicle level based on the input trajectory, thus theoretically fulfilling the main task of vehicle control. However, during implementation, we usually produce a quantity that is already interpretable at the actuator level. For this, we use the vehicle model: we provide a relationship between the target curvature and the steering angle. The most commonly used model is the kinematic bicycle model of the vehicle, but it becomes very inaccurate at higher speeds (&gt;10 km/h). Using the relationships of the kinematic bicycle model, we can obtain the steering angle:</p> \\[ \\delta_f=atan(L_w*\\kappa) \\] <p>Where \\(L_w\\) is the wheelbase of the vehicle.</p> <p>We assume in the model that the vehicle is front-wheel steering. The obtained angle is the road-wheel angle, which can be converted to, for example, servo motor angle based on the geometry of the steering mechanism, and thus can be directly implemented.</p> <p> Figure 19: Geometric relationships of the pure pursuit controller.</p> <p>Figure 20 shows the effect of the look-ahead distance on the vehicle's behavior. If we choose a point that is too close, the vehicle tends to oscillate (similar to the effect of a PID controller with too high a P gain). If the look-ahead distance is too large, the reaction slows down, but in sharp turns, the vehicle tends to cut corners. It is common to adaptively set the look-ahead distance, for example, as a function of speed. In this case, we are practically talking about look-ahead time.</p> <p> </p> <p>Figure 20: Effect of look-ahead distance on vehicle behavior in pure pursuit control</p> <p>Further developed versions of pure-pursuit models can be found in articles [2] and [3].</p>"},{"location":"control/#predictive-models","title":"Predictive Models","text":"<p>Predictive models, similar to inverse models, are based on the vehicle model. However, they also look ahead over a specified horizon: using the model, we estimate the vehicle's behavior in advance and then choose the best solution in the present based on this. Thus, in this case, we make decisions using future information with a certain accuracy. Here we distinguish between two cases: - Receding horizon: the future horizon continuously shifts ahead of us, as we always execute only the first element of the planned future behavior, then replan. - Proceeding horizon: the horizon approaches us, meaning we fully execute the planned future behavior and only then replan.</p> <p>Since control here also involves motion planning, we must use the tools of planning. These controllers are also called Optimal Controllers. In this case, we plan the motion over the look-ahead horizon using the model to achieve the lowest cost according to the given criteria. Here we refer back to the criteria introduced at the beginning of subsection 3.2: - Settling time (speed) - Overshoot - Steady-state error - Control energy.</p> <p>Since we want to plan the optimal motion over a finite-length time horizon, we combine the settling time, overshoot, and steady-state error into a vector and aim to minimize the sum of the elements of this vector (1st criterion). Control energy is related to the amplitude of the control signal vector. That is, we want to achieve the best result with the lowest possible signal (e.g., we want to accelerate or apply torque to the steering wheel as little as possible). This is the 2nd criterion, which imposes an opposing requirement on control compared to the 1st criterion.</p> <p>These controllers are also called Model Predictive Controllers (MPC). The following equation is an example of how to formulate the cost function to be solved:</p> \\[ J(k)=\\sum_{i=1}^{N_p}\\|y(k+i)-y_{ref}(k+i)\\|^2_M + \\sum_{i=1}^{N_c-1}\\|\\Delta U(k+i)\\|^2_N \\] <p>Where:</p> <ul> <li>\\(N_p\\): prediction horizon, expressed in computation cycles (considering the model)</li> <li>\\(k\\): the current computation cycle</li> <li>\\(y(k+i)\\): the vehicle's lateral position estimated by the model in the \\(i\\)th cycle</li> <li>\\(y_{ref}(k+i)\\): the reference position (target position) in the \\(i\\)th cycle</li> <li>\\(N_c\\): control horizon (considering the input)</li> <li>\\(\\Delta U\\): the increment of the input vector over the control horizon</li> <li>\\(M\\) and \\(N\\): weight matrices for the error and input energy.</li> </ul> <p>Examples of such controllers can be found in literature [1], [5-7]. The advantage of MPCs is that they provide very high accuracy and stable control if the applied model is highly accurate. However, this is also their disadvantage, as if the model is not appropriate, the error can grow exponentially. We see an example of this in Figures 21-23. In each simulation, we used a kinematic bicycle model to design the MPC. The PID controller minimizes the position error. In the simulation, we applied the vehicle's dynamic model as the real physical system. It can be seen that at 5 m/s, the MPC clearly outperforms the PID controller, being much more accurate and stable. However, at 2 m/s, the MPC falls apart, as the model relationships are not valid at low speeds. A similar observation can be made in Figure 23. In Figure 22, we see that up to 10 m/s, both the MPC and PID perform well, with the MPC still being better than the PID. However, above 10 m/s, dynamic effects become more pronounced, and the kinematic model is not suitable. Thus, the MPC becomes unstable, while the PID, although with significant error, continues to operate stably.</p> <p> Figure 21: Comparison of MPC and PID controllers using a kinematic model, turning at low speeds</p> <p> Figure 22: Comparison of MPC and PID controllers using a kinematic model, turning at higher speeds</p> <p> Figure 23: Comparison of MPC and PID controllers using a kinematic model, circular path at low speeds</p>"},{"location":"control/#closed-loop-models","title":"Closed-Loop Models","text":"<p>As the name suggests, these models are based on the logic of PID controllers. They typically minimize the error of one or more feedback quantities. Examples of such models can be found in literature [3] and [8]. Figure 24 illustrates an example presented in [3]. According to this, two look-ahead points are designated: a near one (in front of the vehicle) and a far one (on the horizon). Similar to pure-pursuit solutions, here we also examine how to get from the current position to the distant one. However, this is achieved not by simple curvature calculation but by minimizing the error according to the following equation:</p> \\[ \\phi=k_f\\dot\\Theta_f + k_n\\dot\\Theta_n + k_i\\Theta_n  \\] <p>Where:</p> <ul> <li>\\(\\dot\\Theta_f\\) and \\(\\dot\\Theta_n\\) are the angular velocities of the far and near points relative to us</li> <li>\\(\\Theta_n\\) is the angle of the near point relative to us</li> <li>\\(k\\) terms: weights</li> <li>\\(\\phi\\): the steering wheel angle.</li> </ul> <p>This equation essentially minimizes the angular errors, as the goal is to always be \"on course.\" The feedback comes from environmental sensing. The output is the steering wheel angle.</p> <p></p> <p>Figure 24: Illustration of the dual-point control solution</p> <p>Figure 25 shows the solution described in [8]. The essence is to minimize the position error using multiple nested PID controllers. To do this, the control task is divided into low-frequency control (position error) and high-frequency control (steering angle error). The transfer functions represent individual controllers, sequentially meaning:</p> <ul> <li>\\(G_c\\): position control with a PI controller</li> <li>\\(G_L\\): human control delay (reaction time)</li> <li>\\(G_NM\\): neuromotor control, representing how humans move the steering wheel. Its dynamics depend heavily on human muscle structure.</li> <li>\\(G_{P1}\\) and \\(G_{P2}\\): sensor models in the feedback loop. These represent human sensory dynamics, respectively for torque on the steering wheel and steering angle.</li> </ul> <p></p> <p>Figure 25: A complete closed-loop controller, integrating steering angle control</p>"},{"location":"control/#summary_1","title":"Summary","text":"<p>As we have seen, driver models always require a pre-planned trajectory. Controllers are used to follow this trajectory, which can be categorized into three groups:</p> <ul> <li>Inverse models</li> <li>Predictive models</li> <li>Closed-loop models.</li> </ul> <p>The oldest inverse models are the simplest and most robust, but their performance is generally low. Predictive models are very accurate but highly sensitive to model accuracy. Closed-loop models are stable over a wide range but generally have low accuracy. They consist of multiple nested loops, typically calibrated from the inside out. These are the most common in today's mass-produced systems.</p>"},{"location":"control/#recommended-literature","title":"Recommended Literature","text":"<ol> <li>Introduction: System Modeling, University of Michigan</li> <li>Interactive Live Script Control Tutorials for MATLAB and Simulink</li> <li>Mario Theers - PID - CC BY 4.0 License</li> <li>Mario Theers - Pure pursuit - CC BY 4.0 License</li> <li>Youtube ControlLectures</li> <li>Bokor J\u00f3zsef &amp; G\u00e1sp\u00e1r P\u00e9ter. Ir\u00e1ny\u00edt\u00e1stechnika</li> </ol>"},{"location":"control/#driver-models","title":"Driver Models","text":"<ol> <li>A. Y. Ungoren and H. Peng, \"An Adaptive Lateral Preview Driver Model,\" Vehicle System Dynamics, vol. 43, pp. 245-259, 2005.</li> <li>W. Rui, L. Ying, F. Jiahao, W. Tan and C. Xuetao, \"A Novel Pure Pursuit Algorithm for Autonomous Vehicles Based on Salp Swarm Algorithm and Velocity Controller,\" IEEE Access, vol. 8, pp. 166525-166540, 2020.</li> <li>D. Salvucci and R. Gray, \"A Two-Point Visual Control Model of Steering,\" Perception, vol. 33, pp. 1233-1248, 2004.</li> <li>C. R. Coulter, \"Implementation of the Pure Pursuit Path Tracking Algorithm,\" Vols. CMU-RI-TR-92-01, pp. 1-15, 1992.</li> <li>H. Jiang, H. Tian and Y. Hua, \"Model predictive driver model considering the steering characteristics of the skilled drivers,\" Advances in Mechanical Engineering, vol. 11, pp. 1-14, 2019.</li> <li>U. Kiencke, R. Majjad and S. Kramer, \"Modeling and performance analysis of a hybrid driver model,\" Control Engineering Practice, vol. 7, pp. 985-991, 1999.</li> <li>C. MacAdam, \"An Optimal Preview Control for Linear Systems,\" Journal of Dynamic Systems, Measurement and Control, vol. 102, pp. 188-190, 1980.</li> <li>R. Hess and A. Modjtahedzadeh, \"A Control Theoretic Model of Driver Steering Behavior,\" IEEE Control Systems Magazine, vol. 5, no. 8, pp. 3-8, 1990.</li> </ol>"},{"location":"control/practice/","title":"Practice - Control","text":""},{"location":"control/ros1practice/","title":"Gyakorlat","text":"<p>A gyakorlaton a robotverseny szimul\u00e1ci\u00f3t fogjuk haszn\u00e1lni. A szimul\u00e1tor linkenlt le\u00edr\u00e1s alapj\u00e1n telep\u00edthet\u0151.</p> <p>Melodic</p> <p>Noetic</p>"},{"location":"control/ros1practice/#sebessegszabalyzo-pid-hangolasa","title":"Sebess\u00e9gszab\u00e1lyz\u00f3 PID hangol\u00e1sa","text":"<p>A k\u00f6vetkez\u0151 paranccsal egy \u00fcres (akad\u00e1lyok n\u00e9lk\u00fcli) szimul\u00e1ci\u00f3 indul. Ez a PID sebess\u00e9gszab\u00e1lyz\u00f3 hangol\u00e1s\u00e1ra alkalmas.</p> <pre><code>roslaunch racecar_gazebo racecar_empty.launch\n</code></pre> <pre><code>roslaunch racecar_control cmd_vel_from_file.launch\n</code></pre> <p>Sz\u00fcks\u00e9g\u00fcnk lesz referencia jelek kiad\u00e1s\u00e1ra, megism\u00e9telhet\u0151 m\u00f3don. Ezt a p\u00e9ld\u00e1ban egy csv beolvas\u00e1sa, majd <code>/cmd_vel</code> topicon hirdet\u00e9se jelenti. Vizsg\u00e1ljuk meg a python f\u00e1jlt. A  topic hirdet\u00e9se, a node ROS-ben t\u00f6rt\u00e9n\u0151 regisztr\u00e1l\u00e1sa, a csv f\u00e1jl beolvas\u00e1sa a f\u00e1jl elej\u00e9n tal\u00e1lhat\u00f3:</p> <pre><code>cmd_pub = rospy.Publisher('/cmd_vel', Twist, queue_size=1)\nrospy.init_node('cmd_vel_from_file', anonymous=True)\nrate = rospy.Rate(10) # 10hz\nmsg_twist = Twist()\ncsv_file = rospy.get_param('~csv')\nrospack = rospkg.RosPack()\npath = rospack.get_path('racecar_control')\nrospy.loginfo('csv file is: %s/config/%s' % (path, csv_file))\narray = pd.read_csv(path + '/config/' + csv_file, header = None).to_numpy()\nstart_time = rospy.Time.now()\n</code></pre> <p>A folyamatosan fut\u00f3 loop <code>/cmd_vel.linear.x</code> jeleket hirdet, a csv-ben tal\u00e1lhat\u00f3 id\u0151 szerint. A <code>np.where</code> visszaadja, hogy az aktu\u00e1lis id\u0151 szerint (<code>current_time</code>) milyen sebess\u00e9g indexn\u00e9l (<code>itemindex</code>) tartunk. Ez egy 2D array, ami minden, a felt\u00e9telnek megfelel\u0151 indexet tartalmaz, de sz\u00e1munkra persze csak ennek az els\u0151 eleme a fontos, ezt fogjuk hirdetni. </p> <pre><code>while not rospy.is_shutdown():\n    current_time = (rospy.Time.now() - start_time).to_sec()\n    itemindex = np.where(array[:,0] &gt;= current_time)\n    try:\n        msg_twist.linear.x = array[itemindex[0][0],1]\n    except:\n        msg_twist.linear.x = 0.0\n    cmd_pub.publish(msg_twist)\n    rate.sleep()\n</code></pre> <p>A <code>roscd</code> parancs seg\u00edts\u00e9g\u00e9vel l\u00e9pj\u00fcnk a <code>racecar_control</code> package <code>config</code> mapp\u00e1j\u00e1ba.</p> <pre><code>roscd racecar_control/config/\n</code></pre> <p>Ez val\u00f3sz\u00edn\u0171leg a <code>~/sim_ws/src/racecar_gazebo/f1tenth/virtual/dependencies/racecar_control/config</code> helyen tal\u00e1lhat\u00f3, de elk\u00e9pzelht\u0151, hogy valaki m\u00e1shova telep\u00edtette.</p> <p>Innen bet\u00f6lthet\u00fcnk k\u00fcl\u00f6nb\u00f6z\u0151 PID be\u00e1ll\u00edt\u00e1sokat, pl: </p> <pre><code>rosparam load racecar_control01.yaml\nrosparam load racecar_control02.yaml\nrosparam load racecar_control03.yaml\n</code></pre> <p>Ellen\u0151rizz\u00fck a <code>get</code> paranccsal, a k\u00f6vetkez\u0151h\u00f6z hasnonl\u00f3 eredm\u00e9nyt fogunk kapni: </p> <pre><code>rosparam get /racecar/left_rear_wheel_velocity_controller/pid/\n{antiwindup: false, d: 0.0, i: 0.0, i_clamp: 0.0, i_clamp_max: 0.0, i_clamp_min: -0.0,\n  p: 5.0}\n</code></pre> <p>Note</p> <p>Alternat\u00edvak\u00e9nt haszn\u00e1lhatjuk a <code>rosrun rqt_reconfigure rqt_reconfigure</code> parancsot is.</p> <p>Futtassuk a k\u00f6vetkez\u0151 parancsot a sebess\u00e9g referencia kiad\u00e1s\u00e1ra: <pre><code>roslaunch racecar_control cmd_vel_from_file.launch\n</code></pre> A launch f\u00e1jlba megadhatjuk, hogy pl a <code>01.csv</code>, <code>02.csv</code> stb f\u00e1jlt t\u00f6ltse-e be. T\u00f6bbsz\u00f6r futtathatjuk, ak\u00e1r m\u00e1s PID be\u00e1ll\u00edt\u00e1sok mellett is.</p> <p>Figyelj\u00fcnk meg k\u00e9t topicot pl Foxglove seg\u00edts\u00e9g\u00e9vel, k\u00fcl\u00f6nb\u00f6z\u0151 PID be\u00e1ll\u00edt\u00e1sok mellett: - <code>/racecar/left_rear_wheel_velocity_controller/state.process_value</code> - <code>/racecar/left_rear_wheel_velocity_controller/command.data</code></p> <p></p>"},{"location":"control/ros1practice/#kormanyzas-pid-hangolasa","title":"Korm\u00e1nyz\u00e1s PID hangol\u00e1sa","text":"<p>A k\u00f6vetkez\u0151 parancsra, m\u00e1r nem \u00fcres, hanem egy k\u00f6rbeker\u00edtett versenyp\u00e1lya ny\u00edlik meg.</p> <pre><code>roslaunch racecar_gazebo racecar.launch\n</code></pre> <p>A p\u00e1lya a k\u00f6vetkez\u0151k\u00e9pp n\u00e9z ki:</p> <p></p>"},{"location":"control/ros2practice/","title":"Practice","text":"<p>In the first part of the practice, we will use a first and second-order system example, apply a PID controller, and then tune it. In the second part of the practice, we will review and tune the operation of a simulated trajectory-following robot/vehicle.</p> <p></p> <ul> <li><code>Task 1</code>: Trajectory following with simulation</li> <li><code>Task 2</code>: Custom controller and vehicle model</li> <li><code>Task 3</code>: PID tuning</li> </ul>"},{"location":"control/ros2practice/#task-1-trajectory-following-with-simulation","title":"<code>Task 1</code>: Trajectory following with simulation","text":"<p>github.com/jkk-research/sim_wayp_plan_tools</p>"},{"location":"control/ros2practice/#requirements","title":"Requirements","text":"<p>For the practice to run smoothly, the following programs need to be installed: - ROS 2 Humble: docs.ros.org/en/humble/Installation.html - Gazebo Fortress: gazebosim.org/docs/fortress/install_ubuntu, More information on integration: gazebosim.org/docs/fortress/ros2_integration - <code>ros-gz-bridge</code> can be installed with one command: <code>sudo apt install ros-humble-ros-gz-bridge</code> - Ensure that <code>colcon_cd</code> is properly installed. CSV files are loaded with <code>colcon_cd</code>.</p>"},{"location":"control/ros2practice/#packages-and-build","title":"Packages and build","text":"<p>The default workspace should be: <code>~/ros2_ws/</code>.</p>"},{"location":"control/ros2practice/#clone-the-packages","title":"Clone the packages","text":"<pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/jkk-research/wayp_plan_tools\n</code></pre> <pre><code>git clone https://github.com/jkk-research/sim_wayp_plan_tools\n</code></pre>"},{"location":"control/ros2practice/#building-ros-2-packages","title":"Building ROS 2 packages","text":"<pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select wayp_plan_tools sim_wayp_plan_tools\n</code></pre>"},{"location":"control/ros2practice/#using-wayp_plan_tools-as-a-simulator","title":"Using <code>wayp_plan_tools</code> as a simulator","text":""},{"location":"control/ros2practice/#11-starting-gazebo","title":"1.1. Starting gazebo","text":"<pre><code>ign gazebo -v 4 -r ackermann_steering.sdf\n</code></pre>"},{"location":"control/ros2practice/#12-starting-the-gazebo-bridge","title":"1.2. Starting the Gazebo bridge","text":"<p>If the bridge is not installed, the following commands will help: <pre><code>sudo apt update\n</code></pre></p> <pre><code>sudo apt install ros-humble-ros-gz -y\n</code></pre> <p>In the classroom:</p> <pre><code>cd /mnt/kozos/script\n</code></pre> <pre><code>./gz_bridge.sh\n</code></pre> <p>Don't forget to <code>source</code> before running ROS commands.</p> <pre><code>source ~/ros2_ws/install/local_setup.bash\n</code></pre> <pre><code>ros2 launch sim_wayp_plan_tools gazebo_bridge.launch.py\n</code></pre> <p>This <code>launch</code> file starts the following nodes together:</p> <pre><code>ros2 run ros_gz_bridge parameter_bridge /world/ackermann_steering/pose/info@geometry_msgs/msg/PoseArray[ignition.msgs.Pose_V\n</code></pre> <pre><code>ros2 run ros_gz_bridge parameter_bridge /model/vehicle_blue/cmd_vel@geometry_msgs/msg/Twist]ignition.msgs.Twist\n</code></pre> <pre><code>ros2 run ros_gz_bridge parameter_bridge /model/vehicle_blue/odometry@nav_msgs/msg/Odometry[ignition.msgs.Odometry --ros-args -r /model/vehicle_blue/odometry:=/odom\n</code></pre> <p>More information about the bridge: github.com/gazebosim/ros_gz/blob/ros2/ros_gz_bridge/README.md</p> <p>This <code>launch</code> also creates a <code>/tf</code> from the <code>PoseArray</code> with <code>pose_arr_to_tf</code>.</p>"},{"location":"control/ros2practice/#optional-controlling-the-robot-in-gazebo-with-the-keyboard","title":"Optional: Controlling the robot in Gazebo with the keyboard:","text":"<pre><code>ros2 run teleop_twist_keyboard teleop_twist_keyboard --ros-args -r /cmd_vel:=/model/vehicle_blue/cmd_vel\n</code></pre>"},{"location":"control/ros2practice/#13-loading-waypoints","title":"1.3. Loading waypoints","text":"<p>Note: Waypoints are a set of points that contain the position, orientation, and speed data of the route at discrete points. These data are typically extracted by recording the x, y, and possibly z coordinates, the orientation pointing to the next point relative to the current one, and the current speed data during our journey in ROS. Finally, the aforementioned data are recorded in CSV files.</p> <p>Use the ROS 2 workspace as <code>file_dir</code>: <pre><code>ros2 run wayp_plan_tools waypoint_loader --ros-args -p file_name:=sim_waypoints1.csv -p file_dir:=$HOME/ros2_ws/src/sim_wayp_plan_tools/csv -r __ns:=/sim1\n</code></pre></p> <p>Or with default parameters:</p> <pre><code>ros2 launch sim_wayp_plan_tools waypoint_loader.launch.py\n</code></pre>"},{"location":"control/ros2practice/#14-waypoint-as-goal-pose","title":"1.4. Waypoint as goal pose","text":"<p>As shown in the diagrams in Chapter 4 of the theoretical part, each control algorithm has one or more goal poses that the current controller regulates.</p> <pre><code>ros2 run wayp_plan_tools waypoint_to_target --ros-args -p lookahead_min:=2.5 -p lookahead_max:=4.5 -p mps_alpha:=1.5 -p mps_beta:=3.5 -p waypoint_topic:=waypointarray -p tf_frame_id:=base_link -p tf_child_frame_id:=map -r __ns:=/sim1\n</code></pre> <p>Or with default parameters:</p> <pre><code>ros2 launch sim_wayp_plan_tools waypoint_to_target.launch.py\n</code></pre>"},{"location":"control/ros2practice/#15-starting-the-control","title":"1.5. Starting the control:","text":"<p>Several options: - <code>single_goal_pursuit</code>: Pure pursuit (for vehicles/robots), a simple cross-track error method - <code>multiple_goal_pursuit</code>: Multiple goal pursuit for vehicles/robots, an implementation of our paper - <code>stanley_control</code>: Stanley controller, a heading error + cross-track error method - <code>follow_the_carrot</code>: Follow-the-carrot, the simplest controller</p> <p>An example for pure pursuit:</p> <pre><code>ros2 run wayp_plan_tools single_goal_pursuit --ros-args -p cmd_topic:=/model/vehicle_blue/cmd_vel -p wheelbase:=1.0 -p waypoint_topic:=targetpoints -r __ns:=/sim1\n</code></pre> <p>Or with default parameters:</p> <pre><code>ros2 launch sim_wayp_plan_tools single_goal_pursuit.launch.py\n</code></pre>"},{"location":"control/ros2practice/#16-visualizing-the-results-in-rviz2","title":"1.6. Visualizing the results in <code>RViz2</code>:","text":"<pre><code>ros2 launch sim_wayp_plan_tools rviz1.launch.py\n</code></pre> <p>Or run everything together with a single command:</p> <p>After <code>ign gazebo -v 4 -r ackermann_steering.sdf</code> (terminal 1) and <code>source ~/ros2_ws/install/local_setup.bash</code> (terminal 2), run this command (also in terminal 2): <pre><code>ros2 launch sim_wayp_plan_tools all_in_once.launch.py\n</code></pre></p>"},{"location":"control/ros2practice/#troubleshooting","title":"Troubleshooting","text":"<p>Stopping the <code>ign gazebo server</code>:</p> <pre><code>ps aux | grep ign\n</code></pre> <pre><code>ab  12345 49.9  1.2 2412624 101608 ?      Sl   08:26  27:20 ign gazebo server\nab  12346  518  6.6 10583664 528352 ?     Sl   08:26 283:45 ign gazebo gui\nab  12347  0.0  0.0   9396  2400 pts/2    S+   09:21   0:00 grep --color=auto ign\n</code></pre> <p>If the PID is identified, use the kill command to stop the process. For example, to stop the gazebo server:</p> <pre><code>kill 12345\n</code></pre>"},{"location":"control/ros2practice/#task-2-custom-controller-and-vehicle-model","title":"<code>Task 2</code>: Custom controller and vehicle model","text":"<p>In this task, we will create the speed controller presented in the theory and the associated simple vehicle model.</p> <p>If not done already, update the arj_packages repository:</p> <pre><code>git pull\n</code></pre> <p>Navigate to the repo's root directory in the workspace src folder:</p> <pre><code>cd ~ros2_ws/src/arj_packages\n</code></pre> <p>Examine the repository content: <pre><code>dir\n</code></pre> We see that a subfolder named <code>speed_control_loop</code> has appeared. This folder contains the vehicle model and the controller used for regulation. Let's open the source code using VS Code.</p> <p></p> <p>The folder contains the usual package.xml and CMakeLists.txt, as well as two cpp source files. The <code>vehicle_model.cpp</code> naturally contains the vehicle model, and the <code>speed_controller.cpp</code> contains the controller. Let's first examine the vehicle model source code!</p>"},{"location":"control/ros2practice/#vehicle-model","title":"Vehicle Model","text":"<pre><code>class VehicleModel : public rclcpp::Node\n{\npublic:\n    VehicleModel() : Node(\"vehicle_model\")\n    {\n        timer_ = this-&gt;create_wall_timer(std::chrono::milliseconds(200), std::bind(&amp;VehicleModel::loop, this));  \n        state_pub_ = this-&gt;create_publisher&lt;std_msgs::msg::Float32MultiArray&gt;(\"/vehicle/state\", 10);\n        cmd_sub_ = this-&gt;create_subscription&lt;std_msgs::msg::Float32&gt;(\"/vehicle/propulsion\", 10,  std::bind(&amp;VehicleModel::propulsion_callback, this, std::placeholders::_1));\n        RCLCPP_INFO(this-&gt;get_logger(), \"vehicle_model has been started\");\n    }\n</code></pre> <p>After the usual #includes and namespace definitions, we see the constructor of the vehicle model class. The node's name is \"vehicle_model\". We subscribe to a topic named <code>/vehicle/propulsion</code>, which, as the name suggests, provides the propulsion force acting on the vehicle. Additionally, we advertise the <code>/vehicle/state</code> topic, which provides the vehicle's motion state.</p> <p>Next, we define some variables. 1. First, a local variable to store the input force. 2. Then, an array to contain the vehicle's speed and acceleration, the two state variables that describe the vehicle's state. 3. We define a variable named <code>Fload</code> to specify any extra loads acting on the vehicle. 4. Finally, we define some immutable parameters, such as the vehicle's weight, frontal area, etc.</p> <pre><code>private:\n    // input command\n    float Fprop {0.0f};\n\n    // vehicle state array\n    std::vector&lt;float&gt; state; //speed, acceleration\n    float vx{0.0f};\n    float ax{0.0f};\n\n    // load\n    float Fload{0.0f};\n\n    // params\n    float m {1350.0}; // kg\n    float A {1.5f}; // m^2\n    float rho {1.0f}; // kg/m^3\n    float c {0.33f}; // aerodynamic factor\n    float b {0.1f}; // rolling friction, viscosous\n</code></pre> <p>The topic callback function simply copies the incoming data to our local variable.</p> <pre><code>void propulsion_callback(const std_msgs::msg::Float32 input_msg)\n{\n    Fprop = input_msg.data;\n}\n</code></pre> <p>Finally, the <code>loop()</code> function, where we first calculate the resistance forces (aerodynamic drag and viscous friction), then compute the resultant force and the vehicle's acceleration. By integrating the vehicle's acceleration, we obtain the vehicle's speed.</p> <pre><code>void loop()\n{\n    // calculate new state based on load, prop force, mass and aerodynamic drag\n    float Faero = 0.5*A*rho*c*pow(vx,2);\n    float Ffric = b*vx;\n    ax = (Fprop - Ffric - Fload - Faero)/m;\n    vx = std::max(0.0f, vx + ax*0.1f); // 0.1s is the time step of the model\n\n    // Publish state\n    state.clear();\n    std_msgs::msg::Float32MultiArray state_msg;\n    state.push_back(vx); // m/s\n    state.push_back(ax); // m/s^2\n\n    state_msg.data = state;\n    state_pub_-&gt;publish(state_msg);\n}\n</code></pre>"},{"location":"control/ros2practice/#controller","title":"Controller","text":"<p>In <code>speed_control.cpp</code>, we see the PID control of the vehicle's speed. The node's name is \"speed_control\", and it subscribes to the <code>/vehicle/state</code> topic advertised by the vehicle model. Additionally, we advertise the <code>/vehicle/propulsion</code> command topic and subscribe to the <code>/vehicle/cmd</code> topic that provides the target speed. The controller's essence is to regulate the user-specified speed by generating the target force for the vehicle propulsion. Depending on the model's state, we increase or decrease the target force.</p> <pre><code>class SpeedControl : public rclcpp::Node\n{\npublic:\n    SpeedControl() : Node(\"speed_control\")\n    {\n        timer_ = this-&gt;create_wall_timer(std::chrono::milliseconds(200), std::bind(&amp;SpeedControl::loop, this));  \n\n        cmd_pub_ = this-&gt;create_publisher&lt;std_msgs::msg::Float32&gt;(\"/vehicle/propulsion\", 10);\n        state_sub_ = this-&gt;create_subscription&lt;std_msgs::msg::Float32MultiArray&gt;(\"/vehicle/state\", 10, std::bind(&amp;SpeedControl::state_callback, this, std::placeholders::_1));\n        cmd_sub_ = this-&gt;create_subscription&lt;std_msgs::msg::Float32&gt;(\"/vehicle/cmd\", 10, std::bind(&amp;SpeedControl::cmd_callback, this, std::placeholders::_1));\n\n        this-&gt;declare_parameter(\"/control/P\", 100.0f);\n        this-&gt;declare_parameter(\"/control/I\", 5.0f);\n        this-&gt;declare_parameter(\"/control/D\", 10.0f);\n\n        RCLCPP_INFO(this-&gt;get_logger(), \"speed_control has been started\");\n    }\n</code></pre> <p>The control logic is in the <code>loop()</code> function. The P, I, and D parameters can be set as ROS parameters. The propulsion force consists of three components: the derivative term (Fprop_D), the proportional term (Fprop_P), and the integral term (Fprop_I). This is a parallel PID structure, so the sum of the three terms gives the target force.</p> <pre><code>void loop()\n{\n    P = (float)this-&gt;get_parameter(\"/control/P\").as_double();\n    I = (float)this-&gt;get_parameter(\"/control/I\").as_double();\n    D = (float)this-&gt;get_parameter(\"/control/D\").as_double();\n    // calculate new state based on load, prop force, mass and aerodynamic drag\n    float Fprop_D = D*((vSet-vx)-error)/0.1;\n\n    float error = vSet-vx;\n    float Fprop_P = P*error;\n    float Fprop_I = I*integrated_error;\n\n    Fprop = Fprop_P+Fprop_I+Fprop_D;\n\n    Fprop = std::min(std::max(-Fprop_max, Fprop), Fprop_max);\n\n    // Publish cmd\n    std_msgs::msg::Float32 cmd_msg;\n    cmd_msg.data = Fprop;\n\n    cmd_pub_-&gt;publish(cmd_msg);\n\n    integrated_error+= error*0.1f;\n}\n</code></pre>"},{"location":"control/ros2practice/#test","title":"Test","text":"<p>To test, first build the <code>speed_control_loop</code> package!</p> <pre><code>colcon build --packages-select speed_control_loop\n</code></pre> <p>In another terminal, after sourcing, start the <code>vehicle_model</code> node, then the <code>speed_control</code> node! You can also do this easily using the pre-prepared <code>run_all.launch.py</code> launch file!</p> <pre><code>cd ~/ros2_ws/src/arj_packages/speed_control_loop\n</code></pre> <pre><code>ros2 launch launch/run_all.launch.py\n</code></pre> <p>Open Foxglove Studio and connect to the local host. To establish the connection, start the appropriate bridge! Do this from another terminal!</p> <p><pre><code>cd ~/ros2_ws/\n</code></pre> <pre><code>ros2 launch foxglove_bridge foxglove_bridge_launch.xml\n</code></pre></p> <p>Add 3 plot panels and select the topics shown in the image. Since we haven't set the target speed yet, it defaults to zero. The vehicle is practically stationary, and the controller output is also zero.</p> <p></p> <p>Manually advertise a topic that specifies the desired speed (e.g., the target speed set on the steering wheel in cruise control)!</p> <pre><code>ros2 topic pub /vehicle/cmd std_msgs/msg/Float32 \"data: 30.0\"\n</code></pre> <p>What do we see? The controller accelerates the vehicle with the maximum allowed acceleration (about 9 m/s^2) until it reaches the desired speed of 30 m/s. We can experiment with different speeds and parameter settings.</p> <p></p> <p>For example,</p> <pre><code>rosparam set /speed_control /control/I 200.0\n</code></pre> <p>results in less smooth speed ramp-up and noticeable overshoot.</p> <p></p>"},{"location":"control/ros2practice/#task-3-pid-tuning","title":"<code>Task 3</code>: PID Tuning","text":""},{"location":"control/ros2practice/#video","title":"Video","text":"<p>We aim to illustrate the control topic similarly to the video, but we will use Foxglove Studio instead of Plotjuggler.</p> <p>The following description assumes that the ROS 2 workspace is located at <code>~/ros2_ws/</code>.</p>"},{"location":"control/ros2practice/#terminal-1-clone","title":"<code>Terminal 1</code> clone","text":"<p>Clone the repository:</p> <pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/dottantgal/ros2_pid_library\n</code></pre>"},{"location":"control/ros2practice/#terminal-1-build","title":"<code>Terminal 1</code> build","text":"<p>Navigate back to the workspace root and build:</p> <pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select use_library pid_library example_system\n</code></pre>"},{"location":"control/ros2practice/#terminal-2-run","title":"<code>Terminal 2</code> run","text":"<p>Open a new terminal and run the following commands:</p> <pre><code>source ~/ros2_ws/install/local_setup.bash &amp;&amp; source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 launch example_system example_sys_launch.py\n</code></pre>"},{"location":"control/ros2practice/#terminal-3-set-point","title":"<code>Terminal 3</code> set point","text":"<pre><code>ros2 topic pub -r 1 /set_point_topic std_msgs/msg/Float32 \"data: 0.0\"\n</code></pre> <pre><code>ros2 topic pub -r 1 /set_point_topic std_msgs/msg/Float32 \"data: 1.0\"\n</code></pre> <pre><code>ros2 topic pub -r 1 /set_point_topic std_msgs/msg/Float32 \"data: 1.4\"\n</code></pre> <pre><code>ros2 topic pub -r 1 /set_point_topic std_msgs/msg/Float32 \"data: 0.6\"\n</code></pre>"},{"location":"control/ros2practice/#terminal-4-foxglove","title":"<code>Terminal 4</code> foxglove","text":"<p>If not installed yet:</p> <pre><code>sudo apt install ros-humble-foxglove-bridge\n</code></pre> <p>Start the bridge:</p> <pre><code>source ~/ros2_ws/install/local_setup.bash &amp;&amp; source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 launch foxglove_bridge foxglove_bridge_launch.xml\n</code></pre> <p>Then, using Foxglove Studio, all data is accessible at <code>ws://localhost:8765</code>.</p> <p></p>"},{"location":"control/ros2practice/#vs-code","title":"VS code","text":"<p>Edit the <code>example_sys_launch.py</code> file, then <code>colcon build</code> (terminal 1), <code>source</code>, and run.</p> <pre><code>code ~/ros2_ws/src/ros2_pid_library/\n</code></pre> <p></p> <p>Run and observe the results; the control signal (<code>control_value</code>) shows a slightly different characteristic:</p> <p></p>"},{"location":"control/ros2practice/#sources","title":"Sources","text":"<ul> <li>github.com/dottantgal/ros2_pid_library - MIT license</li> </ul>"},{"location":"dataset/","title":"Dataset overview","text":""},{"location":"dataset/#jkk_dataset_01","title":"<code>JKK_DATASET_01</code>","text":"<p>This dataset consists of measurement log files (ROS 1 rosbag), pointcloud files and additional scripts to access and edit these. The data is provided for research and educational purposes.</p> <p>Details</p> <p></p>"},{"location":"dataset/#jkk_dataset_02","title":"<code>JKK_DATASET_02</code>","text":"<p>This dataset consists of measurement log files (ROS 2 mcap) with additional scripts to access and edit these. The data is provided for research and educational purposes.</p> <p>Details</p> <p></p>"},{"location":"dataset/#jkk_dataset_03","title":"<code>JKK_DATASET_03</code>","text":"<p>This dataset contains the Human-like Behavior (HLB) usecase data, in mat format.</p> <p>Details</p> <p></p>"},{"location":"dataset/jkk_dataset_01/","title":"Jkk dataset 01","text":"<p>The log data is in .bag format, the standard logging format for ROS. To simply view and play the data Foxglove Studio is the easiest solution. It works on Windows, Linux and Mac. Another popular option is MATLAB. The data can be imported, viewed and edited in MATLAB. If you are familiar with ROS C++ or python can be a good option too. Python also offers possibilities top open the rosbags without ROS, similarly to MATLAB. The postprocessed 3D pointcloud data is in .pcd (Point Cloud Data) file format, it is a common format used inside Point Cloud Library (PCL). Also pcd can be imported easily to MATLAB / python. One of our most researched topic is self-driving (a.k.a autonomous) vehicles. We believe that fully self-driving technology can lead to safe, easy and sustainable transportation. We are preparing for this new technology-to-come by studying and researching its fundamentals and exploring the possibilities it offers. This process helps us gain unique knowledge on the mixed field of mechatronics, robotics and artificial intelligence. Future transportation can be safe, easy and sustainable without compromises.</p>"},{"location":"dataset/jkk_dataset_01/#leaf-2022-03-18-gyorbag","title":"<code>leaf-2022-03-18-gyor.bag</code>","text":"<p>Size: <code>2.12 GB</code> </p> <p>Go to details</p> <p>Download from here or get it with <code>wget</code>:</p> <pre><code>wget https://laesze-my.sharepoint.com/:u:/g/personal/herno_o365_sze_hu/EVlk6YgDtj9BrzIE8djt-rwBZ47q9NwcbgxU_zOuBji9IA?download=1 -O leaf-2022-03-18-gyor.bag\n</code></pre> <p></p>"},{"location":"dataset/jkk_dataset_01/#leaf-2021-04-23-campusbag","title":"<code>leaf-2021-04-23-campus.bag</code>","text":"<p>Size: <code>3.37 GB</code> </p> <p>Go to details</p> <p>Download from here or get it with <code>wget</code>:</p> <pre><code>wget https://laesze-my.sharepoint.com/:u:/g/personal/herno_o365_sze_hu/EYl_ahy5pgBBhNHt5ZkiBikBoy_j_x95E96rDtTsxueB_A?download=1 -O leaf-2021-04-23-campus.bag\n</code></pre> <p></p>"},{"location":"dataset/jkk_dataset_01/#leaf-2021-07-02-zala-uni-trackbag","title":"<code>leaf-2021-07-02-zala-uni-track.bag</code>","text":"<p>Size: <code>1.16 GB</code> </p> <p>Go to details</p> <p>Download from here or get it with <code>wget</code>:</p> <pre><code>wget https://laesze-my.sharepoint.com/:u:/g/personal/herno_o365_sze_hu/EaUlnq2KcQBHkCLB52nuPtQBw-FXYby23VUuwk6jmVzJBA?download=1 -O leaf-2021-07-02-zala-uni-track.bag\n</code></pre> <p></p>"},{"location":"dataset/jkk_dataset_01/#leaf-2020-06-10-campusbag","title":"<code>leaf-2020-06-10-campus.bag</code>","text":"<p>Size: <code>2.36 GB</code> </p> <p>Go to details</p> <p>Download from here or get it with <code>wget</code>:</p> <pre><code>wget https://laesze-my.sharepoint.com/:u:/g/personal/herno_o365_sze_hu/ETGGWQ0z5FxDkj3vwsjRPJEBuMwnFavgEU9aF0ol4NlwDA?download=1 -O leaf-2020-06-10-campus.bag\n</code></pre>"},{"location":"dataset/jkk_dataset_02/","title":"Jkk dataset 02","text":"<p>The log data is in .mcap format, the standard logging format for <code>ROS 2</code>. <code>MCAP</code> is an open source container file format for multimodal log data. It supports multiple channels of timestamped pre-serialized data, and is ideal for use in pub/sub or robotics applications.</p>"},{"location":"dataset/jkk_dataset_02/#getting-started","title":"Getting started","text":""},{"location":"dataset/jkk_dataset_02/#download-the-mcap-bag-files","title":"Download the <code>mcap</code> (bag) files","text":"<p>Download every MCAP as a ZIP</p> <p>Download a sample MCAP</p> <p>You can instanly view the data in Foxglove Studio (Free, online or on ay platform).</p> <p></p> <p>One of the easiest way to getting started with the dataset is to look at the notebook examples:</p> <p>Open MCAP in python notebook</p>"},{"location":"dataset/jkk_dataset_02/#dataset-description","title":"Dataset description","text":"Route Name Description Terrain <code>nissan_zala_90_country_road_1</code> road section flat - no hills <code>nissan_zala_90_country_road_2</code> longer stretches of highway, slight bends, some roundabouts hilly road <code>nissan_zala_50_sagod</code> slightly winding roads with some sharper turns 1 slight uphill <code>nissan_zala_50_zeg_1</code> mostly going in one direction, interrupted by roundabouts, continuous going flat - no hills <code>nissan_zala_50_zeg_2</code> roundabouts, bends, stationary situations (due to traffic) flat - no hills <code>nissan_zala_50_zeg_3</code> square bends with parking flat - no hills <code>nissan_zala_50_zeg_4</code> winding flat - no hills <code>nissan_zala_90_mixed</code> dynamic, city and country road mostly flat, last about 10m hilly"},{"location":"dataset/jkk_dataset_02/#usage-in-ubuntu-windows-wsl","title":"Usage in Ubuntu / Windows WSL","text":""},{"location":"dataset/jkk_dataset_02/#install-mcap","title":"Install <code>mcap</code>:","text":"<pre><code>pip install mcap\n</code></pre>"},{"location":"dataset/jkk_dataset_02/#download-dataset-eg-to-mntcbagjkkds02","title":"Download dataset, e.g. to <code>/mnt/c/bag/jkkds02/</code>:","text":"<pre><code>cd /mnt/c/bag/jkkds02/\n</code></pre> <pre><code>wget https://laesze-my.sharepoint.com/:u:/g/personal/herno_o365_sze_hu/EVofDCG_ORZJh--XTVLFsFEBOUYB1eAbHAzdTVDdf19Y9g?download=1 -O jkkds02.zip\n</code></pre> <p>Make sure you have <code>unzip</code> (<code>sudo apt-get install unzip</code>) and:</p> <pre><code>unzip jkkds02.zip\n</code></pre>"},{"location":"dataset/jkk_dataset_02/#some-images","title":"Some images","text":""},{"location":"dataset/jkk_dataset_03/","title":"Jkk dataset 03","text":"<p>This dataset contains the raw data of naturalistic driving, utilized for Human-Like Behavior studies of Automated Vehicles (HLB4AV).</p>"},{"location":"dataset/jkk_dataset_03/#jkk_dataset_03zip","title":"<code>jkk_dataset_03.zip</code>","text":"<p>Download from here or get it with <code>wget</code>:</p> <pre><code>wget https://laesze-my.sharepoint.com/personal/igneczi_gergo_ferenc_hallgato_sze_hu/_layouts/15/onedrive.aspx?id=%2Fpersonal%2Figneczi%5Fgergo%5Fferenc%5Fhallgato%5Fsze%5Fhu%2FDocuments%2FDataset%2Fjkk%5Fdataset%5F03&amp;ga=1 -O leaf-2022-03-18-gyor.bag\n</code></pre> <p>The data contains information of 17 drivers, who were selected to have relevant driving experience. Dr001-Dr003 are professional drivers who have extra driving certificate. The following table shows the details of participants:</p> Driver ID Type Age Driving Experience Driving Frequency Milage per year 001 N-P 31 10+ 3 4 002 N-P 32 10+ 3 4 003 N-P 28 10+ 3 5 004 N-P 31 10+ 4 5 005 N-P 46 10+ 4 4 006 N-P 25 6-10 2 2 007 N-P 29 10+ 3 3 008 N-P 28 3-6 2 3 009 N-P 28 1-3 1 2 010 N-P 43 10+ 4 4 011 N-P 31 10+ 3 3 012 N-P 44 10+ 3 3 013 N-P 52 10+ 4 4 014 N-P 36 10+ 4 5 015 N-P 32 10+ 3 4 021 N-P 51 10+ 4 5 023 N-P 39 10+ 2 3 <p>Explanation to notations: - P: Professional, N-P: Non-Professional  - Driving Frequency: 1: few times a year, 2: few times a month, 3: few times a week, 4: every day. - Driving Milage per year: 1: 0-1000km, 2: 1000-3000km, 3: 5000-10000km, 4: 10000-25000km, 5: more than 25000km.</p> <p>The dataset uses the following coordinate system of the vehicle:</p> <p></p> <p>Even though the data is recorded considering only two dimensional movement, the Z axis is displayed to give the right explanation of the yaw rate signal. Always, positive direction of a rotational quantity means CCW direction.</p>"},{"location":"dataset/jkk_dataset_03/#reference-platform","title":"Reference Platform","text":"<p>Data was recorded using two different vehicle platforms.</p> <p>The reference platform is a dedicated test vehicle, equipped with multiple environment sensors, also with direct access to the CAN network of the vehicle. The type of the vehicle is a Volkswagen Golf VII Variant, with a 1.4 TSI engine and 7-shift automatic gearbox.</p> <p>There are various sensor devices in this vehicle: - Genesys ADMA Gen3 (DGPS), source: ADMA 3.0 Technical Documentation, Document revision: 1.9, Date: 02/2019. Device includes the sensing of vehicle kinematic states. - Bosch Second Generation Multi-Purpose Camera (MPC2.5), including lane edge detection. - Bosch Fourth Generation Radar sensor, including object detection in ego lane and the two neighbouring lanes. - CAN data, steering torque and steering angle values.</p> <p>Reference Platform was used for measurements with Driver 1, 2 and 3 (professional drivers).</p>"},{"location":"dataset/jkk_dataset_03/#test-platform","title":"Test Platform","text":"<p>The test platform is a vehicle which is used when nonprofessional drivers are measured. The test vehicle is a Skoda Octavia MK3, with automatic gearbox. The vehicle systems were not modified, and no driver-assistance function was activated during testing. This vehicle was only equipped with the Genesys ADMA Gen3 (DGPS) device. The lane position information was reconstructed from the static lane map and the localization of the vehicle.</p>"},{"location":"dataset/jkk_dataset_03/#offline-calculations","title":"Offline Calculations","text":""},{"location":"dataset/jkk_dataset_03/#static-lane-map","title":"Static Lane Map","text":"<p>Based on the reference measurements, the lane map of the test route was created. For this, the lane position provided by the video camera was used. The lane position accuracy has +/- 2cm, while the localization has accuracy of +/- 1 cm.</p> <p></p> <p>The camera provides information of the position of the lane edges at each sample time. The following information are provided: - lane position (\\(d\\)) - lane orientation (\\(\\Theta\\)) - lane curvature (\\(\\kappa\\)). These data are then interpolated to a resolution of 5 cm travel distance through the route, using MATLAB function spline. Also, the lane edge position are transformed to the global UTM coordinates considering the pose of the vehicle. In the end, the map data contains high resolution geometry of the lane edges and also the higher level geometrical quantities (orientation and curvature).</p>"},{"location":"dataset/jkk_dataset_03/#lane-reconstruction","title":"Lane Reconstruction","text":"<p>For the test platform, the static lane map information is transferred back to the vehicle coordinate frame at each time sample. This replaced the video camera information, therefore the lane position of the test vehicle is available, with an accuracy of +/- 3 cm. Unfortunately, the dynamic information (e.g., other objects in the lane) are not available for the test platform.</p>"},{"location":"dataset/jkk_dataset_03/#dash-cam-data","title":"Dash-cam data","text":"<p>For multiple drivers' data (currently noted by \"_withTraffic\" tag in the file name) a dash cam video is available. This video is not applicable to use for e.g., computer vision algorithms, but serve more as an informal source of traffic data. However, by manual labelling the following information were added to the data:  1. Oncoming traffic time to pass: when a vehicle appears on the camera image, a timer starts to count down from a certain initial value, until the vehicle passes the test vehicle. Initial value is 2.38 seconds for small vehicles (higher preceeding speed) and 3.38 seconds for trucks (lower preceeding speed). Times were calculated based on the experiments. When there is no oncoming traffic detected, time-to-pass is set to 2.38 seconds, reflecting the fact that a vehicle may turn up in any minute. Therefore, drivers are assumed to be prepared as there would already be oncoming traffic. When a vehicle is followed, the initial value is decreased to the half for both types of vehicles. 2. Oncoming traffic type: 0: no oncoming traffic, 1: small vehicle, 2: truck and 3: convoy.</p> <p>An example of a convoy, passing the ego vehicle is shown here:</p> <p></p> <p>The same scenario on the dash cam video (snippets cut by hand):</p> <p></p> <p>Please be noted, that this information is added manually, therefore not suitable for quantitative evaluation, only qualitative!</p>"},{"location":"dataset/jkk_dataset_03/#summary-of-signals","title":"Summary of Signals","text":"Signal Name Description Unit Range Availability Source VelocityX Longitudinal velocity of the vehicle m/s 0 - 40 both platforms ADMA SteeringTorque Torque applied by the driver on the steering wheel Nm +/-3 reference platforms CAN LaneOrientation Orientation of the mid-lane in the ego frame (positive: CW, negative: CCW) rad +/- 0.1 both platforms Camera LaneEdgePositionRight Position of the lane edge of the ego lane on right side (positive: left, negative: right) m +/- 2 both platforms Camera LaneEdgePositionLeft Position of the lane edge of the ego lane on left side (positive: left, negative: right) m +/- 2 both platforms Camera LaneCurvature Curvature of the lane in the vehicle position 1/m +/- 0.005 both platforms Camera ObjectDistanceFront Distance of the vehicle in the ego lane (if no vehicle is present, value is zero) m 0-250 m reference platforms Radar ObjectVelocityFront Absolute velocity of the vehicle in the ego lane (if no vehicle is present, value is zero) m/s 0-40 reference platforms Radar ObjectAccelerationFront Absolute acceleration of the vehicle in the ego lane (if no vehicle is present, value is zero) m/s^2 +/- 10 reference platforms Radar YawRate Yawrate of the vehicle around the Z axis rad/s +/- 0.1 both platforms ADMA AccelerationX Longitudinal acceleration of the vehicle m/s^2 +/- 10 both platforms ADMA AccelerationY Longitudinal acceleration of the vehicle m/s^2 +/- 10 both platforms ADMA RoadWheelAngleFront Road-wheel-angle of the front wheels rad +/- 0.1 reference platforms CAN GPS_time Global GPS time ms - both platforms ADMA GPS_status Global GPS status enum 1: GPS, 2: RTK float, 4: RTK_course, 8: RTK_Fixed both platforms ADMA LongPos_abs Global longitudinal position of the vehicle \u00b0 - both platforms ADMA LatPos_abs Global lateral position of the vehicle \u00b0 - both platforms ADMA Relative_time Relative time stamp to the beginning of the measurement s - both platforms ADMA <p>The data is recorded in every 10 ms. Localization information is available at every 50 ms.</p>"},{"location":"dataset/jkk_dataset_03/#github-repo","title":"GitHub repo","text":"<p>The following repository contains algorithms for driver model analysis and prototypes for ADAS functions endowed with human-like features.</p> <p>github.com/gfigneczi1/hlb</p> <p>The following scripts are used for the data process:</p> <ul> <li>Lane reconstruction from reference data:     Run segmentor profile \"MapValidation\" and evaluator profile \"MapValidation\", based on this description: </li> </ul> <p>Evaluation description </p> <p>Place the raw mat files (without the map data) into the _temp folder.</p> <ul> <li>Traffic information for which dash-cam video is available:</li> </ul> <p>Traffic label procession </p> <p>In this case, you shall define the path of the corresponding xlsx file that contains the relevant traffic information.</p> <ul> <li>Standardize names for the proper storing:</li> </ul> <p>Standardize names </p> <ul> <li>Merge data for drivers where multiple short runs are available:</li> </ul> <p>Merge data </p> <p>For this script, you shall also store all unmerged data in the _temp folder.</p>"},{"location":"home/about/","title":"About","text":"<ul> <li>Gy\u0151r, Hungary, Europe</li> <li>Sz\u00e9chenyi University IS Building 2nd floor</li> <li>+36 96 613 680</li> <li>jkk@sze.hu</li> <li>jkk.sze.hu</li> <li>youtube.com/jkk-sze-research</li> </ul>"},{"location":"home/social/","title":"Social","text":"<ul> <li>youtube.com/jkk-sze-research</li> <li>instagram.com/jkk.sze</li> <li>youtube.com/szenergyteam</li> <li>instagram.com/szenergyteam</li> </ul>"},{"location":"home/videos/","title":"Videos","text":""},{"location":"introduction/","title":"Introduction","text":"<p>Systemically, autonomous driving can be described as the sum of the following sub-functions:</p> <p></p> <p>Literature: [TU M\u00fcnchen], [Autoware], [University of Texas at Dallas], [ApolloAuto]</p> <ol> <li>Sensing: deals with the production of raw data at the driver-program level, for example, producing an image from a camera sensor for the system.</li> <li>Perception: a more complex process that extracts important information for the system from the input data, such as recognizing a pedestrian from a camera image.</li> <li>Planning: plans the vehicle's path or trajectory at a global level (beyond the sensor's detection range) and at a local level (within the sensor's detection range).</li> <li>Control: follows the path or trajectory produced by the planner, using controllers like Pure-Pursuit, Model Predictive Control (MPC), etc.</li> <li>Actuation: issues the reference signals (steering angle, gas, and brake pedal) produced by the system (e.g., via CAN bus system).</li> </ol> <p>The above classification can also be observed in larger systems, such as the Autoware summary system diagram. The sense-think-act paradigm is also known in robotics. Here, thinking (think) encompasses perception, planning, and somewhat control.</p> <p>Let's look at an illustration for each sub-task on one of our university's vehicles with autonomous functions at the Zalaegerszeg test track:</p> <p></p>"},{"location":"introduction/#autonomous-driving-vs-driver-assistance","title":"Autonomous Driving vs. Driver Assistance","text":""},{"location":"introduction/#sae-levels","title":"SAE Levels","text":"<p>The SAE J3016 standard defines the division of labor between the driver and the vehicle system.</p> <ul> <li>Level 0: L0 - No Driving Automation, i.e., the complete absence of driving automation.</li> <li>Level 1: L1 - Driver Assistance, where certain driver assistance functions can already influence the vehicle's movement.</li> <li>Level 2: L2 - Partial Driving Automation, where the car performs maneuvers in both directions, but supervision is the driver's responsibility.</li> <li>Level 3: L3 - Conditional Driving Automation, where the driver must take over control if the vehicle requests it.</li> <li>Level 4: L4 - High Driving Automation, where the vehicle takes full responsibility, but it can still be used in traditional mode.</li> <li>Level 5: L5 - Full Driving Automation, Autonomous, where the vehicle takes full responsibility, and it cannot be used with a traditional steering wheel.</li> </ul> <p>However, the standard does not describe the \"scope\" or area limitations of the vehicle. For example, an autonomous airport bus cannot leave the airport area. Similarly, Waymo, Cruise, or Zoox robotaxis typically operate in smaller regions, roughly equivalent to 1-2 counties in Hungary. This is also known as \"geofencing.\"</p>"},{"location":"introduction/#examples","title":"Examples","text":"<p>As we have seen, technologies similar to those in autonomous (L5) vehicles can also be found at driver assistance (L2/L3) levels. However, the complexity of the task is entirely different.</p> Level: L2/L3 L5 Name: Automated, driver assistance Autonomous, self-driving Typical sensors: Camera, radar Camera, radar, LIDAR, GPS Examples: Tesla, Audi, BMW Waymo, Zoox, Cruise"},{"location":"introduction/#autonomous-vehicles-and-robots","title":"Autonomous Vehicles and Robots","text":"Robots Robotaxis Nuro, Segway, Turtlebot, Clearpath, Starship Zoox, Cruise, Waymo, Navya, Sensible4 <p>Let's look at an example that showcases the Zoox autonomous robotaxi in action:</p>"},{"location":"introduction/#lines-of-code","title":"Lines of Code","text":"<p>The following diagram shows that a modern average (driver-assisted) passenger car is a result of highly complex software engineering work, and it is clear that future autonomous vehicles will require even more complex solutions.</p> <pre><code>---\nconfig:\n    themeVariables:\n        xyChart:\n            backgroundColor: transparent\n            titleColor: \"#AAAAAA\"\n            xAxisLabelColor: \"#43AEC5\"\n            yAxisLabelColor: \"#43AEC5\"\n            xAxisLineColor: \"#AAAAAA\"\n            yAxisLineColor: \"#AAAAAA\"\n            plotColorPalette: \"#43AEC5\"\n---\nxychart-beta\n\n    title \"Millions of Lines of code (LOC) in 2024\"\n    x-axis [\"Avg. iPhone app\",\"World of warcraft\", \"Linux kernel\", Facebook, \"Avg. new vehicle\"]\n    y-axis \"Average number of lines of codes (million)\" 0 --&gt; 210\n    bar [0.04, 5.5, 30, 62, 200]\n</code></pre> <p>Source: statista, informationisbeautiful</p>"},{"location":"introduction/#university-vehicles","title":"University Vehicles","text":"<p>Sz\u00e9chenyi Istv\u00e1n University fortunately has a relatively large number of modified passenger cars and robots. These are the following:</p>"},{"location":"introduction/#lexus-rx450h-my2016-car","title":"Lexus RX450h MY2016+ (car)","text":"<p>Sensors: Ouster OS2-64 LIDAR, 2x OS1-32 LIDAR, Stereolabs Zed2i depth camera. More information here.</p> Lexus"},{"location":"introduction/#nissan-leaf-car","title":"Nissan Leaf (car)","text":"<p>Sensors: 2x Ouster OS1-64 LIDAR, 2x Velodyne VLP16 LIDAR, SICK LMS111 LIDAR, Stereolabs Zed / Zed2 depth camera. More information here.</p> Nissan Leaf"},{"location":"introduction/#szenergy-car","title":"Szenergy (car)","text":"<p>Sensors: Ouster OS1-128 LIDAR, SICK LMS111 LIDAR, Stereolabs Zed2i depth camera. More information here.</p> Szenergy <p>The Szenergy team achieved first place in 2023 and second place before that at Europe's largest autonomous driving competition, the Shell Eco-marathon Autonomous Urban Concept (AUC) competition. The podium finishes in these years were as follows:</p> \ud83c\udfc6 2022 2023 2024 1. DTU Road Runners, Technical University of Denmark (<code>Denmark</code>) SZEnergy Team, Sz\u00e9chenyi Istv\u00e1n University (<code>Hungary</code>) SZEnergy Team, Sz\u00e9chenyi Istv\u00e1n University (<code>Hungary</code>) 2. SZEnergy Team, Sz\u00e9chenyi Istv\u00e1n University (<code>Hungary</code>) Team EVA,  Hogeschool Van Amsterdam University (<code>Netherlands</code>) H2politO,Molecole Urbane Politecnico Di Torino University (<code>Italy</code>) 3. DNV Fuel Fighter, Norwegian University of Science And Technology (<code>Norway</code>) H2politO,Molecole Urbane Politecnico Di Torino University (<code>Italy</code>) Team EVA,  Hogeschool Van Amsterdam University (<code>Netherlands</code>) <p>Source: shellecomarathon.com</p>"},{"location":"introduction/#f110-ackermann-robot-roboworks-rosbot-mini-ackermann","title":"F1/10 (Ackermann robot) / Roboworks Rosbot mini Ackermann","text":"<p>The F1/10 competition is an autonomous vehicle competition where participants build and program 1/10 scale Formula 1 car models to autonomously navigate a race track. The goal is for the vehicles to complete the track as quickly and safely as possible while avoiding obstacles and other cars. During the competition, participants can test their knowledge of robotics, artificial intelligence, and machine learning. The Roboworks robot is very similar in size and sensor setup to the F1/10 vehicle. F1tenth vehicle description here.</p>"},{"location":"introduction/#segway-loomo-robot","title":"Segway Loomo (robot)","text":"<p>Description here.</p>"},{"location":"introduction/#husarion-rosbot-2-pro-robot","title":"Husarion ROSbot 2 Pro (robot)","text":"<p>Description here.</p>"},{"location":"introduction/#robotis-ros-turtlebot-3-robot","title":"Robotis ROS TurtleBot 3 (robot)","text":"<p>Description here.</p>"},{"location":"introduction/#dji-matrice-600-pro-drone-robot","title":"DJI Matrice 600 Pro drone (robot)","text":"<p>Sensors: Ouster OS1-64 LIDAR. More information here.</p> <p></p>"},{"location":"introduction/copilot/","title":"Copilot","text":"<p>GitHub Copilot is a programming assistant tool: github.com/features/copilot. It is based on AI technologies, similar to ChatGPT. It is particularly useful for beginner programmers but can also be a great help for experienced developers. GitHub Copilot assists developers in writing, completing, and correcting code, suggests coding patterns and structures, and helps developers solve problems faster.</p> <p>GitHub Copilot supports multiple programming languages, making it useful for various development tasks, such as robotics development, database management, mobile application development, and many other areas.</p> <p>The tool integrates into development environments like Visual Studio Code and can be used directly within the application.</p> <p>By default, it is a paid service, but it is free with student access: education.github.com/benefits.</p> <p> </p> <p>Let's see Copilot in action:</p> <p></p>"},{"location":"introduction/copilot/#getting-github-copilot-for-sze-students","title":"Getting GitHub Copilot for SZE Students","text":"<p>Using GitHub Copilot is almost essential for completing the course. Through the GitHub Student Developer Pack, students can access GitHub Copilot for free. Details of the Developer Pack and registration can be found here: education.github.com/pack. As a student, the simplest way to get GitHub Copilot is by following these steps:</p> <ul> <li>Register for Student Office 365, @hallgato.sze.hu email, 5GB OneDrive storage, Office Online, and Office 365 ProPlus desktop applications: office365.sze.hu</li> <li>Register on GitHub or, once the @hallgato.sze.hu email is active, set it as a secondary or primary email address in your GitHub account.</li> <li>Register for the GitHub Student Developer Pack: education.github.com/pack</li> <li>After a few days, GitHub Copilot will be available in Visual Studio Code. Search for Copilot and Copilot chat among the extensions, and simply log in to the VS Code GitHub account.</li> </ul>"},{"location":"introduction/linux/","title":"Linux, Git","text":"<p>The description contains basic Linux knowledge.</p> <p></p> <p>In Linux (in this description, understand Ubuntu, Raspbian), most sessions can or should be executed from the terminal. This tutorial helps to get acquainted with the basics of the Linux terminal.</p> <p>Danger</p> <p>It is important that instead of the usual <code>ctrl</code>+<code>v</code>, <code>ctrl</code>+<code>c</code>, here <code>ctrl</code>+<code>shift</code>+<code>v</code>, <code>ctrl</code>+<code>shift</code>+<code>c</code> works. The <code>ctrl</code>+<code>c</code> (interrupt from the keyboard) can be used here to terminate a ROS node (program).</p>"},{"location":"introduction/linux/#recommended-terminal-programs","title":"Recommended Terminal Programs","text":"<p>Several programs can be chosen to access the text command line. For ROS/ROS2, the following might be the best choices.</p>"},{"location":"introduction/linux/#windows-terminal","title":"Windows Terminal","text":"<p>As the name suggests, this solution is relevant on Windows with WSL. The advantage is that we can use multiple Linux distributions in one place, even with the Windows command line. With <code>Ctrl-Shift-P</code> key combinations, then the Split down, Split left commands, we can split the terminal similarly:</p> <p></p> <p>The Windows Terminal release page offers a downloadable installer or a portable version in zip format. For portable use, after extraction, an empty <code>.portable</code> file must be placed. This way, we can use it with our usual settings even on a USB pendrive. Such a portable version can be found in the computer labs on the <code>K:\\</code> drive (<code>\\\\fs-kab.eik.sze.hu\\C100\\kozos\\GKNB_AUTM078_Autonomous_robots_and_vehicles_programming</code>).</p>"},{"location":"introduction/linux/#terminator","title":"Terminator","text":"<p>A terminal understood on Linux, but it needs to be installed.</p> <pre><code>sudo apt update\nsudo apt install terminator\n</code></pre> <p>Terminator allows you to split the current window with the <code>Ctrl-Shift-O</code> and <code>Ctrl-Shift-E</code> key combinations. <code>Ctrl-Shift-W</code> closes the active window.</p> <p></p>"},{"location":"introduction/linux/#vs-code-terminal","title":"VS Code Terminal","text":"<p>The integrated terminal of the development environment works on both Windows and Linux.</p> <p></p> <p></p>"},{"location":"introduction/linux/#important-terminal-commands","title":"Important Terminal Commands","text":""},{"location":"introduction/linux/#previous-commands","title":"Previous Commands","text":"<ul> <li><code>Up Arrow \ud83d\udd3c</code> or <code>Down Arrow \ud83d\udd3d</code> - Access the most recent commands.</li> <li><code>Ctrl+R</code> key combination allows you to search for previous commands in reverse chronological order.</li> <li><code>Ctrl+Shift+R</code> key combination allows you to search for previous commands in chronological order.</li> </ul> <p>Instead of the usual <code>ctrl</code>+<code>v</code>, <code>ctrl</code>+<code>c</code>, here <code>ctrl</code>+<code>shift</code>+<code>v</code>, <code>ctrl</code>+<code>shift</code>+<code>c</code> works. The <code>ctrl</code>+<code>c</code> can be used to terminate a ROS node (program).</p> <p></p>"},{"location":"introduction/linux/#auto-completion","title":"Auto-completion","text":"<ul> <li><code>Tab</code> key can be used to complete the started commands.</li> <li><code>Tab Tab</code> key combination will list all possible commands.</li> </ul>"},{"location":"introduction/linux/#screen-clearing","title":"Screen Clearing","text":"<ul> <li><code>Ctrl+L</code> key can be used to clear the previous texts, making the terminal more readable.</li> </ul>"},{"location":"introduction/linux/#navigating-between-directories","title":"Navigating Between Directories","text":"<ul> <li><code>cd</code>: enter a specific directory/folder</li> <li>e.g., <code>cd ~/ros2_ws/src</code>, <code>cd ../..</code></li> <li><code>ls</code>: list directories, files</li> <li><code>mkdir</code>: create a directory</li> <li><code>pwd</code>: print working directory</li> <li><code>cp</code>: copy files (<code>cp /path/to/file /path/to/destination/</code>, <code>cp -r /path/to/directory /path/to/destination/</code>)</li> <li><code>mv</code>: move (relocate) or rename a file or directory (<code>mv /path/to/file new_file_name</code>, <code>mv /path/to/file /new/path/to/file</code>)</li> <li><code>rm</code>: delete files (<code>rm /path/to/file</code>, <code>rm -r /path/to/files/and/directories</code>) The <code>rm -r</code> command will delete everything at the specified location.</li> <li><code>rmdir</code>: delete an empty directory</li> <li><code>chmod</code>: (change mode) used to change the access permissions of files/directories. This can be done using character switches (r, w, etc.) or octally (numbers).</li> <li>e.g., <code>chmod +x my_python_node.py</code>: add execute permission</li> <li>e.g., <code>chmod 777 everything.py</code>: add all permissions</li> </ul> <p>#### <code>chmod</code></p> N Sum <code>rwx</code> Permission <code>7</code> 4(r)+ 2(w) + 1(x) <code>rwx</code> read, write and execute <code>6</code> 4(r)+ 2(w) <code>rw-</code> read and write <code>5</code> 4(r)+ 1(x) <code>r-x</code> read and execute <code>4</code> 4(r) <code>r--</code> read only <code>3</code> 2(w)+ 1(x) <code>-wx</code> write and execute <code>2</code> 2(w) <code>-w-</code> write only <code>1</code> 1(x) <code>--x</code> execute only <code>0</code> 0 <code>---</code> none"},{"location":"introduction/linux/#directories","title":"Directories","text":"Location Explanation <code>/</code> The starting point of the directory tree, root <code>/boot</code> System boot, bootloader <code>/bin</code> Executable commands, binaries <code>/sbin</code> Administrator commands, superuser/system bin <code>/lib</code> Shared system libraries needed for startup, modules, drivers <code>/dev</code> Devices, such as USB (<code>ttyUSB0</code>) <code>/etc</code> Configuration files, local startup commands, passwords, network settings, etc. <code>/home</code> Contains each user's personal directory. For example, if logged in as <code>sanyi</code>, <code>/home/sanyi</code> contains our files. <code>/home/sanyi/Desktop</code>, or simply <code>~/Desktop</code>, is the content of our desktop. <code>/mnt</code> Mount point for mounted peripherals, filesystems <code>/proc</code> Process information <code>/root</code> The root user's directory <code>/tmp</code> Temporary files <code>/usr</code> Universal system resources, applications, system tools <code>/var</code> Variable data, such as print jobs, emails"},{"location":"introduction/linux/#version-control","title":"Version Control","text":"<ul> <li><code>git clone</code>: clone a git repository</li> <li><code>git config --global user.name \"Sanyika\"</code>: set username</li> <li><code>git config --global user.email \"sanyika@gggmail.com\"</code>: set email</li> <li><code>git init</code>: initialize a local repository</li> <li><code>git add &lt;file&gt;</code>: add a file</li> <li><code>git status</code>: check current status</li> <li><code>git commit -m \"My beautiful commit\"</code>: commit with a message</li> <li><code>git push</code>: push changes</li> <li><code>git pull</code>: pull changes</li> <li><code>git branch &lt;new_branch_name&gt;</code>: create a new branch</li> <li><code>git checkout &lt;branch_name&gt;</code>: switch to a branch</li> <li><code>git checkout -- .</code>: Discard all unstaged changes locally. In VS Code, this is similar to the \"discard all changes\" command. (In newer git versions, <code>git restore .</code> works similarly.)</li> <li><code>git merge &lt;branch_name&gt;</code>: merge a branch into the current branch</li> </ul> <p>Tip</p> <p>Most operations can be performed in VS Code without using the terminal. Read more about it here.</p> <p></p> <p>Source: link</p>"},{"location":"introduction/linux/#text-files","title":"Text Files","text":"<ul> <li><code>wget</code>: download web content from the terminal</li> <li><code>cat</code>: display the content of a file</li> <li><code>touch</code>: create a text file</li> <li>e.g., <code>touch hello.txt</code></li> <li><code>echo</code>: print or write to a file (<code>&gt;&gt;</code> operator). If the file does not exist, it creates it (<code>touch</code>).</li> <li>e.g., <code>echo \"hello\" &gt;&gt; hello.txt</code> </li> <li>e.g., <code>echo \"n = 5; print('\\n'.join(':D ' * i for i in range(1, n + 1)))\" &gt;&gt; hello.py</code> </li> <li>e.g., <code>ros2 topic list &gt;&gt; hello.txt</code> </li> <li>e.g., <code>ros2 topic echo --once /scan &gt;&gt; hello.txt</code> </li> <li><code>find</code>: search for files, e.g., <code>find ~/ros2_ws/src/ -name *.txt</code> searches for all <code>txt</code> files in the <code>~/ros2_ws/src</code> directory.</li> <li><code>nano</code>: text editor: simple, terminal-based</li> <li><code>code</code>: text editor: GUI, VS Code</li> <li>e.g., <code>code .</code> opens the current folder</li> <li>e.g., <code>code ~/.bashrc</code> opens the <code>~/.bashrc</code> file for editing</li> <li><code>colcon</code>: wrapper for <code>cmake</code> and <code>make</code> commands for easier use, more on this later</li> </ul>"},{"location":"introduction/linux/#installation","title":"Installation","text":"<ul> <li><code>sudo apt install</code> or <code>sudo apt-get install</code>: install software using the package manager, Advanced Packaging Tool (APT). </li> <li>e.g., <code>sudo apt install tree mc</code> - install tree and mc programs </li> <li><code>sudo</code>: (Superuser do) Allows executing commands as an administrator or another user.</li> <li><code>sudo apt update</code>: update package index, recommended before installing (<code>apt install</code>) new software.</li> <li><code>sudo apt upgrade</code>: upgrade installed packages</li> <li><code>apt list</code>: list all installed packages</li> <li>e.g., <code>apt list | grep ros</code>: filter only ROS-related packages</li> </ul>"},{"location":"introduction/linux/#additional-useful-tools","title":"Additional Useful Tools","text":""},{"location":"introduction/linux/#navigation","title":"Navigation","text":"<ul> <li><code>Ctrl + a</code> or <code>home</code>: Move to the beginning of the line</li> <li><code>Ctrl + e</code> or <code>end</code>: Move to the end of the line</li> <li><code>Ctrl + \u25c0</code> / <code>Ctrl + \u25b6</code>: Move to the previous/next word</li> </ul>"},{"location":"introduction/linux/#grep","title":"<code>grep</code>","text":"<ul> <li><code>grep</code>: (Global \\ Regular Expression \\ Print) search within files or command outputs</li> <li>e.g., <code>grep 'ROS' ~/.bashrc</code>: list lines containing <code>ROS</code> in the <code>bashrc</code> file</li> <li>e.g., <code>ros2 topic list | grep pose</code>: list all topics containing the string <code>pose</code></li> </ul>"},{"location":"introduction/linux/#ssh","title":"<code>ssh</code>","text":"<ul> <li><code>ssh</code>: (Secure Shell Protocol) allows remote terminal login to Linux machines</li> <li>e.g., <code>ssh nvidia@192.168.1.5</code>: login to the machine with the specified user and IP address</li> <li>e.g., <code>ssh user01@computer4 -X</code>: login with <code>-X</code> to use X window, so windows appear on our machine but are hosted on the remote machine</li> <li>e.g., <code>ssh laptop@192.168.0.2 touch hello.txt</code>: create a file on the specified machine, works with other commands as well</li> </ul>"},{"location":"introduction/linux/#frequently-used-commands","title":"Frequently Used Commands","text":"<ul> <li><code>ps</code> provides information about running processes, e.g., <code>ps -A | grep ros</code> or <code>ps -eo pid,cmd | grep ros2</code></li> <li><code>df -h</code> (disk filesystem, human readable) provides information about the filesystem status </li> </ul> <p><code>ssh</code> typically requires a password, but if you trust a machine, you can save the private-public key pair to avoid this, for example like this.</p>"},{"location":"introduction/linux/#rsync-network-copy","title":"<code>rsync</code> Network Copy","text":"<p>Copying between networked machines (remote sync), for example, copying from an Nvidia Jetson embedded computer to our own machine's <code>/mnt/c/bag/</code> folder with a progress bar looks like this:</p> <p><pre><code>rsync -avzh --progress /mnt/kozos/measurement_files/lexus-2023-07-18-campus.mcap  /mnt/c/temp/\n</code></pre> <pre><code>rsync -avzh --progress nvidia@192.168.1.5:/mnt/storage_1tb/2023-07-02/ /mnt/c/bag/2023-07-02/\n</code></pre></p>"},{"location":"introduction/linux/#scp-network-copy","title":"scp Network Copy","text":"<p>Copying between networked machines (an alternative to rsync). Unfortunately, the progress bar does not appear on all systems:</p> <pre><code>scp /mnt/kozos/measurement_files/lexus3sample02.mcap  /mnt/c/temp/\n</code></pre>"},{"location":"introduction/linux/#screen","title":"<code>screen</code>","text":"<p>Manages virtual terminals, for example:</p> <pre><code>screen -m -d -S roscore bash -c roscore\nscreen -m -d -S campfly bash -c 'roslaunch drone_bringup campus_fly.launch'\nscreen -m -d -S rviz1 bash -c 'rosrun rviz rviz'\n</code></pre> <ul> <li>list screen: <code>screen -ls</code></li> <li>restore screen:  <code>screen -r roscore</code> / <code>screen -r campfly</code> /  <code>screen -r rviz1</code></li> <li>detach: <code>Ctrl-a</code> + <code>Ctrl-d</code></li> <li>kill: <code>killall -9 screen</code> and <code>screen -wipe</code></li> </ul>"},{"location":"introduction/linux/#mc-file-manager","title":"<code>mc</code> File Manager","text":"<p>GNU Midnight Commander (<code>mc</code>), a file manager inspired by Norton Commander:</p> <p></p>"},{"location":"introduction/linux/#nmtui","title":"<code>nmtui</code>","text":"<p>The <code>nmtui</code> (Network Manager Text User Interface) is a terminal-based Wifi / Ethernet / Network configurator.</p> <p></p>"},{"location":"introduction/linux/#nano-text-editor","title":"<code>nano</code> Text Editor","text":"<p>Terminal-based text editor. After editing, <code>Ctrl+X</code> to exit, then press <code>Y</code> to save the file.</p> <p></p>"},{"location":"introduction/linux/#htop-top","title":"<code>htop</code> / <code>top</code>","text":"<p><code>htop</code> is an interactive process viewer command (similar to the functionality of the Windows task manager), which displays and monitors running processes on the system. Memory and CPU usage can be read in detail per process, and there is also the possibility to use <code>kill</code>.</p> <p></p>"},{"location":"introduction/linux/#bashrc-file","title":"<code>~/.bashrc</code> File","text":"<p>The <code>bashrc</code> file (the <code>~</code> means it is located in the <code>/home/user1/</code> folder for user <code>user1</code>, and the <code>.</code> means it is a hidden file) is a file that runs every time a terminal is started. So, for example, if we write a command like <code>echo \"hello\"</code> in it, it will print a hello message every time the terminal starts. It can be edited using <code>nano</code>/<code>VS Code</code> text editors:</p> <p><pre><code>nano ~/.bashrc\ncode ~/.bashrc\n</code></pre> Important environment variables for us, for example: <pre><code>export ROS_DOMAIN_ID=4\nexport ROS_LOCALHOST_ONLY=1\nexport GAZEBO_MODEL_PATH=$GAZEBO_MODEL_PATH:/opt/ros/humble/share/turtlebot3_gazebo/models\nexport TURTLEBOT3_MODEL=waffle\nsource /opt/ros/humble/setup.bash\nsource ~/ros2_ws/install/setup.bash\n</code></pre> After modifying the <code>bashrc</code> file, there is no need to open a new terminal if we issue the following command:</p> <pre><code>source ~/.bashrc\n</code></pre>"},{"location":"introduction/linux/#ros1","title":"ROS1","text":"<p>!!! tip This chapter discusses the old ROS 1 environment variables, the new ROS 2 environment variables are covered in the next chapter.</p> <p>We can print the environment variables using <code>echo</code> or <code>printenv</code>, for example: <pre><code>echo $ROS_MASTER_URI\nprintenv ROS_MASTER_URI\n\nhttp://192.168.1.5:11311\n</code></pre> <pre><code>echo $ROS_IP\nprintenv ROS_IP\n\n192.168.1.10\n</code></pre></p>"},{"location":"introduction/linux/#ros-2","title":"ROS 2","text":"<p>!!! important \"ROS 2 Chapter\" This is the new chapter containing ROS 2.</p> <p>We can print the environment variables using <code>echo</code> or <code>printenv</code>, for example:</p> <p><pre><code>echo $ROS_DISTRO\nprintenv ROS_DISTRO\n\nhumble\n</code></pre> <pre><code>echo $AMENT_PREFIX_PATH\nprintenv AMENT_PREFIX_PATH\n\n/opt/ros/humble\n</code></pre> <pre><code>printenv | grep -i ROS\n\nROS_VERSION=2\nROS_PYTHON_VERSION=3\nROS_DISTRO=humble\n</code></pre></p>"},{"location":"introduction/linux/#gazebo-and-wsl","title":"Gazebo and WSL","text":"<p>When using the Gazebo simulator and WSL, an issue may occur, which can be fixed by setting a simple environment variable. In the <code>~/.bashrc</code> file, set the following:</p> <pre><code>export LIBGL_ALWAYS_SOFTWARE=1 ### GAZEBO IGNITION \n</code></pre> <p>After opening a new terminal or running <code>source</code>, the command <code>echo $LIBGL_ALWAYS_SOFTWARE</code> will print <code>1</code>.</p>"},{"location":"introduction/linux/#displaying-branch-in-linux-bash","title":"Displaying Branch in Linux Bash","text":"<p>*Optional but useful: Find and modify the following part in the <code>~/.bashrc</code> file.</p> <p>(Using VS Code, the command is: <code>code ~/.bashrc</code>)</p> <pre><code>if [ \"$color_prompt\" = yes ]; then\n    PS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[00m\\]\\$ '\nelse\n    PS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w\\$ '\nfi\nunset color_prompt force_color_prompt\n</code></pre> <p>Once found, replace it with the following:</p> <p><pre><code>parse_git_branch() {\n git branch 2&gt; /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/(\\1)/'\n}\nif [ \"$color_prompt\" = yes ]; then\n PS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[01;31m\\]$(parse_git_branch)\\[\\033[00m\\]\\n\\$ '\nelse\n PS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w$(parse_git_branch)\\\\n$ '\nfi\n</code></pre> or without starting a new line:</p> <pre><code>parse_git_branch() {\n git branch 2&gt; /dev/null | sed -e '/^[^*]/d' -e 's/* \\(.*\\)/(\\1)/'\n}\nif [ \"$color_prompt\" = yes ]; then\n PS1='${debian_chroot:+($debian_chroot)}\\[\\033[01;32m\\]\\u@\\h\\[\\033[00m\\]:\\[\\033[01;34m\\]\\w\\[\\033[01;31m\\]$(parse_git_branch)\\[\\033[00m\\]\\$ '\nelse\n PS1='${debian_chroot:+($debian_chroot)}\\u@\\h:\\w$(parse_git_branch)\\$ '\nfi\n</code></pre> <p>Save, then after <code>source ~/.bashrc</code>, or opening a new terminal, a bash similar to the following will greet us in a directory containing a git repository:</p> <p></p> <p>Source:  Ubuntu magyar dokument\u00e1ci\u00f3s projekt <code>CC by-sa 2.5</code>, \u00d3buda University <code>CC BY-NC-SA 4.0</code></p>"},{"location":"introduction/practice/","title":"Introduction Practice","text":"<p>During the practice, we will get to know the characteristic properties of autonomous vehicles and the characteristics of the recorded data.</p>"},{"location":"introduction/practice/#foxglove-studio","title":"Foxglove Studio","text":"<p>As an introduction, let's look at the characteristic data of an autonomous vehicle. As an example, it is advisable to examine the data recorded with one of the university's vehicles. We will use Foxglove Studio, as it is available without installation or as a ~150MB installable file, and it can visualize the data that is important to us. The examined data will show a similar picture:</p> <p> </p> <p>In class, download the visualized rosbag <code>.bag</code> / <code>.mcap</code> file and the Foxglove Studio layout from the <code>K:\\</code> drive (<code>\\\\fs-kab.eik.sze.hu\\C100\\kozos\\GKNB_AUTM078_Autonomous_robots_and_vehicles_programming</code>), or at home using the green button:</p> <p>Download MCAP  553 MB Download Layout </p> <p><pre><code>cd /mnt/c/temp\nmkdir /mnt/c/temp # if it doesn't exist\nrsync -avzh --progress /mnt/kozos/measurement_files/lexus3-2024-04-05-gyor.mcap /mnt/c/temp/\nrsync -avzh --progress /mnt/kozos/measurement_files/lexus01foxglove.json /mnt/c/temp/\n</code></pre> !!! tip Additional example data can be downloaded from the https://jkk-research.github.io/dataset page. `</p>"},{"location":"introduction/practice/#introduction-to-foxglove","title":"Introduction to Foxglove","text":"<p>While the <code>.mcap</code> is downloading, let's briefly introduce the Foxglove Studio program. Foxglove Studio is an open-source tool for visualizing and debugging robotics data. Specifically, it was open-source up to <code>v1.87.0</code>, and from <code>v2.0.0</code> it is free to use but closed-source. It is available in several ways:</p> <ul> <li>as a standalone desktop application</li> <li>accessible in a browser</li> <li>self-hosted on your own domain</li> </ul> <p>Native robotics tools (such as parts of the ROS ecosystem) are generally only supported on Linux systems, but the Studio desktop application works on Linux, Windows, and macOS. Even if the ROS stack runs on another operating system, the Studio can communicate with the robot seamlessly.</p> <p>The Studio offers rich visual elements and debugging panels - from interactive charts, 3D visual elements, camera images, and diagnostic data streams. Whether it's real-time robot tracking or debugging in a <code>.bag</code> / <code>.mcap</code> file, these panels help solve various common robotics tasks.</p> <p>These panels can then be configured and assembled into custom layouts to suit the unique needs and workflows of the project.</p>"},{"location":"introduction/practice/#description-of-the-universitys-nissan-measurement-data","title":"Description of the University's Nissan Measurement Data","text":"<p>In the ROS system (but also in other similar robotics solutions), individual data are published in topics. A topic can be, for example, the output of a sensor, the input of a controller, a visualization marker, etc. Topics have types, there are many predefined types, but we can create our own if these are not enough. For example, a few predefined types:</p> <ul> <li><code>sensor_msgs/Image</code> - Uncompressed image information, typically from the camera, but can be processed data, such as marked pedestrians.</li> <li><code>sensor_msgs/CompressedImage</code> - Compressed image information.</li> <li><code>std_msgs/String</code> - Simple text message type.</li> <li><code>std_msgs/Bool</code> - Simple binary message type.</li> <li><code>geometry_msgs/Point</code> - XYZ 3D point.</li> <li><code>geometry_msgs/Pose</code> - 3D point and associated orientation.</li> </ul> <p>As you can see, the types fall into different categories, such as <code>std_msgs</code>, <code>diagnostic_msgs</code>, <code>geometry_msgs</code>, <code>nav_msgs</code>, <code>sensor_msgs</code>, etc. Let's see what types of messages are found in the downloaded file:</p> Topic Type Hz Sensor /gps/duro/current_pose <code>geometry_msgs/PoseStamped</code> 10 Duro GPS (UTM) /gps/duro/imu <code>sensor_msgs/Imu</code> 200 Duro GPS /gps/duro/mag <code>sensor_msgs/MagneticField</code> 25 Duro GPS /gps/nova/current_pose <code>geometry_msgs/PoseStamped</code> 20 Novatel GPS (UTM) /gps/nova/imu <code>sensor_msgs/Imu</code> 200 Novatel GPS /left_os1/os1_cloud_node/imu <code>sensor_msgs/Imu</code> 100 Ouster LIDAR /left_os1/os1_cloud_node/points <code>sensor_msgs/PointCloud2</code> 20 Ouster LIDAR /right_os1/os1_cloud_node/imu <code>sensor_msgs/Imu</code> 100 Ouster LIDAR /right_os1/os1_cloud_node/points <code>sensor_msgs/PointCloud2</code> 20 Ouster LIDAR /velodyne_left/velodyne_points <code>sensor_msgs/PointCloud2</code> 20 Velodyne LIDAR /velodyne_right/velodyne_points <code>sensor_msgs/PointCloud2</code> 20 Velodyne LIDAR /cloud <code>sensor_msgs/PointCloud2</code> 25 SICK LIDAR /scan <code>sensor_msgs/LaserScan</code> 25 SICK LIDAR /zed_node/left/camera_info <code>sensor_msgs/CameraInfo</code> 30 ZED camera /zed_node/left/image_rect_color/compressed <code>sensor_msgs/Image</code> 20 ZED camera /vehicle_status <code>autoware_msgs/VehicleStatus</code> 100 CAN data /ctrl_cmd <code>autoware_msgs/ControlCommandStamped</code> 20 Reference speed and steering angle /current_pose <code>geometry_msgs/PoseStamped</code> 20 Current GPS /tf <code>tf2_msgs/TFMessage</code> 500+ Transform"},{"location":"introduction/windows/","title":"Windows Installation (<code>C100</code>)","text":""},{"location":"introduction/windows/#shared-drive-k","title":"Shared Drive (<code>K:\\</code>)","text":"<p>The shared drive can be found as the <code>K:\\</code> drive in Windows File Explorer. If it is not visible, it can also be accessed in File Explorer:</p> <pre><code>\\\\fs-kab.eik.sze.hu\\C100\\kozos\n</code></pre> <p></p> <p>Files related to the course can be accessed at the following address: <code>\\\\fs-kab.eik.sze.hu\\C100\\kozos\\GKNB_AUTM078_Auton\u00f3m_robotok_\u00e9s_j\u00e1rm\u0171vek_programoz\u00e1sa</code> c\u00edmen \u00e9rhet\u0151ek el.</p>"},{"location":"introduction/windows/#wsl-and-shared-drive","title":"WSL and Shared Drive","text":"<p>The shared drive should also be accessible from WSL at the /mnt/kozos mount point. Test the access with the cd /mnt/kozos command. If you receive the -bash: cd: /mnt/kozos: No such file or directory message, create it using mkdir. If ls /mnt/kozos does not list files, it is not mounted.</p> <p>If the shared drive does not work, these commands might help:</p> <p><pre><code>sudo mkdir /mnt/kozos\necho \"\\\\\\\\\\\\\\\\fs-kab.eik.sze.hu\\C100\\kozos\\GKNB_AUTM078_Autonomous_robots_and_vehicles_software_engineering    /mnt/kozos    drvfs defaults,uid=1000,gid=1000    0    0\" | sudo tee -a /etc/fstab\n</code></pre> Then run wsl --shutdown from Windows cmd.</p>"},{"location":"introduction/windows/#wsl-in-file-explorer","title":"WSL in File Explorer","text":"<p>The files of Ubuntu 22.04 are also accessible from Windows File Explorer. On the left side, you will see a WSL or Linux label. The ~ is accessible within the /home/ folder, including the ros2_ws.  <p></p>"},{"location":"introduction/windows/#vs-code","title":"VS code","text":""},{"location":"introduction/windows/#vs-code-wsl-access","title":"VS Code WSL Access","text":""},{"location":"introduction/windows/#useful-vs-code-extensions","title":"Useful VS Code Extensions","text":""},{"location":"introduction/windows/#windows-terminal","title":"Windows terminal","text":"<p>A portable version is available on the shared drive. Copy it to C:\\temp to use the program.</p> <p></p> <p>The following figure shows a recommended (not mandatory) computer lab layout, with the terminal on the left and the browser on the right:</p> <p></p> <p></p> <p></p>"},{"location":"introduction/windows/#foxglove","title":"Foxglove","text":"<p>It is installed and can be launched with the icon on the desktop. If it is not installed, copy the portable version from the shared drive to C:\\temp.</p> <p></p>"},{"location":"introduction/windows/#quick-check-of-computer-lab-settings","title":"Quick Check of Computer Lab Settings","text":"<p>!!! success \"Check\" Run the following commands in the computer lab terminal: sh cd /mnt/kozos/script/ ./check_all.sh ```</p>"},{"location":"kalman_filter/","title":"K\u00e1lm\u00e1n filter","text":"<p>K\u00e1lm\u00e1n Rudolf Emil (Budapest, 1930. m\u00e1jus 19. \u2013 Gainesville, 2016. j\u00falius 2.) amerikai magyar villamosm\u00e9rn\u00f6k, matematikus, a m\u0171szaki tudom\u00e1nyok doktora, a Magyar Tudom\u00e1nyos Akad\u00e9mia tiszteleti tagja. Munk\u00e1ss\u00e1ga a matematikai elj\u00e1r\u00e1sok folyamatir\u00e1ny\u00edt\u00e1si \u00e9s szab\u00e1lyoz\u00e1selm\u00e9leti alkalmaz\u00e1s\u00e1ban, az oper\u00e1ci\u00f3kutat\u00e1sban jelent\u0151s, t\u00f6bbek k\u00f6z\u00f6tt a nev\u00e9hez f\u0171z\u0151dik a K\u00e1lm\u00e1n-sz\u0171r\u0151 elv\u00e9nek kidolgoz\u00e1sa.</p> <p></p> <p>Newton's Equations of Motion</p> \\[ x = x_0 + v_{x0} * t + \\frac{1}{2}a_x * t^2 \\] \\[ y = y_0 + v_{y0} * t + \\frac{1}{2}a_y * t^2 \\] <p>State Transition (no control input)</p> \\[x_{k+1} = \\begin{bmatrix}1 &amp; 0 &amp; \\Delta t &amp; 0 &amp; \\frac{1}{2}\\Delta t^2 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; \\Delta t &amp; 0 &amp; \\frac{1}{2}\\Delta t^2 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; \\Delta t &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; \\Delta t \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0  \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y \\\\ \\dot x \\\\ \\dot y \\\\ \\ddot x \\\\ \\ddot y\\end{bmatrix}_{k}\\] \\[y = H \\cdot x\\] <p>Acceleration (IMU) and position (GNSS) (x\u02d9\u02d9, y\u02d9\u02d9, x, y) sensors are used.</p> \\[y = \\begin{bmatrix}0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\cdot x\\]"},{"location":"kalman_filter/practice/","title":"Gyakorlat","text":"<p>GitHub  link</p>"},{"location":"kalman_filter/practice/#import","title":"Import","text":"<pre><code>import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import norm\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = [16, 9]\nplt.rc(\"xtick\", labelsize=20)\nplt.rc(\"ytick\", labelsize=20)\n</code></pre>"},{"location":"kalman_filter/practice/#kalman-filter-for-constant-acceleration-model","title":"Kalman Filter for Constant Acceleration Model","text":""},{"location":"kalman_filter/practice/#state-vector-constant-acceleration","title":"State Vector - Constant Acceleration","text":"<p>Constant Acceleration Model for Ego Motion in Plane</p> \\[x_{k+1} = A \\cdot x_{k} + B \\cdot u\\]"},{"location":"kalman_filter/practice/#newtons-equations-of-motion","title":"Newton's Equations of Motion","text":"<p>$$ x = x_0 + v_{x0} * t + \\frac{1}{2}a_x * t^2 $$ </p> \\[ y = y_0 + v_{y0} * t + \\frac{1}{2}a_y * t^2 \\]"},{"location":"kalman_filter/practice/#state-transition-no-control-input","title":"State Transition (no control input)","text":"\\[x_{k+1} = \\begin{bmatrix}1 &amp; 0 &amp; \\Delta t &amp; 0 &amp; \\frac{1}{2}\\Delta t^2 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; \\Delta t &amp; 0 &amp; \\frac{1}{2}\\Delta t^2 \\\\ 0 &amp; 0 &amp; 1 &amp; 0 &amp; \\Delta t &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 &amp; \\Delta t \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0  \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1\\end{bmatrix} \\cdot \\begin{bmatrix} x \\\\ y \\\\ \\dot x \\\\ \\dot y \\\\ \\ddot x \\\\ \\ddot y\\end{bmatrix}_{k}\\] \\[y = H \\cdot x\\] <p>Acceleration (IMU) and position (GNSS) (\\(\\ddot x\\), \\(\\ddot y\\), \\(x\\), \\(y\\)) sensors are used.</p> \\[y = \\begin{bmatrix}0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 &amp; 0 \\\\ 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 1 \\\\ 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\\\ 0 &amp; 1 &amp; 0 &amp; 0 &amp; 0 &amp; 0 \\end{bmatrix} \\cdot x\\]"},{"location":"kalman_filter/practice/#initial-state","title":"Initial State","text":"<pre><code>plt.figure(figsize=(18, 10))\nx = np.matrix([[0.0, 0.0, 0.0, 0.0, 0.0, 0.0]]).T\nn = x.size  # States\nplt.scatter(float(x[0]), float(x[1]), s=100)\nplt.title(\"Initial Location\", fontsize=20)\nplt.ylabel(\"y in m\", fontsize=20)\nplt.xlabel(\"x in m\", fontsize=20)\nplt.grid(True)\n#### Initial Uncertainty\nP = np.matrix(\n    [\n        [10.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 10.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 10.0, 0.0, 0.0, 0.0],\n        [0.0, 0.0, 0.0, 10.0, 0.0, 0.0],\n        [0.0, 0.0, 0.0, 0.0, 10.0, 0.0],\n        [0.0, 0.0, 0.0, 0.0, 0.0, 10.0],\n    ]\n)\nprint(P)\n\nfig = plt.figure(figsize=(6, 6))\nim = plt.imshow(P, interpolation=\"none\", cmap=plt.get_cmap(\"binary\"))\nplt.title(\"Initial Covariance Matrix $P$\")\nylocs, ylabels = plt.yticks()\n# set the locations of the yticks\nplt.yticks(np.arange(7))\n# set the locations and labels of the yticks\nplt.yticks(\n    np.arange(6),\n    (\"$x$\", \"$y$\", \"$\\dot x$\", \"$\\dot y$\", \"$\\ddot x$\", \"$\\ddot y$\"),\n    fontsize=22,\n)\n\nxlocs, xlabels = plt.xticks()\n# set the locations of the yticks\nplt.xticks(np.arange(7))\n# set the locations and labels of the yticks\nplt.xticks(\n    np.arange(6),\n    (\"$x$\", \"$y$\", \"$\\dot x$\", \"$\\dot y$\", \"$\\ddot x$\", \"$\\ddot y$\"),\n    fontsize=22,\n)\n\nplt.xlim([-0.5, 5.5])\nplt.ylim([5.5, -0.5])\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\ndivider = make_axes_locatable(plt.gca())\ncax = divider.append_axes(\"right\", \"5%\", pad=\"3%\")\nplt.colorbar(im, cax=cax)\n\nplt.tight_layout()\n</code></pre>"},{"location":"kalman_filter/practice/#dynamic-matrix","title":"Dynamic Matrix","text":"<p>It is calculated from the dynamics of the Egomotion.</p> <p>\\(\\(x_{k+1} = x_{k} + \\dot x_{k} \\cdot \\Delta t +  \\ddot x_k \\cdot \\frac{1}{2}\\Delta t^2\\)\\) </p> \\[y_{k+1} = y_{k} + \\dot y_{k} \\cdot \\Delta t +  \\ddot y_k \\cdot \\frac{1}{2}\\Delta t^2\\] <p>\\(\\(\\dot x_{k+1} = \\dot x_{k} + \\ddot x \\cdot \\Delta t\\)\\) </p> \\[\\dot y_{k+1} = \\dot y_{k} + \\ddot y \\cdot \\Delta t\\] <p>\\(\\(\\ddot x_{k+1} = \\ddot x_{k}\\)\\) </p> \\[\\ddot y_{k+1} = \\ddot y_{k}\\] <pre><code>dt = 0.1  # Time Step between Filter Steps\n\nA = np.matrix(\n    [\n        [1.0, 0.0, dt, 0.0, 1 / 2.0 * dt ** 2, 0.0],\n        [0.0, 1.0, 0.0, dt, 0.0, 1 / 2.0 * dt ** 2],\n        [0.0, 0.0, 1.0, 0.0, dt, 0.0],\n        [0.0, 0.0, 0.0, 1.0, 0.0, dt],\n        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n    ]\n)\nprint(A)\n## Measurement Matrix\nThis matrix determines how the sensor measurements map to the vehicle state. In this example, the position and the accelerations are measured ($x$, $y$, $\\ddot x$, $\\ddot y$).\nH = np.matrix(\n    [\n        [0.0, 0.0, 0.0, 0.0, 1.0, 0.0],\n        [0.0, 0.0, 0.0, 0.0, 0.0, 1.0],\n        [1.0, 0.0, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 1.0, 0.0, 0.0, 0.0, 0.0],\n    ]\n)\nprint(H)\n## Measurement Noise Covariance\nra = 10.0 ** 2\nrp = 2.0 ** 2\n\nR = np.matrix(\n    [[ra, 0.0, 0.0, 0.0], [0.0, ra, 0.0, 0.0], [0.0, 0.0, rp, 0.0], [0.0, 0.0, 0.0, rp]]\n)\nprint(R)\n</code></pre>"},{"location":"kalman_filter/practice/#process-noise-covariance-matrix-q-for-ca-model","title":"Process Noise Covariance Matrix Q for CA Model","text":"<p>The Position of an object can be influenced by a force (e.g. wind), which leads to an acceleration disturbance (noise). This process noise has to be modeled with the process noise covariance matrix Q.</p> \\[Q = \\begin{bmatrix}     \\sigma_{x}^2 &amp; 0 &amp; \\sigma_{x \\dot x} &amp; 0 &amp; \\sigma_{x \\ddot x} &amp; 0 \\\\     0 &amp; \\sigma_{y}^2 &amp; 0 &amp; \\sigma_{y \\dot y} &amp; 0 &amp; \\sigma_{y \\ddot y} \\\\     \\sigma_{\\dot x x} &amp; 0 &amp; \\sigma_{\\dot x}^2 &amp; 0 &amp; \\sigma_{\\dot x \\ddot x} &amp; 0 \\\\     0 &amp; \\sigma_{\\dot y y} &amp; 0 &amp; \\sigma_{\\dot y}^2 &amp; 0 &amp; \\sigma_{\\dot y \\ddot y} \\\\     \\sigma_{\\ddot x x} &amp; 0 &amp; \\sigma_{\\ddot x \\dot x} &amp; 0 &amp; \\sigma_{\\ddot x}^2 &amp; 0 \\\\     0 &amp; \\sigma_{\\ddot y y} &amp; 0 &amp; \\sigma_{\\ddot y \\dot y} &amp; 0 &amp; \\sigma_{\\ddot y}^2    \\end{bmatrix} \\cdot \\sigma_{j}\\]"},{"location":"kalman_filter/practice/#symbolic-calculation","title":"Symbolic Calculation","text":"<pre><code>from sympy import Symbol, Matrix\nfrom sympy.interactive import printing\n\ndts = Symbol(\"\\Delta t\")\nsj = 0.1\n\nQ = (\n    np.matrix(\n        [\n            [(dt ** 6) / 36, 0, (dt ** 5) / 12, 0, (dt ** 4) / 6, 0],\n            [0, (dt ** 6) / 36, 0, (dt ** 5) / 12, 0, (dt ** 4) / 6],\n            [(dt ** 5) / 12, 0, (dt ** 4) / 4, 0, (dt ** 3) / 2, 0],\n            [0, (dt ** 5) / 12, 0, (dt ** 4) / 4, 0, (dt ** 3) / 2],\n            [(dt ** 4) / 6, 0, (dt ** 3) / 2, 0, (dt ** 2), 0],\n            [0, (dt ** 4) / 6, 0, (dt ** 3) / 2, 0, (dt ** 2)],\n        ]\n    )\n    * sj ** 2\n)\n\nprint(Q)\nfig = plt.figure(figsize=(6, 6))\nim = plt.imshow(Q, interpolation=\"none\", cmap=plt.get_cmap(\"binary\"))\nplt.title(\"Process Noise Covariance Matrix $Q$\")\nylocs, ylabels = plt.yticks()\n# set the locations of the yticks\nplt.yticks(np.arange(7))\n# set the locations and labels of the yticks\nplt.yticks(\n    np.arange(6),\n    (\"$x$\", \"$y$\", \"$\\dot x$\", \"$\\dot y$\", \"$\\ddot x$\", \"$\\ddot y$\"),\n    fontsize=22,\n)\n\nxlocs, xlabels = plt.xticks()\n# set the locations of the yticks\nplt.xticks(np.arange(7))\n# set the locations and labels of the yticks\nplt.xticks(\n    np.arange(6),\n    (\"$x$\", \"$y$\", \"$\\dot x$\", \"$\\dot y$\", \"$\\ddot x$\", \"$\\ddot y$\"),\n    fontsize=22,\n)\n\nplt.xlim([-0.5, 5.5])\nplt.ylim([5.5, -0.5])\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\ndivider = make_axes_locatable(plt.gca())\ncax = divider.append_axes(\"right\", \"5%\", pad=\"3%\")\nplt.colorbar(im, cax=cax)\n\nplt.tight_layout()\n## Identity Matrix\nI = np.eye(n)\n## Measurement\nimport pandas as pd\nfrom pyproj import Proj\n\n# Read data\n\n# Use every 5th value to get GPS updates in every timestep\nn_rows = 10800  # len(df)\nskip = np.arange(n_rows)\nskip = np.delete(skip, np.arange(0, n_rows, 5))\ndf = pd.read_csv(\"data/2014-03-26-000-Data.csv\", skiprows=skip)\n\n# Extract values\nax = df[\"ax\"].dropna()\nay = df[\"ay\"].dropna()\npx = df[\"latitude\"].dropna()\npy = df[\"longitude\"].dropna()\n\nm = len(df[\"ax\"])  # Measurements\n\n# Lat Lon to UTM\nutm_converter = Proj(\n    \"+proj=utm +zone=33U, +south +ellps=WGS84 +datum=WGS84 +units=m +no_defs\"\n)\n\nfor i in range(len(px)):\n    py[i], px[i] = utm_converter(py[i], px[i])\n    px[i] = px[i] + np.random.normal(0, 2.0, 1)\n    py[i] = py[i] + np.random.normal(0, 2.0, 1)\n    # px[i] = 0 #TODO\n    # py[i] = 0 #TODO\n\n# Start from position (0 ,0)\npy_offset = py[0]\npx_offset = px[0]\npx = px - px_offset\npy = py - py_offset\n\n# Stack measurement vector\nmeasurements = np.vstack((ax, ay, px, py))\nfig = plt.figure(figsize=(16, 9))\nplt.step(range(m), ax, label=\"$a_x$\")\nplt.step(range(m), ay, label=\"$a_y$\")\nplt.ylabel(\"Acceleration in m / $s^2$\", fontsize=20)\nplt.xlabel(\"Number of measurements\", fontsize=20)\nplt.title(\"IMU Measurements\", fontsize=20)\nplt.ylim([-20, 20])\nplt.legend(loc=\"best\", prop={\"size\": 18})\nfig = plt.figure(figsize=(16, 9))\nplt.step(px, py, label=\"$GNSS$\")\nplt.xlabel(\"x in m\", fontsize=20)\nplt.ylabel(\"y in m\", fontsize=20)\nplt.title(\"GNSS Measurements\", fontsize=20)\nplt.xlim([min(px), max(px)])\nplt.ylim([min(py), max(py)])\nplt.legend(loc=\"best\", prop={\"size\": 18})\n# Preallocation for Plotting\nxt = []\nyt = []\ndxt = []\ndyt = []\nddxt = []\nddyt = []\nZx = []\nZy = []\nPx = []\nPy = []\nPdx = []\nPdy = []\nPddx = []\nPddy = []\nKx = []\nKy = []\nKdx = []\nKdy = []\nKddx = []\nKddy = []\n</code></pre>"},{"location":"kalman_filter/practice/#kalman-filter","title":"Kalman Filter","text":"<p> <pre><code>for n in range(m):\n\n    # Time Update (Prediction)\n    # ========================\n    # Project the state ahead\n    x = A * x\n\n    # Project the error covariance ahead\n    P = A * P * A.T + Q\n\n    # Measurement Update (Correction)\n    # ===============================\n    # Compute the Kalman Gain\n    S = H * P * H.T + R\n    K = (P * H.T) * np.linalg.pinv(S)\n\n    # Update the estimate via z\n    Z = measurements[:, n].reshape(H.shape[0], 1)\n    y = Z - (H * x)  # Innovation or Residual\n    x = x + (K * y)\n\n    # Update the error covariance\n    P = (I - (K * H)) * P\n\n    # Save states for Plotting\n    xt.append(float(x[0]))\n    yt.append(float(x[1]))\n    dxt.append(float(x[2]))\n    dyt.append(float(x[3]))\n    ddxt.append(float(x[4]))\n    ddyt.append(float(x[5]))\n    Zx.append(float(Z[0]))\n    Zy.append(float(Z[1]))\n    Px.append(float(P[0, 0]))\n    Py.append(float(P[1, 1]))\n    Pdx.append(float(P[2, 2]))\n    Pdy.append(float(P[3, 3]))\n    Pddx.append(float(P[4, 4]))\n    Pddy.append(float(P[5, 5]))\n    Kx.append(float(K[0, 0]))\n    Ky.append(float(K[1, 0]))\n    Kdx.append(float(K[2, 0]))\n    Kdy.append(float(K[3, 0]))\n    Kddx.append(float(K[4, 0]))\n    Kddy.append(float(K[5, 0]))\n## Plots\n### Covariance Matrix\nfig = plt.figure(figsize=(6, 6))\nim = plt.imshow(P, interpolation=\"none\", cmap=plt.get_cmap(\"binary\"))\nplt.title(\"Covariance Matrix $P$ (after %i Filter Steps)\" % (m), fontsize=20)\nylocs, ylabels = plt.yticks()\n# set the locations of the yticks\nplt.yticks(np.arange(7))\n# set the locations and labels of the yticks\nplt.yticks(\n    np.arange(6),\n    (\"$x$\", \"$y$\", \"$\\dot x$\", \"$\\dot y$\", \"$\\ddot x$\", \"$\\ddot y$\"),\n    fontsize=22,\n)\n\nxlocs, xlabels = plt.xticks()\n# set the locations of the yticks\nplt.xticks(np.arange(7))\n# set the locations and labels of the yticks\nplt.xticks(\n    np.arange(6),\n    (\"$x$\", \"$y$\", \"$\\dot x$\", \"$\\dot y$\", \"$\\ddot x$\", \"$\\ddot y$\"),\n    fontsize=22,\n)\n\nplt.xlim([-0.5, 5.5])\nplt.ylim([5.5, -0.5])\n\nfrom mpl_toolkits.axes_grid1 import make_axes_locatable\n\ndivider = make_axes_locatable(plt.gca())\ncax = divider.append_axes(\"right\", \"5%\", pad=\"3%\")\nplt.colorbar(im, cax=cax)\n\n\nplt.tight_layout()\n## State Vector\nfig = plt.figure(figsize=(16, 12))\n\nplt.subplot(311)\nplt.step(range(len(measurements[0])), ddxt, label=\"$\\ddot x$\")\nplt.step(range(len(measurements[0])), ddyt, label=\"$\\ddot y$\")\n\nplt.title(\"Estimate (Elements from State Vector $x$)\", fontsize=20)\nplt.legend(loc=\"best\", prop={\"size\": 22})\nplt.ylabel(\"Acceleration in m/ $s^2$\", fontsize=20)\n\nplt.subplot(312)\nplt.step(range(len(measurements[0])), dxt, label=\"$\\dot x$\")\nplt.step(range(len(measurements[0])), dyt, label=\"$\\dot y$\")\n\nplt.ylabel(\"\")\nplt.legend(loc=\"best\", prop={\"size\": 22})\nplt.ylabel(\"Velocity in m/s\", fontsize=20)\n\nplt.subplot(313)\nplt.step(range(len(measurements[0])), xt, label=\"$x$\")\nplt.step(range(len(measurements[0])), yt, label=\"$y$\")\n\nplt.xlabel(\"Filter Step\", fontsize=20)\nplt.ylabel(\"Position in m\", fontsize=20)\nplt.legend(loc=\"best\", prop={\"size\": 22})\n## Position x/y\nfig = plt.figure(figsize=(16, 9))\n\nplt.step(px, py, label=\"$GNSS$\")\n\nplt.scatter(xt[0], yt[0], s=100, label=\"Start\", c=\"g\")\nplt.scatter(xt[-1], yt[-1], s=100, label=\"Goal\", c=\"r\")\nplt.plot(xt, yt, label=\"State\", alpha=0.5)\nplt.xlabel(\"x in m\", fontsize=20)\nplt.ylabel(\"y in m\", fontsize=20)\nplt.title(\"Position\", fontsize=20)\nplt.legend(loc=\"best\", fontsize=20)\nplt.xlim(min(xt), max(xt))\nplt.ylim(min(yt), max(yt))\n</code></pre></p>"},{"location":"links/","title":"Links","text":""},{"location":"links/#linux-knowledge","title":"Linux Knowledge","text":"<ul> <li>Simple Linux commands - [hun]</li> <li>ROS training - 0.1 Intro to Ubuntu GUI - [eng]</li> <li>ROS training - 0.2 The Linux File System - [eng]</li> <li>ROS training - 0.3 Using the Terminal - [eng]</li> <li>Terminal usage - [hun]</li> <li>60 Linux Commands you need to know [video, eng]</li> <li>The 50 Most Popular Linux &amp; Terminal Commands, freeCodeCamp [video, eng]</li> <li>Raspberry Pi guide: [hun]</li> <li>Git usage:</li> <li>Assignment description, Git and GitHub - [hun] </li> <li>GitHub first-contributions Hungarian translation - [hun]</li> <li>GitHub Learning Lab - [eng]</li> <li>VS code - [hun], [vid]</li> <li>Python [hun]</li> <li>Python freeCodeCamp video [eng]</li> <li>Python 60 days with python videos [eng]</li> <li>C++ [hun]</li> <li>C++ Optimizations Diary [eng]</li> <li>C++ Code for yourself videos [eng]</li> </ul>"},{"location":"links/#robotics-knowledge","title":"Robotics Knowledge","text":"<ul> <li>Basic robotics knowledge [eng]</li> <li>Kalman filter [eng]</li> <li>Universitat Polit\u00e8cnica de Catalunya BarcelonaTech (UPC) - [eng]</li> <li>English tutorial by Professor Pozna and Csaba Antonya - Autocarsim [eng]</li> </ul>"},{"location":"links/#stanford-university","title":"Stanford University","text":"<ul> <li>Stanford University - Introduction to Robotics Oussama Khatib - [eng, video playlist]</li> </ul>"},{"location":"links/#tu-munchen","title":"TU M\u00fcnchen","text":"<ul> <li>Github link: github.com/TUMFTM/Lecture_ADSE</li> </ul> Number Session Description Video Lecture Slides 1 Python intro Some basics of programming in python for beginners. ResearchGate 2 Basics of mapping and localization Exemplary implementation of a Kalman filter and application for localization via GNSS-signal. YouTube ResearchGate 3 SLAM The google cartographer SLAM algorithm is applied to data from the KITTI-dataset. Note, that this lecture is held in Linux and has its own dependencies, please refer to the local readme. YouTube ResearchGate 4 Detection Overview about the YOLO-approach from network  architecture to exemplary usage. YouTube ResearchGate 5 Prediction Implementation of the pipeline to setup a motion prediction algorithm based on a Encoder-Decoder architecture. YouTube ResearchGate 6 Global plannings A global optimal race line optimization is shown. This lecture has its own dependencies, please refer to the local readme. YouTube ResearchGate 7 Local planning A local planning algorithm based on a graph-based approach is presented. YouTube ResearchGate 8 Control The design of a velocity controller and numerical solver for differential equation are covered. YouTube ResearchGate 9 Safety assessment The evaluation of the criticality of planned trajectories based on various metrics and their sensitivity is discussed. YouTube ResearchGate 10 Teleoperated driving How to send and receive data via MQTT over network is shown in this practice session. YouTube ResearchGate 11 End-to-End The exemplary pipeline of data collection from expert demonstration, training and application are treated in this session. This lecture has its own dependencies, please refer to the local YouTube ResearchGate"},{"location":"links/#hungarian-ros-tutorials","title":"Hungarian ROS Tutorials","text":"<ul> <li>ROS exercises homepage: horverno.github.io/ros-gyakorlatok</li> <li>ROS installation (hun) - Melodic</li> <li>ROS \u00d3budai Egyetem - Antal Bejczy Center for Intelligent Robotics (hun)</li> </ul>"},{"location":"links/#english-ros-tutorials","title":"English ROS Tutorials","text":"<ul> <li>ROS installation (eng)</li> <li>ETH Z\u00fcrich - Programming for Robotics (ROS)</li> <li>edX - Hello (Real) World with ROS</li> <li>ROS.org tutorials</li> <li>ROS PCL tutorial</li> <li>Felipe Boseong Jeon ROS2 tutorials</li> </ul>"},{"location":"links/#apex-ai","title":"Apex AI","text":"<ul> <li>Apex AI youtube</li> <li>1: Development Environment</li> <li>2: ROS2 101</li> <li>3: ROS 2 Tooling - Develop Like a Pro</li> <li>4: Platform HW, RTOS and DDS</li> <li>5: Autonomous Driving Stacks</li> <li>6: Autoware 101</li> <li>7: Object Perception: LIDAR</li> <li>8: Object Perception: CAMERA</li> <li>9: Object Perception: Radar</li> <li>10: State Estimation for Localization</li> <li>11: LGSVL Simulator</li> <li>12: Motion Control</li> <li>13: Data Storage and Analytics</li> <li>14: HD Maps</li> <li>F1/10 ROS</li> </ul>"},{"location":"links/#eth-zurich","title":"ETH Z\u00fcrich","text":"<ul> <li>Programming for Robotics - ROS: P\u00e9ter Fankhauser, Dominic Jud, Martin Wermelinger, Prof. Dr. Marco Hutter. rsl.ethz.ch/education-students/lectures/ros.html</li> </ul> 2021TopicsMaterial 22.02.<ul> <li>ROS architecture &amp; philosophy</li> <li>ROS master, nodes, and topics</li> <li>Console commands</li> <li>Catkin workspace and build system</li> <li>Launch-files</li> <li>Gazebo simulator</li> <li>Programming Tools</li> </ul><ul> <li>Lecture Slides (PDF, 2.4 MB)</li> <li>Exercises (PDF, 314 KB)</li> <li>Files: smb_common.zip (ZIP, 2.3 MB)</li> <li>Video Recording </li> </ul>24.02.<ul> <li>ROS package structure</li> <li>Integration and programming with Eclipse</li> <li>ROS C++ client library (roscpp)</li> <li>ROS subscribers and publishers</li> <li>ROS parameter server</li> <li>RViz visualization</li> </ul><ul> <li>Lecture Slides (PDF, 2.4 MB)</li> <li>Exercises (PDF, 219 KB) </li> <li>Files: smb_highlevel_controller.zip (ZIP, 3 KB)</li> <li>Video Recording</li> </ul><ul> <li>Lecture Slides (PDF, 2 MB)</li> <li>Exercises (PDF, 170 KB)</li> <li>Files: smb_common_v2.zip (ZIP, 2.3 MB)</li> <li>Files: singlePillar.world (WORLD, 1 KB)</li> <li>Video Recording </li> </ul>01.03.<ul> <li>ROS services</li> <li>ROS actions (actionlib)</li> <li>ROS time</li> <li>ROS bags</li> <li>Debugging strategies</li> <li>Introduction to ROS2 </li> </ul><ul> <li>Lecture Slides (PDF, 932 KB)</li> <li>Exercises (PDF, 283 KB)</li> <li>Files: smb_navigation.bag (BAG, 158.9 MB)</li> <li>Video Recording </li> </ul>05.03.<ul> <li>Case study: Using ROS in complex real-world applications</li> </ul><ul> <li>Exercises (PDF, 67 KB)</li> </ul> 2021: <ul> <li>ANYbotics Case Study (PDF, 8.6 MB)</li> <li>Video Recording </li> </ul> 2020: <ul> <li>ANYbotics Case Study (PDF, 7.6 MB)</li> </ul> 2018: <ul> <li>Building a Legged Robot with ROS slides (PDF, 11.5 MB)</li> <li>mANYpulator \u2013 Mobile Manipulation slides (PDF, 2 MB)</li> <li>Using ROS with other Simulators slides (PDF, 1.6 MB)</li> </ul> 2017: <ul> <li>ANYmal at the ARGOS Challenge slides</li> </ul>"},{"location":"links/#university-of-bonn","title":"University of Bonn","text":"<p>Link: ipb.uni-bonn.de/sdc-2021</p> <p>Self-Driving Cars: An Introduction (Cyrill Stachniss) Introduction lecture for the course \u201cTechniques for Self-Driving Cars\u201d taught at the University of Bonn. A course by Cyrill Stachniss, Jens Behley, Nived Chebrolu, Benedikt Mersch, Igor Bogoslavskyi.</p> <p>Self-Driving Cars: Localization (Daniel Wilbers) Localization lecture for the course \u201cTechniques for Self-Driving Cars\u201d taught at the University of Bonn. Further Information on Deep Learning and CNNs, see our Machine Learning for Robotics and Computer Vision Course: Youtube Link</p> <p>Self-Driving Cars: Control (Nived Chebrolu) Control lecture for the course \u201cTechniques for Self-Driving Cars\u201d taught at the University of Bonn. A course by Cyrill Stachniss, Jens Behley, Nived Chebrolu, Benedikt Mersch, Igor Bogoslavskyi. Youtube Link</p> <p>Model Predictive Control \u2013 Part 1: Introduction to MPC (Lasse Peters) Introduction to Model Predictive Control; lecture presented by Lasse Peters. Youtube Link</p> <p>Model Predictive Control \u2013 Part 2: Numerical Methods for MPC (Lasse Peters) Numerical Methods for Model Predictive Control; lecture presented by Lasse Peters. Youtube Link</p> <p>Self-Driving Cars: Planning (Benedikt Mersch) Planning lecture for the course \u201cTechniques for Self-Driving Cars\u201d taught at the University of Bonn. A course by Cyrill Stachniss, Jens Behley, Nived Chebrolu, Benedikt Mersch, Igor Bogoslavskyi. Youtube Link</p> <p>Self-Driving Cars: Behavior Estimation (Benedikt Mersch) Behavior estimation lecture for the course \u201cTechniques for Self-Driving Cars\u201d taught at the University of Bonn. A course by Cyrill Stachniss, Jens Behley, Nived Chebrolu, Benedikt Mersch, Igor Bogoslavskyi, Lasse Peters. Youtube Link</p> <p>Self-Driving Cars: Perception \u2013 Part 1 (Jens Behley) Youtube Link Perception lecture for the course \u201cTechniques for Self-Driving Cars\u201d taught at the University of Bonn. Further Information on Deep Learning and CNNs, see our Machine Learning for Robotics and Computer Vision Course:  Youtube playlist</p> <p>Self-Driving Cars: Perception \u2013 Part 2 (Jens Behley) Perception lecture for the course \u201cTechniques for Self-Driving Cars\u201d taught at the University of Bonn. Youtube Link</p> <p>Self-Driving Cars: View from Practice (Igor Bogoslavskyi) Lecture giving a view from practice for the course \u201cTechniques for Self-Driving Cars\u201d taught at the University of Bonn. A course by Cyrill Stachniss, Jens Behley, Nived Chebrolu, Benedikt Mersch, Igor Bogoslavskyi. Youtube Link</p>"},{"location":"links/#articulated-robotics","title":"Articulated Robotics","text":"<p>ROS 2</p> <ul> <li>Youtube playlist</li> <li>articulatedrobotics.xyz</li> </ul>"},{"location":"links/#the-robotics-back-end","title":"The Robotics Back-End","text":"<p>ROS 2</p> <ul> <li>Youtube playlist</li> <li>roboticsbackend.com</li> </ul>"},{"location":"links/#foxglove-ros-2-tutorials","title":"Foxglove ROS 2 tutorials","text":"<ul> <li>foxglove.dev/tutorials</li> <li>Install ROS 2 Galactic on Ubuntu</li> <li>Install ROS 2 Galactic on Ubuntu</li> <li>Install ROS 2 Humble on Ubuntu</li> <li>Install ROS 2 Humble on macOS with Docker</li> <li>Introduction to ROS 2</li> <li>Use a Rosbridge connection</li> <li>Create services</li> <li>Create actions</li> <li>Use parameters</li> <li>Use launch files</li> <li>Understand transforms</li> <li>Publish and visualize transforms</li> <li>Calculate object positions across frames</li> </ul>"},{"location":"links/#official-ros-2-documentation","title":"Official ROS 2 documentation","text":"<ul> <li>docs.ros.org/en/humble</li> <li>docs.ros.org</li> </ul>"},{"location":"links/#egyeb","title":"Egy\u00e9b","text":"<ul> <li>VS code \u00e9s ROS 2 aj\u00e1nlott be\u00e1ll\u00edt\u00e1sok: picknik.ai/vscode/docker/ros2/2024/01/23/ROS2-and-VSCode.html</li> <li>ROS felhaszn\u00e1l\u00f3k a vil\u00e1gban: metrorobots.com/rosmap.html</li> <li>Colcon cheatsheet: github.com/ubuntu-robotics/ros2_cheats_sheet/blob/master/colcon%2Fcolcon_cheats_sheet.pdf</li> <li>IEEE robots guide robotsguide.com/robots</li> </ul>"},{"location":"papers/","title":"Papers overview","text":"<ul> <li>Curve Trajectory Model for Human Preferred Path Planning of Automated Vehicles - Gerg\u0151 Ign\u00e9czi, Ern\u0151 Horv\u00e1th, Roland T\u00f3th, Krisztian Nyilas  - Springer Automotive Innovation PDF <code>2024</code> </li> <li>Deep Learning-Based Approach for Autonomous Vehicle Localization: Application and Experimental Analysis - Norbert Mark\u00f3, Ern\u0151 Horv\u00e1th, Istv\u00e1n Szalay, Kriszti\u00e1n Enisz -  Machines, vol. 11, no. 12, p. 1079, <code>2023</code> </li> <li>Network Optimization Aspects of Autonomous Vehicles: Challenges and Future Directions - Rudolf Krecht, Tam\u00e1s Budai, Ern\u0151 Horv\u00e1th, \u00c1kos Kov\u00e1cs, Nobert Mark\u00f3, Mikl\u00f3s Unger  - IEEE Network <code>2023</code></li> <li>Node Point Optimization for Local Trajectory Planners based on Human Preferences - Gerg\u0151 Ign\u00e9czi, Ern\u0151 Horv\u00e1th  - 21st World Symposium on Applied Machine Intelligence and Informatics (SAMI) <code>2023</code> </li> <li>Real-Time LIDAR-Based Urban Road and Sidewalk Detection for Autonomous Vehicles - Ern\u0151 Horv\u00e1th,Claudiu Radu Pozna, Mikl\u00f3s Unger -  Sensors, vol. 22, no. 1, p. 194, <code>2022</code> </li> <li>A Clothoid-based Local Trajectory Planner with Extended Kalman Filter - Gerg\u0151 Ign\u00e9czi, Ern\u0151 Horv\u00e1th  - IEEE 20th Jubilee World Symposium on Applied Machine Intelligence and Informatics (SAMI) <code>2022</code>, Poprad, Slovakia</li> <li>Hybrid Particle Filter-Particle Swarm Optimization Algorithm and Application to Fuzzy Controlled Servo Systems - Claudiu Pozna, Radu-Emil Precup, Ern\u0151 Horv\u00e1th, Emil M. Petriu - IEEE Transactions on Fuzzy Systems, <code>2022</code></li> <li>Implementation of a self-developed Model Predictive Control Scheme for Vehicle Parking Maneuvers - Gerg\u0151 Ign\u00e9czi, Ern\u0151 Horv\u00e1th, D\u00e1niel Pup  - The 1st ISTRC Annual Conference, PDF <code>2021</code>, Tel Aviv, Israel</li> <li>Case Study on the Tactical Level of an Autonomous Vehicle Control - Claudiu Radu Pozna, Csaba Antonya, Ern\u0151 Horv\u00e1th  - International Conference on Electrical, Computer, Communications and Mechatronics Engineering (ICECCME), <code>2021</code>, Mauritius, Mauritius</li> <li>Clothoid-based Trajectory Following Approach for Self-driving vehicles - Ern\u0151 Horv\u00e1th, Claudiu Radu Pozna - IEEE 19th World Symposium on Applied Machine Intelligence and Informatics (SAMI), <code>2021</code>, Herl'any, Slovakia, Virtual</li> <li>Development of Point-cloud Processing Algorithm for Self-Driving Challenges - Mikl\u00f3s Unger, Ern\u0151 Horv\u00e1th, P\u00e9ter K\u0151r\u00f6s - IEEE International Conference on Intelligent Engineering Systems (INES), <code>2020</code>, Reykjav\u00edk, Iceland, Virtual</li> <li>Self-Driving Vehicle Sensors from One-Seated Experimental to Road-legal Vehicle - P\u00e9ter K\u0151r\u00f6s, G\u00e1bor Szak\u00e1llas, P\u00e9ter Guly\u00e1s, Zolt\u00e1n Pusztai, Zolt\u00e1n Szeli, Ern\u0151 Horv\u00e1th - IEEE International Conference on Intelligent Engineering Systems (INES), <code>2020</code>, Reykjav\u00edk, Iceland, Virtual</li> <li>Improving the efficiency of neural networks with virtual training data - J\u00e1nos Holl\u00f3si, Rudolf Krecht, Norbert Mark\u00f3, \u00c1ron Ballagi - Hungarian Journal of Industry and Chemistry, Self-Driving Vehicles Special Issue, PDF <code>2020</code>, Hungary</li> <li>Theoretical background and application of multiple goal pursuit trajectory follower - Ern\u0151 Horv\u00e1th, Claudiu Radu Pozna, P\u00e9ter K\u0151r\u00f6s, Csaba Hajdu, \u00c1ron Ballagi - Hungarian Journal of Industry and Chemistry, Self-Driving Vehicles Special Issue, PDF <code>2020</code>, Hungary  </li> <li>LIDAR-based Collision-Free Space Estimation Approach - Mikl\u00f3s Unger, Ern\u0151 Horv\u00e1th, Csaba Hajdu - Hungarian Journal of Industry and Chemistry, Self-Driving Vehicles Special Issue, PDF <code>2020</code>, Hungary</li> <li>Towards System-Level Testing with Coverage Guarantees for Autonomous Vehicles - Istv\u00e1n Majzik, Oszk\u00e1r Semer\u00e1th, Csaba Hajdu, Krist\u00f3f Marussy, Zolt\u00e1n Szatm\u00e1ri, Zolt\u00e1n Micskei, Andr\u00e1s V\u00f6r\u00f6s, Aren A. Babikian, D\u00e1niel Varr\u00f3 - ACM/IEEE 22nd International Conference on Model Driven Engineering Languages and Systems (MODELS) <code>2019</code>, Munich, Germany</li> <li>Range Sensor-based Occupancy Grid Mapping with Signatures - Ern\u0151 Horv\u00e1th, Csaba Hajdu, Claudiu Radu Pozna, \u00c1ron Ballagi - 20th International Carpathian Control Conference (ICCC), <code>2019</code>, Krakow-Wieliczka, Poland</li> <li>Novel Pure-Pursuit Trajectory Following Approaches and their Practical Applications - Ern\u0151 Horv\u00e1th, Csaba Hajdu and Peter K\u0151r\u00f6s - 10th IEEE International Conference on InfoCommunications <code>2019</code>, Naples, Italy</li> <li>Improve the Accuracy of Neural Networks using Capsule Layers - J\u00e1nos Holl\u00f3si, Claudiu Radu Pozna - IEEE 18th International Symposium on Computational Intelligence and Informatics (CINTI), <code>2018</code>, Budapest, Hungary</li> </ul>"},{"location":"perception/","title":"Perception","text":"<p>Perception is the extraction of information from raw sensory data.</p> <p></p> <p>The goals of perception can include:</p> <ul> <li>Object recognition (detection), e.g.:<ul> <li>Pedestrian, cyclist, vehicle recognition</li> <li>Traffic sign recognition, traffic light recognition</li> <li>Drivable surface and lane recognition (also for localization and planning)</li> </ul> </li> <li>Object classification:<ul> <li>Classifying already recognized objects. For example, determining the color of a traffic light, or distinguishing between a van and a horse-drawn carriage.</li> </ul> </li> <li>Object tracking and prediction:<ul> <li>Determining the past paths of vehicles and pedestrians and predicting their future paths. This can be related to classification, as a horse-drawn carriage, despite being similar in size to a trailer, has different acceleration capabilities. This information can be used to plan routes and trajectories.</li> </ul> </li> <li>Localization and mapping:<ul> <li>SLAM: non-GNSS-based localization supplemented with local map creation. LOAM: LIDAR-based odometry.</li> </ul> </li> </ul> <p>Based on the sensors used, perception can involve: - LIDAR - Camera - Radar - IMU - GNSS/GPS - Microphone - Any combination of the above sensors</p> <p>Danger</p> <p>In Hungarian, it is easy to confuse the terms sensing (sensing) and perception (perception). Perception is a complex function that deals with producing processed, interpreted output from raw data.</p> <pre><code>flowchart LR\n\nL[Planning]:::light\n\nsubgraph Perception [Perception]\n  T[Mapping]:::light \n  H[Localization]:::light\n  P[Object\n  Prediction]:::light \n  D[Object\n  Detection]:::light\n  K[Object \n  Classification]:::light\n  D--&gt;K\nend\nsubgraph Sensing [Sensing]\n  GPS[GPS/GNSS]:::light -.-&gt; T\n  GPS -.-&gt; H\n  LIDAR[LIDAR]:::light\n  KAM[Camera]:::light\n  IMU[IMU]:::light\n  LIDAR -.-&gt; D\n  LIDAR -.-&gt; P\n  LIDAR -.-&gt; T\n  KAM-.-&gt; P\n  KAM-.-&gt; D\n  IMU-.-&gt; T\n  D-.-&gt;P\nend\n\nT --&gt;|map| L\nH --&gt;|pose| L\nP --&gt;|obj.| L\nK --&gt;|obj.| L\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre> <p>This material is based on the Autonomous Driving Software Engineering course at TU Munich, compiled by the staff of the Institute of Automotive Technology. The lecture video is available in German:</p>"},{"location":"perception/#challenges-and-difficulties","title":"Challenges and Difficulties","text":"<p>Several challenges can hinder recognition and its accuracy: - Weather (rain, snow, fog, ...) - Time of day (night, sunset, sunrise ...) - Occlusion (objects are only partially visible) - Computation time (exponentially more critical at higher speeds) - Different environments (urban, highway, forested areas ...)</p>"},{"location":"perception/#use-cases","title":"Use Cases","text":"<p>Since it would be difficult to demonstrate every aspect of perception, we will instead showcase a few use cases.</p>"},{"location":"perception/#camera-based-traffic-light-classification","title":"Camera-based Traffic Light Classification","text":"<p>Processing camera images using artificial intelligence (neural network: YOLOv7).</p>"},{"location":"perception/#lidar-based-simple-height-filtering","title":"LIDAR-based Simple Height Filtering","text":"<p>A task often encountered in practice is simple LIDAR filtering based on X, Y, and Z coordinates. Since LIDAR provides a simple representation of the 3D environment, it can be easier to work with than a camera. A common technique is to filter out the road level from LIDAR data (ground segmentation), with the remaining points (non-ground) representing all objects. Here we demonstrate a much simpler technology:</p> <p></p>"},{"location":"perception/#clustering","title":"Clustering","text":"<p>After filtering out the road level from LIDAR data (ground segmentation), ground points and non-ground points are generated. The non-ground points need to be clustered to form points describing objects. The essence of clustering is that the points of a given object (e.g., a car) are close to each other.</p> <p></p> <p>Source: codeahoy.com</p>"},{"location":"perception/#sensor-fusion","title":"Sensor Fusion","text":"<p>The following video demonstrates perception through a real-life example.</p>"},{"location":"perception/#lidar-based-road-surface-curb-detection","title":"LIDAR-based Road Surface / Curb Detection","text":"<p>An algorithm developed by our university.</p>"},{"location":"perception/#lidar-based-object-tracking-and-prediction","title":"LIDAR-based Object Tracking and Prediction","text":""},{"location":"perception/#slam-lidar-and-camera-fusion","title":"SLAM LIDAR and Camera Fusion","text":"<p>Simultaneous Localization and Mapping (SLAM) involves mapping the position and environment of a moving system (robot or vehicle) while navigating.</p>"},{"location":"perception/#sources","title":"Sources","text":"<ul> <li>github.com/TUMFTM/Lecture_ADSE</li> <li>Kim and Kum (2019) \u2013 Deep Learning based Vehicle Position and Orientation Estimation via Inverse Perspective Mapping Image</li> <li>Object Perception: LIDAR youtube APEX AI</li> <li>Object Perception: CAMERA youtube APEX AI</li> <li>Object Perception: Radar youtube APEX AI</li> </ul>"},{"location":"perception/ground_filter/","title":"Ground filter","text":"<p>Available: - url-kaist/patchwork-plusplus-ros/tree/ROS2 - github.com/MohamedHussein736/patchwork-plusplus-ros/tree/ROS2 - github.com/jkk-research/patchwork-plusplus-ros a fork of the original repo that only contains the ROS 2 branch, with the SZE-JKK pull request merged into the original Urban Robotics Lab repo.</p> <pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/jkk-research/patchwork-plusplus-ros\n</code></pre> <pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>colcon build --packages-select patchworkpp\n</code></pre> <pre><code>ros2 launch patchworkpp demo.launch\n</code></pre> <p>TODO</p> <pre><code>ros2 bag play kitti_00_sample.db3\n</code></pre>"},{"location":"perception/practice/","title":"Practice - Perception","text":"<p>This short workshop will guide you through filtering LIDAR data into objects. Objects could be pedestrians, cars, buildings, and so on. This workshop is ROS 2 compatible. </p>"},{"location":"perception/practice/#requirements-high-level-overview","title":"Requirements (high-level overview)","text":"<ol> <li>ROS 2 Humble: \ud83d\udfe0 see previous workshops or docs.ros.org/en/humble/Installation.html </li> <li>A log file with raw LIDAR data (MCAP format) \u2705 </li> <li>The <code>patchworkpp</code> package to filter out the ground plane \u2705 </li> <li>The <code>lidar_cluster</code> package to perform the clustering \u2705 </li> </ol>"},{"location":"perception/practice/#video-overview","title":"Video overview","text":"<p>The following screen recording demonstrates the steps involved:</p>"},{"location":"perception/practice/#step-1-download-the-raw-data","title":"<code>Step 1.</code> - Download the raw data","text":"<p>In order to cluster LIDAR data, first you need - no surprise - LIDAR data. Use any of the following 3 options.</p>"},{"location":"perception/practice/#option-a-download-our-mcap-from-the-link-below","title":"<code>Option A.</code> - Download our MCAP from the link below","text":"<p>Download MCAP [~540MB]  </p> <p>In our examples the <code>.mcap</code> file is going to be saved in <code>/mnt/c/bag/</code>. If you want to use another directory, please change it accordingly.</p>"},{"location":"perception/practice/#option-b-download-our-mcap-through-your-terminal","title":"<code>Option B.</code> - Download our MCAP through your terminal","text":"Don't forget to change directory first.  In our case `/mnt/c/bag/` is used as a final destination:  <pre><code>cd /mnt/c/bag/\n</code></pre> <pre><code>wget https://laesze-my.sharepoint.com/:u:/g/personal/herno_o365_sze_hu/Eclwzn42FS9GunGay5LPq-EBA6U1dZseBFNDrr6P0MwB2w?download=1  -O lexus3-2024-04-05-gyor.mcap\n</code></pre>"},{"location":"perception/practice/#option-c-use-your-own-mcap","title":"<code>Option C.</code> - Use your own MCAP","text":"<p>You can use your own MCAP, but in that case, you may need to change following:</p> <ul> <li>The LIDAR topic <ul> <li>In our examples it's <code>/lexus3/os_center/points</code></li> </ul> </li> <li>LIDAR frame <ul> <li>In our examples it's <code>lexus3/os_center_a_laser_data_frame</code></li> </ul> </li> </ul> <p>Never forget to update these in later steps if you use your own MCAP.</p>"},{"location":"perception/practice/#check-your-raw-data","title":"Check your raw data","text":"<p>Play your bag using the following command (or however you wish): <pre><code>ros2 bag play /mnt/c/bag/lexus3-2024-04-05-gyor.mcap -l\n</code></pre></p> <p>Info</p> <p>The <code>-l</code> option in the <code>play</code> command loops the mcap file.</p> <p>Success</p> <p>If everything works as expected you should see a bunch of topics in another terminal   Topics In another terminal issue the command: <p><pre><code>ros2 topic list\n</code></pre> You should see a similar list of topics:</p> <p><pre><code>/clock\n/events/read_split\n/lexus3/gps/duro/current_pose\n/lexus3/gps/duro/imu\n/lexus3/gps/duro/mag\n/lexus3/gps/duro/navsatfix\n/lexus3/gps/duro/status_flag\n/lexus3/gps/duro/status_string\n/lexus3/gps/duro/time_diff\n/lexus3/gps/duro/time_ref\n/lexus3/os_center/points\n/lexus3/os_left/points\n/lexus3/os_right/points\n/lexus3/zed2i/zed_node/left/image_rect_color/compressed\n/parameter_events\n/rosout\n/tf\n/tf_static   \n</code></pre> </p> <p>Also there must be at least one <code>sensor_msgs/msg/PointCloud2</code>, check with: <pre><code> ros2 topic type /lexus3/os_center/points\n</code></pre> Result: <pre><code>sensor_msgs/msg/PointCloud2\n</code></pre></p>"},{"location":"perception/practice/#step-2-install-ros-2-packages","title":"<code>Step 2.</code> - Install <code>ROS 2</code> packages","text":"<p>Info</p> <p>If you don't have the <code>~/ros2_ws/</code> directory already, create it with the following command: <pre><code>mkdir -p ~/ros2_ws/src\n</code></pre> If you have your own workspace, make sure to update the paths accordingly in the following steps.</p>"},{"location":"perception/practice/#clone-patchworkpp-package","title":"Clone <code>patchworkpp</code> package","text":"<p><code>patchwork-plusplus-ros</code> is ROS 2 package of Patchwork++ (@ IROS'22), which provides fast and robust LIDAR ground segmentation. We recommend the JKK research fork which contains some improvements, alternatively you can use the original KAIST version. </p> <p><pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/jkk-research/patchwork-plusplus-ros\n</code></pre> or <pre><code>git clone https://github.com/url-kaist/patchwork-plusplus-ros -b ROS2\n</code></pre></p>"},{"location":"perception/practice/#clone-lidar_cluster-package","title":"Clone <code>lidar_cluster</code> package","text":"<pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/jkk-research/lidar_cluster_ros2\n</code></pre>"},{"location":"perception/practice/#build-the-packages","title":"Build the packages","text":"<pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select patchworkpp lidar_cluster --symlink-install\n</code></pre>"},{"location":"perception/practice/#step-3-run","title":"<code>Step 3.</code> - Run","text":""},{"location":"perception/practice/#what-to-expect","title":"What to expect","text":"<pre><code>graph TD;\n\n    p1[ /lexus3/os_center/points&lt;br/&gt;sensor_msgs::PointCloud2]:::white --&gt; patchwork([ /patchwork_node]):::light\n    patchwork --&gt; p\n    p[ /nonground&lt;br/&gt;sensor_msgs::PointCloud2]:::white --&gt; cluster([ /cluster_node]):::light\n    cluster --&gt; f1[ /clustered_points&lt;br/&gt;sensor_msgs::PointCloud2]:::white\n    cluster --&gt; f2[ /clustered_marker&lt;br/&gt;visualization_msgs::MarkerArray]:::white\n    classDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \n    classDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\n    classDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#15274\n    classDef dash fill:#ffffff,stroke:#152742,stroke-width:2px,color:#15274, stroke-dasharray: 5 5\n    classDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre>  Don't forget to source before ROS commands. <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 bag play /mnt/c/bag/lexus3-2024-04-05-gyor.mcap -l\n</code></pre> <p><pre><code>ros2 launch patchworkpp demo.launch.py  cloud_topic:=/lexus3/os_center/points cloud_frame:=lexus3/os_center_a_laser_data_frame\n</code></pre> Use one of the following clustering algorithms:</p> <p><pre><code>ros2 launch lidar_cluster dbscan_spatial.launch.py\n</code></pre> DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a non-grid based clustering algorithm. On a modern 6-core CPU or better, you can expect a performance of at least 10 Hz. </p> <p><pre><code>ros2 launch lidar_cluster euclidean_spatial.launch.py\n</code></pre> Non-grid clustering based on euclidean distance.  On a modern 6-core CPU or better, you can expect a performance of at least 5 Hz. </p> <p><pre><code>ros2 launch lidar_cluster euclidean_grid.launch.py\n</code></pre> Voxel grid based clustering based on euclidean distance. On a modern 6-core CPU or better, you can expect a performance of at least 100 Hz. </p> <pre><code>ros2 launch lidar_cluster rviz02.launch.py\n</code></pre> <p>Success</p> <p>If everything works as expected you should see a similar rviz window.  </p>"},{"location":"perception/practice_cluster/","title":"ROS 2 LIDAR Clustering","text":"<p>The goal of this short practice/workshop is to demonstrate the filtering of LIDAR data into objects. Thus, we create larger objects/clusters from individual LIDAR points. These objects can be pedestrians, cars, buildings, etc. The practice is compatible with ROS 2. </p>"},{"location":"perception/practice_cluster/#requirements-high-level-overview","title":"Requirements (high-level overview)","text":"<ol> <li>ROS 2 Humble: \ud83d\udfe0 see previous materials or docs.ros.org/en/humble/Installation.html</li> <li>Log file with raw LIDAR data (MCAP format, bag) \u2705</li> <li>The <code>patchworkpp</code> package for ground plane filtering \u2705</li> <li>The <code>lidar_cluster</code> package for clustering execution \u2705</li> </ol>"},{"location":"perception/practice_cluster/#video-overview","title":"Video Overview","text":"<p>The following screen recording demonstrates the necessary steps:</p>"},{"location":"perception/practice_cluster/#step-1-download-the-raw-data","title":"<code>Step 1.</code> - Download the raw data","text":"<p>To cluster LIDAR data, we first need LIDAR data. Use one of the following 3 options.</p>"},{"location":"perception/practice_cluster/#option-a-download-mcap-from-the-link-below","title":"<code>Option A</code>: Download MCAP from the link below","text":"<p>Download MCAP [~540MB]  </p> <p>In our examples, the <code>.mcap</code> file is saved to the <code>/mnt/c/bag/</code> folder. If you want to use another directory, please modify accordingly.</p>"},{"location":"perception/practice_cluster/#option-b-download-mcap-via-your-terminal","title":"<code>Option B</code>: Download MCAP via your terminal","text":"Don't forget to change the directory first.  In our case, `/mnt/c/bag/` is the place where we will put it:  <pre><code>cd /mnt/c/bag/\n</code></pre> <pre><code>wget https://laesze-my.sharepoint.com/:u:/g/personal/herno_o365_sze_hu/Eclwzn42FS9GunGay5LPq-EBA6U1dZseBFNDrr6P0MwB2w?download=1  -O lexus3-2024-04-05-gyor.mcap\n</code></pre>"},{"location":"perception/practice_cluster/#option-c-use-your-own-mcap","title":"<code>Option C</code>: Use your own MCAP","text":"<p>You can use your own MCAP file, but in this case, you need to modify the following:</p> <ul> <li>The LIDAR topic</li> <li>In our example, this is <code>/lexus3/os_center/points</code></li> <li>LIDAR frame</li> <li>In our example, this is <code>lexus3/os_center_a_laser_data_frame</code></li> </ul> <p>Later, don't forget to update these in the subsequent steps.</p>"},{"location":"perception/practice_cluster/#verify-the-raw-data","title":"Verify the raw data","text":"<p>Play the bag with a command similar to the following: <pre><code>ros2 bag play /mnt/c/bag/lexus3-2024-04-05-gyor.mcap -l\n</code></pre></p> <p>Info</p> <p>The <code>-l</code> switch in the <code>play</code> command means loop playback.</p> <p>Success</p> <p>If everything works as expected, you should see multiple topics in another terminal   Topics In another terminal, issue the following command: <p><pre><code>ros2 topic list\n</code></pre> You should see a similar topic list:</p> <p><pre><code>/clock\n/events/read_split\n/lexus3/gps/duro/current_pose\n/lexus3/gps/duro/imu\n/lexus3/gps/duro/mag\n/lexus3/gps/duro/navsatfix\n/lexus3/gps/duro/status_flag\n/lexus3/gps/duro/status_string\n/lexus3/gps/duro/time_diff\n/lexus3/gps/duro/time_ref\n/lexus3/os_center/points\n/lexus3/os_left/points\n/lexus3/os_right/points\n/lexus3/zed2i/zed_node/left/image_rect_color/compressed\n/parameter_events\n/rosout\n/tf\n/tf_static   \n</code></pre> </p> <p>Also, there must be at least one <code>sensor_msgs/msg/PointCloud2</code>, check with: <pre><code> ros2 topic type /lexus3/os_center/points\n</code></pre> Result: <pre><code>sensor_msgs/msg/PointCloud2\n</code></pre></p>"},{"location":"perception/practice_cluster/#step-2-install-ros-2-packages","title":"<code>Step 2</code> - Install <code>ROS 2</code> packages","text":"<p>Info</p> <p>If you don't have a <code>~/ros2_ws/</code> workspace, you will need the following command: <pre><code>mkdir -p ~/ros2_ws/src\n</code></pre> If you have a different workspace name, modify the following commands accordingly.</p>"},{"location":"perception/practice_cluster/#clone-patchworkpp-package","title":"Clone <code>patchworkpp</code> package","text":"<p>The <code>patchwork-plusplus-ros</code> is the ROS 2 package of Patchwork++ (@ IROS'22), providing fast and robust LIDAR ground segmentation. We recommend the JKK-research fork, which includes some improvements, or you can use the original KAIST version.</p> <p><pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/jkk-research/patchwork-plusplus-ros\n</code></pre> or <pre><code>git clone https://github.com/url-kaist/patchwork-plusplus-ros -b ROS2\n</code></pre></p>"},{"location":"perception/practice_cluster/#clone-lidar_cluster-package","title":"Clone <code>lidar_cluster</code> package","text":"<pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/jkk-research/lidar_cluster_ros2\n</code></pre>"},{"location":"perception/practice_cluster/#build-the-packages","title":"Build the packages","text":"<pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select patchworkpp lidar_cluster --symlink-install\n</code></pre>"},{"location":"perception/practice_cluster/#step-3-execution","title":"<code>Step 3</code> - Execution","text":""},{"location":"perception/practice_cluster/#what-is-the-expected-operation","title":"What is the expected operation?","text":"<pre><code>graph TD;\n\n    p1[ /lexus3/os_center/points&lt;br/&gt;sensor_msgs::PointCloud2]:::white --&gt; patchwork([ /patchwork_node]):::light\n    patchwork --&gt; p\n    p[ /nonground&lt;br/&gt;sensor_msgs::PointCloud2]:::white --&gt; cluster([ /cluster_node]):::light\n    cluster --&gt; f1[ /clustered_points&lt;br/&gt;sensor_msgs::PointCloud2]:::white\n    cluster --&gt; f2[ /clustered_marker&lt;br/&gt;visualization_msgs::MarkerArray]:::white\n    classDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \n    classDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\n    classDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#15274\n    classDef dash fill:#ffffff,stroke:#152742,stroke-width:2px,color:#15274, stroke-dasharray: 5 5\n    classDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre>  Don't forget to source <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 bag play /mnt/c/bag/lexus3-2024-04-05-gyor.mcap -l\n</code></pre> <p><pre><code>ros2 launch patchworkpp demo.launch.py  cloud_topic:=/lexus3/os_center/points cloud_frame:=lexus3/os_center_a_laser_data_frame\n</code></pre> Use one of the following clustering algorithms:</p> <p><pre><code>ros2 launch lidar_cluster dbscan_spatial.launch.py\n</code></pre> DBSCAN (Density-Based Spatial Clustering of Applications with Noise) is a non-grid-based clustering algorithm. On a modern 6-core or better CPU, you can expect at least 10 Hz performance.</p> <p><pre><code>ros2 launch lidar_cluster euclidean_spatial.launch.py\n</code></pre> Non-grid clustering based on Euclidean distance. On a modern 6-core or better CPU, you can expect at least 5 Hz performance. </p> <p><pre><code>ros2 launch lidar_cluster euclidean_grid.launch.py\n</code></pre> Voxel grid-based clustering based on Euclidean distance. On a modern 6-core or better CPU, you can expect at least 100 Hz performance.</p> <pre><code>ros2 launch lidar_cluster rviz02.launch.py\n</code></pre> <p>Success</p> <p>If everything works as expected, you should see a similar rviz window. </p>"},{"location":"perception/practice_cluster/#links","title":"Links","text":"<ul> <li>English version of clustering jkk-research.github.io/workshops/clustering_a </li> </ul>"},{"location":"perception/road_filter/","title":"Road filter","text":""},{"location":"perception/slam/","title":"SLAM and LOAM","text":"<p>Simultaneous localization and mapping (SLAM) and LIDAR-based odometry and mapping (LOAM).</p> <p>A global point cloud compiled from a measurement in Gy\u0151r:</p> <p></p>"},{"location":"perception/slam/#direct-lidar-inertial-odometry","title":"Direct LIDAR-Inertial Odometry","text":"<p>DLIO is a lightweight LIDAR-inertial odometry algorithm that generates a continuous trajectory using a novel coarse-to-fine approach.</p> <p></p>"},{"location":"perception/slam/#installation","title":"Installation","text":"<p>Available:</p> <ul> <li>github.com/vectr-ucla/direct_lidar_inertial_odometry/tree/feature/ros2 ROS 2 branch</li> <li>github.com/jkk-research/direct_lidar_inertial_odometry fork containing only the ROS 2 branch</li> </ul> <p>Let's check if <code>pcl-ros</code> <pre><code>sudo apt install ros-humble-pcl-ros\n</code></pre></p> <pre><code>cd ~/ros2_ws/src/\n</code></pre> <pre><code>git clone https://github.com/jkk-research/direct_lidar_inertial_odometry\n</code></pre> <pre><code>cd ~/ros2_ws/\n</code></pre> <pre><code>colcon build --packages-select direct_lidar_inertial_odometry\n</code></pre>"},{"location":"perception/slam/#building-the-package","title":"Building the package","text":"<pre><code>cd ~/ros2_ws/src/\n</code></pre> <pre><code>git clone https://github.com/PRBonn/kiss-icp\n</code></pre> <pre><code>cd ~/ros2_ws/\n</code></pre> <pre><code>colcon build --packages-select kiss_icp\n</code></pre>"},{"location":"perception/slam/#launch","title":"Launch","text":"<pre><code>ros2 launch kiss_icp odometry.launch.py topic:=/lexus3/os_left/points\n</code></pre>"},{"location":"perception/slam/#linkes","title":"Linkes","text":"<ul> <li>fastcampus_slam_codes tutorial: github.com/changh95/fastcampus_slam_codes</li> <li>learn opencv: learnopencv.com/lidar-slam-with-ros2</li> </ul>"},{"location":"planning/","title":"Planning","text":"<p>We can distinguish between global planning and local planning.</p> <p></p> <p>Planning as a concept answers the question of how to get from point A to point B under the appropriate criteria. Planning has two sub-parts: path or route planning, which tells you where to go on a given segment, and trajectory planning, which tells you at what speed the vehicle should travel on the given segment.</p> <p>Depending on the nature of the planning task, we distinguish between global and local planning. The differences between the two planning methods are summarized in the table below:</p> Global Planning Local Planning Map-based Sensor-based Known terrain/work area Unknown area Path planning occurs before movement Path planning and movement occur simultaneously No strict requirement on computation time Requirement to operate in real-time <p>The result of planning, in both local and global cases, is a segment divided into discrete points, each containing position, orientation, and speed information, which we call a trajectory: .</p> <pre><code>flowchart LR\nsubgraph Plan [Planning]\n    G[Global&lt;br/&gt;Planning]:::red --&gt;|route| L[Local&lt;br/&gt;Planning]:::red\nend\nsubgraph Perception [Perception]\n    T[Mapping&lt;br/&gt;/Perception/]:::light \n    H[Localization&lt;br/&gt;/Perception/]:::light\n    P[Prediction&lt;br/&gt;/Perception/]:::light \nend\nT ---&gt;|map| L\nH ---&gt;|pose| L\nP ---&gt;|predicted objects| L\nsubgraph Control [Control]\n    L --&gt; |trajectory| S[Control]:::light \nend\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre>"},{"location":"planning/#global-planning","title":"Global Planning","text":""},{"location":"planning/#introduction","title":"Introduction","text":"<p>The following German-language video with English PPT and subtitles is part of the TU Munich curriculum and provides a good summary of the topic:</p> <p>The PDF file associated with the video is available here</p> <p>Well-known global planning algorithms: - RRT (Rapidly exploring random tree): RRT is a sampling-based method for exploring and planning paths in a global space. Note: In some cases, it is also used as a local planner. The algorithm randomly selects points and extends the tree by connecting new points to the nearest existing points. More information: en.wikipedia.org/wiki/Rapidly_exploring_random_tree. - Informed-RRT: Informed-RRT is an extension of the basic RRT that uses heuristics for more efficient exploration towards the goal. The algorithm plans paths by first exploring closer areas and then moving towards more distant areas in later phases. - A-star: The A algorithm (pronounced \"A star\") is a graph traversal and pathfinding algorithm known for its completeness and efficiency. One of its main practical drawbacks is its $$ O(b^{d}) $$ space complexity, as it stores all generated nodes in memory. Therefore, in practical pathfinding systems, algorithms that can preprocess the graph for better performance often outperform it. More information: hu.wikipedia.org/wiki/A*_algoritmus. - D-star: The D algorithm (pronounced \"D star\") stands for \"Dynamic A-star\". This algorithm is a modified version of the A algorithm that can be used in dynamic environments. The Dynamic A-star algorithm continuously updates the path as the robot moves along it to adapt to changing conditions or obstacles. More information: en.wikipedia.org/wiki/D*. - Dijkstra*: The Dijkstra algorithm is one of the most well-known and widely used algorithms for finding the shortest path in a graph. It is a breadth-first search algorithm that iteratively expands the tree from the starting point and selects the nearest unvisited vertex. More information: en.wikipedia.org/wiki/Dijkstra's_algorithm.</p> <p>It is worth noting that there are many variations and improvements of the above algorithms.</p>"},{"location":"planning/#traveling-salesman-problem","title":"Traveling Salesman Problem","text":"<p>The traveling salesman problem (TSP) is a well-known combinatorial optimization problem that emerged in the fields of computer science and mathematics. The essence of the problem is that the traveling salesman must visit a set of given cities and return to the starting city by the shortest possible route, visiting each city exactly once. More information: hu.wikipedia.org/wiki/Az_utaz\u00f3_\u00fcgyn\u00f6k_probl\u00e9m\u00e1ja.</p> <p>Formally, let there be a directed weighted graph, where the nodes represent the cities, the edges represent the roads between the cities, and the weights represent the lengths of the edges. The goal is to find a Hamiltonian circuit (a circuit that touches each node exactly once) with minimal total weight. The problem belongs to the NP-hard class, which means that there is no known efficient algorithm that always guarantees finding the optimal solution in polynomial time proportional to the number of cities.</p> <p>In the context of autonomous vehicles and robotics, it is often not the classic TSP problem that arises, but its derivative, since, for example, in the case of an autonomous vehicle, we know exactly where we are starting from and where we are going. This condition is not known in the classic traveling salesman problem.</p>"},{"location":"planning/#local-planning","title":"Local Planning","text":""},{"location":"planning/#introduction_1","title":"Introduction","text":"<p>The following German-language video with English PPT and subtitles is part of the TU Munich curriculum and provides a good summary of the topic:</p> <p>The PDF file associated with the video is available here.</p>"},{"location":"planning/#motivation","title":"Motivation","text":"<p>Local planning is essentially the planning response to dynamically changing conditions measured in real-time. What do we mean by this? The simplest example is if we compare global planning to planning a route (e.g., how to get from A to B), local planning is similar to the task of navigating in a given lane under given traffic conditions. However, we can see that a planning level's \"local\" and \"global\" nature does not always separate 100% from each other. For example, we plan to travel on the M1 motorway. Within this, there are several lanes, so which one should we choose? By default, we choose the outer lane, which we can consider the global trajectory. However, during the journey, we need to change lanes and follow the inner lane. We do this several times during a trip. Thus, the lane we want to follow will sometimes be the inner lane and sometimes the outer lane. We cannot predict this in advance, so we do not satisfy the initial global trajectory definition. We can consider it a local planning problem, but the decision to follow the inner or outer lane does not depend on external factors, only on the decision itself (e.g., we change lanes because of a car in front of us), but once we have changed lanes, the new lane's path does not depend on dynamic factors again. We can resolve these contradictions in several ways: - We consider a pre-planned route as global (in this case, this is the outer lane), and any modification is local, or - We consider traveling on the motorway as a global route, which does not depend on the lanes, introduce an intermediate level, call it a global trajectory, which in this case means two alternative routes (outer or inner lane), and a local trajectory, which is a modification of this based on real-time information, or - The global trajectory is not fixed but can change over time, but only rarely, if an external trigger signal is given (e.g., lane change).</p> <p>In this chapter, we will cover the basics necessary for planning a local trajectory, so in the following, we will focus exclusively on this level. The local planning task in the above example can be described as follows: - There is a global route (e.g., lane) that we take as a basis, - Real-time variables (e.g., other vehicles) must be considered, - The path must always be drivable by the vehicle, i.e., stable from the perspective of the following control and comfortable for the passengers; we can briefly call this a \"kinematically well-conditioned\" path, - The path must be safe, i.e., it should not violate boundaries and should maintain a safe distance from other objects.</p> <p>To achieve these goals, we need to know the exact global route, measure the dynamic variables, know the vehicle, and understand what \"comfort\" means for the passengers. It is also important to note that the local path is often not just a set of points. We use some model to represent the trajectory, i.e., we describe it in a geometrically compact form. In practice, this can mean polynomial form, Euler curves, splines, etc. These curve descriptions all describe a curve with a finite number of parameters. To get a point on the curve, we evaluate the function describing the curve at a given X distance. This approach is useful because it allows us to describe long curves with few parameters, saving memory and runtime during implementation. Furthermore, the derivatives of the equation provide additional quantities (e.g., orientation, curvature), which can be easily generated for control.</p>"},{"location":"planning/#local-planning-algorithms","title":"Local Planning Algorithms","text":"<p>As we saw in the introductory video, it is difficult to categorize and systematize local solutions, as the solutions often do not purely use one methodology. An example is the State Lattice planner, which works on a grid-like structure but uses graph-like search. Here we list some well-known local planning algorithms and algorithm families that have open-source implementations:</p> <ul> <li> <p>DWA (Dynamic Window Approach): In robotics/autonomous motion planning, the DWA approach is an online collision avoidance strategy for path planning and navigation in dynamic environments. As the name suggests, the robot/vehicle pushes a dynamic window in front of it during progress. It considers several possible directions (more precisely, trajectories) and then selects the state with the lowest cost. More information: en.wikipedia.org/wiki/Dynamic_window_approach.</p> </li> <li> <p>TEB (Timed Elastic Band): The TEB algorithm is also used for online trajectory planning and tracking of moving robots in dynamic environments. It is particularly useful for non-holonomic robots (such as cars) with limited degrees of freedom. The method locally optimizes the robot's path concerning travel time, separation from obstacles, and adherence to kinodynamic constraints during execution. The name refers to an elastic band that can be easily bent in the desired direction. More information: github.com/rst-tu-dortmund/teb_local_planner.</p> </li> <li>State Lattice: The kinodynamic constraints of the robot/vehicle are encoded in the state lattice graph, and any path in this graph is feasible. After constructing the graph, any graph search algorithm can be used for planning. More information: navigation.ros.org/configuration/packages/smac/configuring-smac-lattice.html</li> <li>RRT (Rapidly exploring random tree): RRT was already mentioned in global planning but is also used in local methods.</li> </ul> <p>Algorithm families:</p> <ul> <li>Graph-based solutions: These include solutions that use a graph to search in continuous space. Often, some local map model is used as an aid, such as Lanelet2. Examples include the Autoware obstacle_avoidance_planner.</li> <li>Grid-based solutions: These algorithms use a grid that results from discretizing continuous space. Terms like voxel grid and occupancy grid are often used to describe the discrete space. More information: github.com/jkk-research/pointcloud_to_grid, github.com/ANYbotics/grid_map. Some DWA solutions belong to this family.</li> <li>Potential field-based solutions: In artificial potential field (APF) planning, the robot is modeled with attractive and repulsive forces from objects in the environment. Unlike grid-based methods, the field itself dictates how far to stay from an object, while in grid-based methods, the planner determines this. Another difference is that the potential field is continuous, while the grid space is discrete. More information: en.wikipedia.org/wiki/Motion_planning#Artificial_potential_fields, and an APF-based solution can be found here.</li> <li>Frenet frame-based solutions: In the Frenet coordinate system, the robot's state is given in two dimensions: longitudinal and lateral positions. The longitudinal axis contains the robot's current position and speed, while the lateral axis contains the robot's position relative to the path. More information: roboticsknowledgebase.com/wiki/planning/frenet-frame-planning/</li> </ul> <p>Note: The TU Munich curriculum similarly categorizes local planning algorithms but with different emphases: Graph-Based methods, Variational methods, Incremental Methods, Hybrid Methods.</p>"},{"location":"planning/#design-example","title":"Design Example","text":"<p>The example in this chapter is taken from the work of Werling et al. [1]. This example presents a general planning problem that includes most of the above aspects. Two important points to note: - We separate the lateral and longitudinal planning problems, and - Lateral planning is done in the so-called Frenet frame.</p>"},{"location":"planning/#lateral-planning","title":"Lateral Planning","text":"<p>Lateral planning involves designing the curve of the path. First, we introduce the concept of the Frenet frame. Its illustration is shown in Figure 1. The Frenet frame is a coordinate system that runs along an arbitrary curve (in this case, e.g., the lane center or the global trajectory) as a function of the parameter \\(\\(s(t)\\)\\). We call the arbitrary curve the reference line. In the Frenet frame, the coordinate of the reference curve is all zeros (its deviation from itself is zero). When interpreting the points of a planned trajectory in this coordinate system, it is easy to express if we want the trajectory to coincide with the reference curve. For example, if we want a planned trajectory to end on the reference path, its endpoint in the Frenet frame would be \\(\\([0; 0]\\)\\). The non-zero distance gives the deviation from the reference line. For example, if we consider the lane center as the reference, the deviation from it is the distance in the Frenet frame, which is an intuitive approach since humans often consider the lane center as a reference and the deviation from it as a significant quantity.</p> <p> Figure 1: Illustration of the Frenet frame along the planned trajectory, source: [1]</p> <p>We examine the lateral planning problem exclusively at high speeds (&gt;30-40kph). For this case, Werling et al. consider it as an optimization problem. The essence is that at any given state, we determine a polynomial with the smallest cost. By choosing different costs and weights, various trajectories can be planned. The two possible outcomes of the planning in the Frenet frame are shown in Figure 2. Suppose the dashed line is the lane center, which will be the reference line or the global trajectory. The thick line is the locally planned trajectory, aiming to guide the vehicle onto the global trajectory. The starting point can be any chosen point (e.g., the vehicle's position or the last point of the previous valid local trajectory, etc.). The horizontal direction represents the independent variable. Its value ranges from 0 to a maximum value, which can be considered the domain of the curve's equation. What is important for us when designing the curve? Firstly, it should start at the starting point and end at the endpoint (surprisingly). Additionally, we can treat the initial and final orientations as given values (e.g., the initial orientation matches the vehicle's orientation, and the final orientation matches the reference line's orientation). We call the initial and final conditions boundary conditions. If necessary, we can specify additional boundary conditions.</p> <p> Figure 2: Possible outcomes of planning in the Frenet frame, source: [1]</p> <p>During polynomial fitting, we look for polynomials that satisfy the boundary conditions. In Figure 2, we can see that multiple polynomials can satisfy these conditions simultaneously. Figure 3 shows such possible polynomials. It is evident that not all curves reach the reference line (the horizontal axis) at the same point, so we can distinguish different shaped curves based on their length. All of these satisfy the boundary conditions, but due to their different shapes, they will result in different kinematic properties when the car follows them. To decide which curve is the best for us, we introduce the so-called cost function. The cost function is a function that determines how good a given curve is according to our freely chosen criteria. We sum the costs. However, not all criteria are equally important, so their costs are not equally relevant. Thus, we use weights to decide which are the most significant and which are the least interesting criteria. We determine the total cost for all possible curves and then select the curve with the smallest cost. This will be our final trajectory, which is the optimal solution to the problem (optimal, meaning not zero cost, but the smallest cost solution considering the circumstances). We call the process optimization, and the length of the trajectory is the optimization variable.</p> <p> Figure 3: Possible outcomes of planning in the Frenet frame, source: [1]</p> <p>What we consider optimal depends on the cost function. It generally includes conflicting terms: the trajectory length should be as short as possible (reach the goal as quickly as possible), but the resulting lateral vehicle acceleration should be as small as possible (comfort condition). These contradict each other, so an intermediate good, i.e., optimal trajectory will be born. We can introduce additional costs, e.g., the amount of overshoot (the extent of crossing into the other lane), initial jerk, quickness of settling, etc. By changing the weights, we can implement different preferences, e.g., aggressive maneuver or comfortable maneuver. Additionally, we exclude trajectories that do not meet safety requirements, e.g., crossing into the other lane.</p> <p>Werling et al. determined a fifth-degree polynomial to describe the curve. In the Frenet frame, the equation of the curve is:</p> \\[ x(s) = c_{0} + c_{1}s + c_{2}s^{2}+c_{3}s^{3}+c_{4}s^{4}+c_{5}s^{5} \\] <p>We see that the curve is defined by 6 parameters, the 6 coefficients from c0 to c5. To determine all coefficients, we need 6 boundary conditions: - The initial and final point deviation from the reference line, - The initial and final point orientation deviation from the reference line, - And the curvature of the planned trajectory at the initial and final points.</p> <p>Arranged in vector form: $$ [d_{0}\\ d_{1}\\ \\theta_{0}\\ \\theta_{1}\\ \\kappa_{0}\\ \\kappa_{1}]$$</p> <p>We can choose these arbitrarily. Based on the above explanation, let: \\(\\([d_{0}\\ d_{1}\\ \\theta_{0}\\ \\theta_{1}\\ \\kappa_{0}\\ \\kappa_{1}]=[d_{0}\\ 0\\ \\theta_{0}\\ 0\\ 0\\ 0]\\)\\) i.e., the vehicle's position at the initial point relative to the reference line, the reference line at the endpoint, and the curvatures are zero, i.e., the curvatures of the reference line at the initial and final points. Using the boundary conditions, we can write a system of equations with 6 unknowns and 6 equations: $$ x(s=0) = c_{0} = d_{0}$$ $$ x'(s=0) = c_{1} = \\theta_{1}$$ $$ x''(s=0) = 2c_{2} = \\kappa_{1}$$ $$ x(s=s_{1}) = c_{0} + c_{1}s + c_{2}s_{1}^{2}+c_{3}s_{1}^{3}+c_{4}s_{1}^{4}+c_{5}s_{1}^{5} $$ $$ x'(s=s_{1}) = c_{1}s + 2c_{2}s_{1}+3c_{3}s_{1}^{2}+4c_{4}s_{1}^{3}+5c_{5}s_{1}^{4} $$ $$ x''(s=s_{1}) = 2c_{2}+6c_{3}s_{1}+12c_{4}s_{1}^{2}+20c_{5}s_{1}^{3} $$</p> <p>where \\(s_{1}\\) is the distance to the endpoint. This will be the variable of the above optimization problem. By varying this quantity over an arbitrary range (e.g., between \\(s_{1,max}\\) and \\(s_{1,min}\\)), we look for the set of coefficients for which the cost function \\(\\(J\\)\\) is the smallest. How should we choose the \\(J\\) function? For this, Werling et al. recommend the following formula:</p> \\[ C_{d} = k_{j}J_{t}(d(t)) + k_{t}T + k_{d}(d_{1})^{2} \\] <p>Where \\(T = \\dfrac{s_{1}}{v_{x}}\\) is the length of the trajectory expressed in time, \\(J_{t}\\) is the so-called jerk (the derivative of lateral acceleration), and \\(d_{1}\\) is the final point's distance from the reference line. We chose this to be \\(d_{1}=0\\), so this term drops out.</p>"},{"location":"planning/#longitudinal-planning","title":"Longitudinal Planning","text":"<p>Longitudinal planning can work similarly to lateral planning. In this case, the global trajectory can be thought of as a series of target speeds along the route. In contrast, the local trajectory involves planning the actual speed according to local conditions. We consider the movement of other objects, target vehicle kinematics, speed limits, etc. This is illustrated in Figure 4. Normally, we maintain the maximum speed. When we encounter another vehicle ahead, we brake and match its speed. During braking, we plan a speed profile to ensure a safe distance from the other vehicle, avoiding sudden or premature braking. We then follow the other vehicle, maintaining this distance within certain limits. When we see an even slower vehicle (e.g., a cyclist), we further reduce our speed. Once the obstacle is gone, we accelerate back to the allowed speed. We always consider our own acceleration and deceleration preferences.</p> <p> Figure 4: Illustration of local speed trajectory</p> <p>It is evident that, similar to lateral planning, we need to plan the best possible profile under given conditions. This is also an optimization problem. Werling et al. recommend a fifth-degree polynomial for the target speed function in this case as well:</p> \\[ v(s(t)) = c_{0} + c_{1}s + c_{2}s^2+c_3s^3+c_4s^4+c_5s^5 \\] <p>The mechanism is the same: we formulate 6 boundary conditions and use them to plan trajectories. We select the one with the lowest cost. In the case of following another vehicle, the final conditions are:</p> \\[ [s_1\\ \\dot{s_1}\\ \\ddot{s_1}\\ T] = [(s_{target}(T_j)+\\delta s_i),\\ \\dot{s}_{target}(T_j),\\ {\\ddot{s}}_{target}(T_j),\\ T_j] \\] <p>The initial conditions are:</p> \\[ [s_0\\ \\dot{s_0}\\ \\ddot{s_0}\\ T] = [s_{target}(0),\\ \\dot{s}_{ego}(0),\\ {\\ddot{s}}_{ego}(0),\\ 0] \\] <p>That is, the initial conditions are given by the object's distance and our vehicle's speed and acceleration. All trajectories planned in such a cycle are shown in Figure 5. The black ones are valid trajectories, the gray ones are invalid (e.g., too high acceleration), the blue one is the object's movement, and the green one is the optimal trajectory. The cost function can be:</p> \\[ C_t = k_jJ_t + k_tT+k_s[s_1-s_d]^2 \\] <p>Where \\(J_t\\) is the average jerk experienced during the trajectory, \\(T\\) is the trajectory length in time, and \\(s_1-s_d\\) is the distance from the object at the end of the trajectory. The \\(k\\) factors are the weights.</p> <p> Figure 5: Speed trajectory planning, source: [1]</p>"},{"location":"planning/#ros-2-solutions","title":"ROS 2 Solutions","text":""},{"location":"planning/#nav2","title":"Nav2","text":"<p>Nav2 is the supported successor of the ROS Navigation Stack, applying the same technology for mobile robotics and autonomous vehicles, optimized and reworked. The Nav2 project aims to find a safe way for a mobile robot to perform complex tasks across various environments and robot kinematic classes. It can not only move from point A to point B but also handle intermediate poses (position + orientation) and other tasks like object tracking, full coverage navigation, etc. Nav2 is a production-level, high-quality navigation framework trusted by over 50 companies worldwide.</p> <p>Overview of the Nav2 architecture: </p>"},{"location":"planning/#autoware-planner","title":"Autoware Planner","text":"<p>The Autoware framework's planning component is also ROS 2 supported. The main function of the Autoware planning component is to create the trajectory that the Control component subscribes to, based on the environmental state received from the Localization and Perception components.</p> <p></p>"},{"location":"planning/#references","title":"References","text":"<ul> <li><code>[1]</code> Moritz Werling, Julius Ziegler, S\u00f6ren Kammel, and Sebastian Thrun: Optimal Trajectory Generation for Dynamic Street Scenarios in a Fren\u00e9t Frame, 2010 IEEE International Conference on Robotics and Automation, Anchorage Convention District, May 3-8, 2010, Anchorage, Alaska, USA, pp. 987-993</li> <li><code>[2]</code> github.com/ai-winter/ros_motion_planning: ROS 1, but planned for ROS 2 Global planners: Dijkstra, A-star, D-star, RRT, Informed-RRT, GBFS Local planners: LQR (Linear\u2013quadratic regulator), DWA (Dynamic Window Approach), APF, RPP, TEB (Timed Elastic Band)</li> </ul>"},{"location":"planning/#additional-articles","title":"Additional Articles","text":"<p>A collection of articles related to the presented algorithms and gathered from the python_motion_planning repository:</p>"},{"location":"planning/#global-planners","title":"Global Planners","text":"<ul> <li>A* - A-star: A Formal Basis for the heuristic Determination of Minimum Cost Paths</li> <li>Modified A-Star: Efficient and optimal penetration path planning for stealth unmanned aerial vehicle using minimal radar cross-section tactics and modified A-Star algorithm</li> <li>Lifelong Planning A*: Lifelong Planning A*</li> <li>D* - D-star: Optimal and Efficient Path Planning for Partially-Known Environments</li> <li>D* Lite: D* Lite</li> <li>JPS: Online Graph Pruning for Pathfinding On Grid Maps</li> <li>Theta*: Theta*: Any-Angle Path Planning on Grids</li> <li>Lazy Theta*: Lazy Theta*: Any-Angle Path Planning and Path Length Analysis in 3D</li> <li>S-Theta*: S-Theta*: low steering path-planning algorithm</li> <li>RRT: Rapidly-Exploring Random Trees: A New Tool for Path Planning</li> <li>RRT-Connect: RRT-Connect: An Efficient Approach to Single-Query Path Planning</li> <li>RRT*: Sampling-based algorithms for optimal motion planning</li> <li>Informed RRT*: Optimal Sampling-based Path Planning Focused via Direct Sampling of an Admissible Ellipsoidal heuristic</li> <li>ACO: Ant Colony Optimization: A New Meta-Heuristic</li> </ul>"},{"location":"planning/#local-planners","title":"Local Planners","text":"<ul> <li>DWA: The Dynamic Window Approach to Collision Avoidance</li> <li>APF: Real-time obstacle avoidance for manipulators and mobile robots</li> <li>RPP: Regulated Pure Pursuit for Robot Path Tracking</li> </ul>"},{"location":"planning/planning_control_diagram/","title":"Planning control diagram","text":"<pre><code>flowchart LR\n\nGP1[Global planning\n  Inputs:\n  - Driver/User selection\n  -Mapdata\n  Output:\n  -Routeplan\n  Goal: to plan a global \n  route which leads from A\n  to B, considering e.g., \n  trafficdata,fuel\n  consumption\u2026 etc.]:::light \nGP2[I want to get \n  from address A \n  to address B \n  with a robotaxi]:::dark\n\nBP1[Behavior planning\n    Inputs:\n    -Route plan\n    -Perception info of\n    the surroundings\n    Output:\n    -Behavior strategy \n    Goal: \n    plan how the \n    vehicle should \n    behave in terms of \n    decisions and motion \n    characteristics\n]:::light \n\nBP2[I want to follow the\nmiddle lane then\n change to the inner\n lane smoothly]:::dark\n\nLP1[\n    Local planning\n    Inputs:\n    -Behavior strategy\n    -Planning constraints\n    Output:\n    -Local trajectory\n    Goal: plan a \n    kinematicly feasible,\n    safe and preferred\n    trajectory]:::light \nLP2[I plan a trajectory\nwithin the lane to be\nsafe and then a\nsmooth trajectory to\nthe inner lane]:::dark\n\n\nVC1[ Vehicle Control \n    High level control\n    Inputs:\n    -Local trajectory\n    -Vehicle state variables\n    -Localization info \n    Outputs:\n    -Vehicle level target \n    quantities\n    -Control constraints \n    Goal: calculate the\n    vehicle target state to \n    be controlled by the\n    low level controllers]:::light \nVC2[ I calculate the\n necessary speed and \n yaw rate of the \n vehicle to follow the \n local trajectory]:::dark\n\n\nAC1[ Actuator Control\nLow  level control\nInputs:\n-Vehicle level target \nquantities\n-Control constraints\n-Actuator state variables\nOutput:\n-Actuator target states \nGoal: realize vehicle \nmotion through \ncontrolling the \nactuators]:::light \nAC2[ I calculate the \nnecessary engine \ntorque and steering\nangle to realize the \nplanned motion\u2019]:::dark\n\n\nsubgraph Plan [Planning]\n  GP1\n  BP1\n  LP1\nend\nsubgraph Control [Control]\n  VC1\n  AC1\nend\nGP1--&gt;BP1--&gt;LP1--&gt;VC1--&gt;AC1\nGP2-.-BP2-.-LP2-.-VC2-.-AC2\n\n\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n</code></pre>"},{"location":"planning/practice/","title":"<code>1.</code> Task","text":"<p>In this task, we will demonstrate the implementation of the polynomial-based local planner presented in the theoretical class. First, let's update the arj_packages repository!</p>"},{"location":"planning/practice/#clone-and-build","title":"Clone and Build","text":"<p><pre><code>cd ~/ros2_ws/src/arj_packages/\n</code></pre> <pre><code>git pull\n</code></pre> Then build the package named arj_local_planner!</p> <p><pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select arj_local_planner\n</code></pre></p>"},{"location":"planning/practice/#execution","title":"Execution","text":"<p>Next, let's run the planner using the launch file after sourcing.</p> <p><pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 launch arj_local_planner run_all.launch.py\n</code></pre></p> <p>Check which topics have been created (in a new terminal)!</p> <pre><code>ros2 topic list\n</code></pre> <p>The /goal_pose topic and the /planner/trajectory topic have been created. The goal_pose is the target position for the planner, and the planner/trajectory is the waypoint list, the planned trajectory itself. Let's start an rviz!</p> <pre><code>ros2 run rviz2 rviz2\n</code></pre> <p>Select the map frame and add the /planner/trajectory topic. Then, using the 2D Goal Pose option from the top bar, set a goal pose on the grid in the positive coordinate direction! The planner will automatically fit a polynomial to the target position.</p> <p></p> <p>This simple planner can be used for moving targets (another vehicle, lane center, a point on the global trajectory, etc.) or static targets (e.g., parking spot).</p>"},{"location":"planning/practice/#2-task","title":"<code>2.</code> Task","text":"<p>The second task is to set up the ROS 2 Navigation stack in a simulator on an empty track. Detailed documentation can be found on navigation.ros.org.</p>"},{"location":"planning/practice/#clone-and-build_1","title":"Clone and Build","text":"<p><pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/rosblox/nav2_outdoor_example\n</code></pre></p> <p><pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>rosdep install -y --from-paths src --ignore-src --rosdistro $ROS_DISTRO\n</code></pre></p> <p><pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select nav2_outdoor_example\n</code></pre></p>"},{"location":"planning/practice/#execution_1","title":"Execution","text":"<p><pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 launch nav2_outdoor_example bringup.launch.py\n</code></pre></p>"},{"location":"planning/practice/#3-task","title":"<code>3.</code> Task","text":"<p>The third task is to set up the ROS 2 Navigation stack in a simulator on one of the turtlebot tracks. Detailed documentation can be found on navigation.ros.org.</p>"},{"location":"planning/practice/#clone-and-build_2","title":"Clone and Build","text":"<pre><code>sudo apt install ros-humble-navigation2 ros-humble-nav2-bringup ros-humble-turtlebot3-gazebo\n</code></pre> <p><pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/ros-controls/gz_ros2_control\n</code></pre> <pre><code>git clone https://github.com/art-e-fact/navigation2_ignition_gazebo_example\n</code></pre> <pre><code>cd ~/ros2_ws/src/gz_ros2_control\n</code></pre> <pre><code>git checkout humble\n</code></pre> <pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>rosdep install -y --from-paths src --ignore-src --rosdistro humble\n</code></pre></p> <p><pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select sam_bot_nav2_gz\n</code></pre></p>"},{"location":"planning/practice/#execution_2","title":"Execution","text":"<p>Gazebo, RViz2, and Navigation2 <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 launch sam_bot_nav2_gz complete_navigation.launch.py\n</code></pre></p> <p>Setting a goal in RViz2: <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 run sam_bot_nav2_gz follow_waypoints.py\n</code></pre> <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 run sam_bot_nav2_gz reach_goal.py\n</code></pre></p> <p></p> <p></p> <p></p>"},{"location":"planning/practice/#navigation","title":"Navigation","text":""},{"location":"planning/practice/#sources","title":"Sources","text":"<ul> <li>navigation.ros.org/getting_started/index.html</li> <li>navigation.ros.org</li> <li>github.com/ros-controls/gz_ros2_control</li> <li>github.com/art-e-fact/navigation2_ignition_gazebo_example</li> </ul>"},{"location":"ros2/","title":"<code>ROS 2</code> Basics","text":"<p>ROS Versions and Installation</p> <p><code>ROS 2</code>, the latest release of <code>ROS</code>, is a set of software libraries and tools (middleware) that help in the development of robotic applications. By definition, middleware is software that connects software components. It is a layer that sits between the operating system and applications on both sides of a distributed computer network. <code>ROS 2</code> uses permissive, open-source Apache 2.0 licensing.</p> ROS 2 Overview <p>Since its release in 2007, <code>ROS</code> has undergone incremental updates, meaning no fundamental changes but continuous major improvements. In 2017, the robotics community realized that the original 2007 concept had fundamental limitations that could not be fixed incrementally. Thus, Noetic Ninjemis (supported until 2025) is the last release of <code>ROS 1</code>, and <code>ROS 2</code> was developed in parallel. This also means that previous source codes are harder to port to the new version, but in return, we get many new features, improvements, and support for developing robots and vehicles.</p> <p>As a result, <code>ROS 2</code> has transitioned from the world of academic research to industrial use. Interestingly, NASA's VIPER lunar rover also runs <code>ROS 2</code>. Additionally, automotive giants like Bosch, BMW, and Volvo use it. Many other robotics companies also use it. Links: www.nasa.gov/viper/lunar-operations, rosindustrial.org/ric/current-members, www.bosch.com/stories/bringing-robotics-middleware-onto-tiny-microcontrollers. ROS users worldwide: metrorobots.com/rosmap.html.</p> <p></p> <p>Image source: Robot Operating System 2: Design, Architecture, and Uses In The Wild: Steve Macenski et al.</p>"},{"location":"ros2/#why-use-a-framework-for-my-robotics-project","title":"Why Use a Framework for My Robotics Project?","text":"<p>For our first robotics project, we might choose to develop entirely on our own without a framework. This has its advantages (learning, execution speed, etc.). But soon, we will need an algorithm that others have implemented, but it is not compatible with the original concept. At this point, it is worth considering using a framework (e.g., <code>ROS 2</code>). Note that <code>ROS 2</code> is not the only option; there are many similar, smaller frameworks: Player, YARP, Orocos, CARMEN, Orca, MOOS, and Microsoft Robotics Studio. Each has its advantages, but in this course, we focus on <code>ROS 2</code> due to its support.</p> <p></p> <p>Image source: ros.org/blog/ecosystem</p> <ul> <li>Plumbing: ROS primarily provides a messaging system, often referred to as \"middleware\" or \"plumbing\". Communication is one of the first needs that arise when implementing a new robotics application or any software system that connects to hardware. ROS's built-in and well-tested messaging system saves time by handling communication details between decentralized nodes, so you don't have to implement it separately. Moreover, intra-process communication allows direct memory access on a single machine.</li> <li>Tools: Effective application development requires good development tools. ROS has such tools, including debugging (<code>rqt_console</code>), visualization (<code>Rviz2</code>, <code>Foxglove Studio</code>), plotting (<code>rqt_plot</code>, <code>Foxglove Studio</code>), logging (<code>mcap</code>), and playback.</li> <li>Capabilities: Whether it's a GPS device driver, walking and balance controller for a quadruped robot, or a mapping system for a mobile robot, ROS has solutions. From drivers to algorithms to user interfaces, ROS provides the building blocks that allow you to focus on your application.</li> <li>Community: ROS is backed by a large, global, and diverse community. From students and hobbyists to multinational corporations and government agencies, people and organizations from all segments drive the <code>ROS 2</code> project. This is important because many questions will arise during development. Most of these have already been answered by the community, and they are happy to answer new questions.</li> </ul> <p>The following diagram illustrates the nodes (programs) and topics (~communication) of a simple line-following robot:</p> <p><pre><code>graph TD;\n\n    camd([/cam_driver]):::red --&gt; im1[ /image1&lt;br/&gt;sensor_msgs/Image]:::light\n    im1 --&gt; li1([ /line_detect_node]):::red\n    im1 --&gt; st1([ /stop_detect_node]):::red\n    li1 --&gt; li2[ /line&lt;br/&gt;example_msgs/Line]:::light\n    st1 --&gt; st2[ /stop&lt;br/&gt;example_msgs/Stop]:::light\n    li2 --&gt; nav([ /line_detect_node]):::red\n    st2 --&gt; nav\n    nav --&gt; cmd[ /cmd_vel&lt;br/&gt;geometry_msgs/Twist]:::light\n    cmd --&gt; control([ /robot_control]):::red\n    n1([ /node]):::white -- publishes --&gt; t[ /topic&lt;br/&gt;msg_type]:::white\n    t -- subscribes --&gt; n2([ /node]):::white\n    classDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \n    classDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\n    classDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\n    classDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre> Source: Bestmann, Marc &amp; Fakult\u00e4t, Min &amp; Zhang, Jianwei &amp; Hendrich, N.. (2017). Towards Using ROS in the RoboCup Humanoid Soccer League. Masterthesis</p> <p>Let's look at another example that creates maps from speed data, IMU, and distance data.</p> <pre><code>graph LR;\n\n    odom[ /odom&lt;br/&gt;nav_msgs/Odometry]:::light --&gt; slam([ /slam_node]):::red\n    speed[ /speed&lt;br/&gt;geometry_msgs/Twist]:::light --&gt; slam\n    imu[ /imu&lt;br/&gt;sensor_msgs/Imu]:::light --&gt; slam\n    scan[ /scan&lt;br/&gt;sensor_msgs/PointCloud2]:::light --&gt; slam\n    n1([ /node]):::white -- publishes --&gt; t[ /topic&lt;br/&gt;msg_type]:::white\n    slam --&gt; pose[ /global_pose&lt;br/&gt;geometry_msgs/Pose]:::light\n    slam --&gt; map_g[ /map_grid&lt;br/&gt;nav_msgs/OccupancyGrid]:::light\n    slam --&gt; map_p[ /map_points&lt;br/&gt;sensor_msgs/PointCloud2]:::light\n    t -- subscribes --&gt; n2([ /node]):::white\n    classDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \n    classDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\n    classDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\n    classDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre>"},{"location":"ros2/#ros-2-directory-structure","title":"<code>ROS 2</code> Directory Structure","text":"<pre><code>~/ros2_ws$ ls\n\nbuild  install  log  src\n</code></pre> <pre><code>graph TD;\n\n    W1{{ Workspace&lt;/br&gt;pl. ros2_ws }}:::light --&gt; S1{{ Source space&lt;/br&gt;src }}:::white\n    W1 --&gt; B1{{ Build space&lt;/br&gt;build }}:::white\n    W1 --&gt; I1{{ Install space&lt;/br&gt;install }}:::white\n    W1 --&gt; L1{{ Log space&lt;/br&gt;log }}:::white\n    S1 --&gt; P1{{ package1 }}:::white\n    S1 --&gt; P2{{ package2 }}:::white\n    S1 --&gt; P3{{ bundle_packages }}:::white\n    P1 --&gt; LA1{{ launch }}:::white\n    P1 --&gt; SR1{{ src }}:::white\n    P2 --&gt; LA2{{ launch }}:::white\n    P2 --&gt; SR2{{ src }}:::white\n\n    classDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \n    classDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\n    classDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\n    classDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre> <pre><code>graph TD;\n\n    W2{{ other_ws }}:::light --&gt; S2{{ src }}:::white\n    W2 --&gt; B2{{ build }}:::white\n    W2 --&gt; I2{{ install }}:::white\n    W2 --&gt; L2{{ log }}:::white\n\n    classDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \n    classDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\n    classDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\n    classDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre> <pre><code>~/ros2_ws/\n\u251c\u2500\u2500build  \n\u251c\u2500\u2500install  \n\u251c\u2500\u2500log\n\u2514\u2500\u2500src/\n    \u251c\u2500\u2500 bundle_packages \n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 cone_detection_lidar\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 launch\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 src\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 my_vehicle_bringup\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 launch\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 other bundle package1\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 other bundle package2\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 img\n    \u2514\u2500\u2500 wayp_plan_tools\n        \u251c\u2500\u2500 csv\n        \u251c\u2500\u2500 launch\n        \u2514\u2500\u2500 src\n</code></pre>"},{"location":"ros2/#differences-between-ros-1-and-ros-2","title":"Differences between <code>ROS 1</code> and <code>ROS 2</code>","text":"<ul> <li>Changes in Middleware <code>ROS 1</code> uses a Master-Slave architecture and XML-RPC middleware. In contrast, <code>ROS 2</code> uses the Data Distribution Service (DDS), which provides greater efficiency and reliability, low latency, scalability, and configurable Quality of Service (QoS) parameters. Among other things, this means there is no need to start <code>roscore</code>. XML-RPC is better for simple remote procedure calls, while the added complexity of DDS allows it to better support real-time systems.</li> <li> <p>Changes in the ROS API <code>ROS 1</code> has two separate libraries: <code>roscpp</code> for C++ and <code>rospy</code> for Python. These are not entirely identical in terms of functionality. In contrast, <code>ROS 2</code> has a core library written in C - <code>rcl</code> (ROS client library) - on which other libraries are built. This ensures that core functionalities are available sooner across different APIs. This is one of the main reasons why <code>ROS 2</code> can provide support for more languages beyond the previous Python and C++: for example, rclada Ada, rclcpp C++, rclgo Go, rclpy Python, rcljava Java, rclnodejs Node.js, rclobjc Objective C (iOS), rclc C, ros2_rust Rust, ros2_dotnet .NET, ros2cs ros2_dotnet alternative in C#.</p> </li> <li> <p>Changes in Data Format <code>ROS 2</code> uses the <code>MCAP</code> format, which is not specifically ROS's own format but an open-source container file format for multimodal log data. It supports timestamped, pre-ordered data and is ideal for use in pub/sub or robotics applications. More information: mcap.dev</p> </li> </ul>"},{"location":"ros2/#some-useful-innovations","title":"Some Useful Innovations","text":"<ul> <li>Real-Time Processing   The summary of the above features, along with the use of DDS, makes <code>ROS 2</code> highly suitable for real-time processing, especially when deterministic, low-latency communication is required.</li> <li>QoS: Quality of Service <code>ROS 2</code> allows the configuration of data flow, which affects how data is sent and received. This includes settings for message reliability, deadlines, and priorities, ensuring that critical messages are delivered on time.</li> <li>Multithreaded Execution <code>ROS 2</code> supports truly parallel execution of multiple nodes, making much better use of modern multi-core processors compared to <code>ROS 1</code>.</li> </ul> <p> Source: husarnet.com/blog/ros2-docker</p>"},{"location":"ros2/#other-changes","title":"Other Changes","text":"<ul> <li>Catkin has been replaced by Ament (Colcon) as the build system. Overlays allow the creation of a secondary workspace that does not affect the primary workspace - this is useful when experimenting with new packages without affecting the base configuration (called \"underlay\").</li> <li><code>ROS 2</code> is not backward compatible with <code>ROS 1</code>. Consequently, <code>ROS 1</code> packages are unlikely to work with <code>ROS 2</code> and would require reworking, and other software you used with <code>ROS 1</code> will no longer work.</li> <li><code>ROS 1</code> was primarily designed for Ubuntu. <code>ROS 2</code> runs on MacOS, Windows, Ubuntu, and other (even Real-Time) operating systems.</li> </ul>"},{"location":"ros2/#versions","title":"Versions","text":"<p>ROS versions and installation</p> <pre><code>gantt\n    dateFormat  YY-MM\n    title       ROS 2 Distros\n    excludes    weekends\n    tickInterval 365days\n    %% (`excludes` accepts specific dates in YYYY-MM-DD format, days of the week (\"sunday\") or \"weekends\", but not the word \"weekdays\".)\n    axisFormat %y\n\n    section ROS 2\n    Jazzy   :active, r012, 2024-05-23, 5y\n    .       :active, r011, 2021-01-01, 0d %% placeholder\n    Iron    :active, r010, 2023-11-01, 188d\n    .       :active, r011, 2021-01-01, 0d %% placeholder\n    Humble  :active, r009, 2022-05-23, 5y\n    .       :active, r011, 2021-01-01, 0d %% placeholder\n    Galactic:active, r008, 2021-05-23, 1y</code></pre> <p></p> <p>Percentage distribution of distros over time: metrics.ros.org/rosdistro_rosdistro.html</p> <p></p> <p>The <code>Humble Hawksbill</code> or simply <code>Humble</code> is a long term support (LTS) release, supported for 5 years (from May 2022 to May 2027).</p> <p>Additional releases: docs.ros.org/en/humble/Releases.html</p> <p>Concepts\u00b6"},{"location":"ros2/#nodes","title":"Nodes","text":"<p>A node, simply put, is a ROS program (referred to as a node in English). Represented by a round \ud83d\udd34 symbol in diagrams. Characteristics:</p> <ul> <li>\"Executable\" (c++ / py).</li> <li>Each node is a process.</li> <li>ROS handles threading.</li> <li>A node can have multiple threads internally.</li> <li>publish/subscribe to topics.</li> <li>Multiple nodes can \"publish\" to a topic, and a node can \"subscribe\" to multiple topics.</li> </ul>"},{"location":"ros2/#topics","title":"Topics","text":"<p>Topics can be thought of as named \"ports\" where nodes can communicate. Represented by a square \ud83d\udfe6 symbol in diagrams. Characteristics:</p> <ul> <li>Responsible for the flow of information between nodes.</li> <li>Each topic's type is determined by the \"message\".</li> <li>\"Many-to-many\" communication is allowed between nodes.</li> </ul>"},{"location":"ros2/#message-types","title":"Message Types","text":"<ul> <li>Primitive built-in types (std_msgs)</li> <li><code>bool</code>, <code>string</code>, <code>float32</code>, <code>int32</code>, <code>\u2026</code></li> <li>Higher-level built-in types:</li> <li><code>geometry_msgs</code>: <code>Point</code>, <code>Polygon</code>, <code>Vector</code>, <code>Pose</code>, <code>PoseWithCovariance</code>, <code>\u2026</code></li> <li><code>nav_msgs</code>: <code>OccupancyGrid</code>, <code>Odometry</code>, <code>Path</code>, <code>\u2026</code></li> <li><code>sensors_msgs</code>: <code>Joy</code>, <code>Imu</code>, <code>NavSatFix</code>, <code>PointCloud</code>, <code>LaserScan</code>, \u2026</li> <li>Also supported:</li> <li>Constants</li> <li>Enumerations</li> <li>Embedded definitions</li> </ul> <p>Example:</p> <pre><code>$ ros2 interface show geometry_msgs/msg/Point\nfloat64 x\nfloat64 y\nfloat64 z\n</code></pre> <pre><code>$ ros2 interface show std_msgs/msg/Header\nuint32 seq\ntime stamp\nstring frame_id\n</code></pre> <p>The structure of the <code>PoseStamped</code> type is built from the <code>Header</code> and <code>Point</code> types</p> <p><pre><code>$ ros2 interface show geometry_msgs/msg/PoseStamped\nstd_msgs/Header header\n  uint32 seq\n  time stamp\n  string frame_id\ngeometry_msgs/Pose pose\n  geometry_msgs/Point position # (1) \n    float64 x\n    float64 y\n    float64 z\n  geometry_msgs/Quaternion orientation # (2)\n    float64 x\n    float64 y\n    float64 z\n    float64 w\n</code></pre></p> <p> This might look familiar: we have already discussed <code>geometry_msgs/msg/Point.</code> <code>geometry_msgs/Quaternion</code> is a type of 3D orientation representation, which we will discuss in detail later.</p>"},{"location":"ros2/#publishing-subscribing","title":"Publishing / Subscribing","text":"<p>n the following example, the node named <code>urban_road_filt</code> subscribes to <code>points</code> data, which is of type <code>PointCloud2</code>, and publishes messages of types <code>PointCloud2</code> and <code>MarkerArray</code>:</p> <pre><code>flowchart LR\n\nP[points]:::light --&gt;|sensor_msgs/PointCloud2| U([urban_road_filt]):::red\nU --&gt; |sensor_msgs/PointCloud2| A[curb]:::light\nU --&gt; |sensor_msgs/PointCloud2| B[road]:::light \nU --&gt; |sensor_msgs/PointCloud2| C[road_probably]:::light\nU --&gt; |sensor_msgs/PointCloud2| D[roi]:::light\nU --&gt; |visualization_msgs/MarkerArray| E[road_marker]:::light\n\nn1([ /node]):::white -- publishes&lt;/br&gt;topic_type --&gt; t[ /topic]:::white\nt -- subscribes&lt;/br&gt;topic_type --&gt; n2([ /node]):::white\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n</code></pre>"},{"location":"ros2/#parameters","title":"Parameters","text":"<p>-Not everything can be described with Publish/Subscribe -Nodes may sometimes need parameterization -Parameters can include:     -Controller type     -Color thresholds     -Camera resolution, etc.</p>"},{"location":"ros2/#launch-files","title":"Launch Files","text":"<p>Batch execution of multiple nodes (ROS programs). Keeping the <code>ROS 1</code> conventions, it can be an XML format file that defines almost every aspect/operation of ROS. Recently, however, these can also be <code>python</code> files, giving us much more freedom. Starting nodes, setting/loading parameters, topic remapping, passing command-line arguments.</p> <p>Here is a short video about it:</p>"},{"location":"ros2/#sources","title":"Sources","text":"<ul> <li>docs.ros.org/en/humble</li> <li>ros.org/blog/ecosystem</li> <li>husarnet.com/blog/ros2-docker</li> <li>design.ros2.org/articles/intraprocess_communications.html</li> <li>Towards Using ROS in the RoboCup Humanoid Soccer League - Masterthesis</li> </ul>"},{"location":"ros2/practice/","title":"<code>ROS 2</code> Introduction and Practice","text":""},{"location":"ros2/practice/#reminder","title":"Reminder","text":"<p>A few basic concepts from the previous session:</p> <ul> <li>Node: Essentially means a ROS program. (e.g., <code>turtlesim_node</code>, <code>cmd_gen_node</code>, <code>foxglove_bridge</code>)</li> <li>Topic: Named communication channel. (e.g., <code>/turtle1/cmd_vel</code>, <code>/turtle1/pose</code>, <code>/raw_cmd</code>)</li> <li>Message: (e.g., <code>std_msgs/msg/Bool</code>, <code>geometry_msgs/msg/Twist</code>, <code>turtlesim/msg/Pose</code>)</li> <li>Package: Collection of ROS programs (nodes) (e.g., <code>turtlesim</code>, <code>arj_intro_cpp</code>, <code>arj_transforms_cpp</code>)</li> <li>Launch files: Used to start multiple nodes with parameters (e.g., <code>multisim.launch.py</code>, <code>foxglove_bridge.launch.xml</code>, <code>foxglove_bridge.launch.py</code>)</li> <li>Publish / subscribe: Publishing and subscribing to messages.</li> <li>Build: The process of creating executable files from the package source code. In ROS2, <code>colcon</code> is the default build tool.</li> </ul>"},{"location":"ros2/practice/#task-1-node-and-publish","title":"Task <code>1.</code> - Node and publish","text":"<p>Open two terminals. From the first terminal, start the built-in <code>turtlesim_node</code> simulator, which is found in the <code>turtlesim</code> package.</p> <pre><code>ros2 run turtlesim turtlesim_node\n</code></pre> <p>Note: If it is missing for some reason, it can be installed with the command <code>sudo apt install ros-humble-turtlesim</code>.</p> <p>From the second terminal, publish a command that makes the turtle turn around:</p> <pre><code>ros2 topic pub /turtle1/cmd_vel geometry_msgs/msg/Twist '{linear: {x: 0.5, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: 1.2}}'\n</code></pre> Turtlesim animation <p>In the background, the <code>turtlesim_node</code> node (round symbol) subscribes to the <code>/turtle1/cmd_vel</code> topic (square symbol), causing the movement.</p> <pre><code>flowchart LR\n\nC[ /turtle1/cmd_vel]:::light --&gt;|geometry_msgs/msg/Twist| S([turtlesim_node]):::red\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n</code></pre> <p>As shown in the flowchart, the type of <code>/turtle1/cmd_vel</code> is <code>geometry_msgs/msg/Twist</code>. This can be found out with the following command:</p> <pre><code>ros2 interface show geometry_msgs/msg/Twist\n</code></pre> <pre><code>Vector3  linear\n        float64 x\n        float64 y\n        float64 z\nVector3  angular\n        float64 x\n        float64 y\n        float64 z\n</code></pre> <p>All topics can be listed with:</p> <pre><code>ros2 topic list\n</code></pre> <p>The content of a specific topic can be printed or written to a file in various formats and with filters:</p> <pre><code>ros2 topic echo /turtle1/pose\nros2 topic echo /turtle1/pose --csv\nros2 topic echo /turtle1/pose --csv &gt; turtle_data_01.csv\nros2 topic echo /turtle1/pose --once\nros2 topic echo /turtle1/pose --once | grep velocity\nros2 topic echo /turtle1/pose --field x\nros2 topic echo /turtle1/pose --field linear_velocity\nros2 topic echo /turtle1/cmd_vel --field linear.x\n</code></pre> <p>Example output:</p> <pre><code>x: 6.2\ny: 4.0\ntheta: 0.0\nlinear_velocity: 0.0\nangular_velocity: 0.0\n</code></pre> <p>!!! tip By issuing the <code>ros2 topic echo --help</code> command, you get further usage instructions. The <code>--help</code> switch can of course be used with other <code>ros2</code> commands as well.</p>"},{"location":"ros2/practice/#workspace-and-build-information","title":"Workspace and build information","text":"<p>First, check if the workspace exists in the home directory (<code>~</code>) using the <code>ls ~ | grep ros2</code> command. In this course, the workspace is named <code>ros2_ws</code>. The name doesn't really matter, but most tutorials use this name, so we follow this tradition. Multiple workspaces can be used simultaneously, sourced separately, which can be convenient for larger systems. For now, we stick to a single ros2_ws. If it doesn't exist, create the workspace and source folders with the <code>mkdir -p ros2_ws/src</code> command.</p>"},{"location":"ros2/practice/#colcon","title":"colcon","text":"<p>The most important command is probably <code>colcon build</code>. Also noteworthy are <code>colcon list</code> and <code>colcon graph</code>. The former lists available packages, while the latter provides a quick view of dependencies.</p> <p>The <code>colcon build</code> command comes with several useful switches:</p> <ul> <li><code>--packages-select</code>:erhaps the most frequently used switch, followed by specifying multiple packages to build. If not specified, the default is to build the entire workspace. In practice, there will be a <code>colcon build --packages-select arj_intro_cpp arj_transforms_cpp</code> command, which builds the two arj packages.</li> <li><code>--symlink-install</code>:Use symbolic links instead of copying files from the source. This avoids having to rebuild the package for every launch file modification.</li> <li><code>--parallel-workers 2</code>: The maximum number of tasks that can be processed in parallel, in this case <code>2</code>. If not specified, the default value is the number of logical CPU cores. It is worth limiting if the build does not complete due to lack of resources.</li> <li><code>--continue-on-error</code>: For larger builds, do not stop after the first faulty package. So if 1 out of 100 packages doesn't work, 99 will still build. If not specified, between 0 and 99 packages will build, depending on dependencies and other orderings.</li> </ul>"},{"location":"ros2/practice/#source","title":"Source","text":"<p>To actually run our ROS2 executable files, we need to set up the environment (so-called sourcing), i.e., tell the bash where to look for the executable files, what their dependencies are, etc. This is simpler than it sounds, just issue a <code>source &lt;path&gt;/&lt;name&gt;.bash</code> command. As mentioned earlier, the workspace name doesn't matter, and indeed, after sourcing, it doesn't matter where the executable is physically located; it can be conveniently run from any folder with a command. Since packages within different workspaces can build on each other, ROS2 introduced the overlay/underlay concept. This means that when building one workspace, another workspace was already sourced, and some package depends on the previously built package. Thus, its functionality, code is needed for the dependent package. Accordingly, sourcing can also be of two types:</p> <ul> <li> <p>The <code>local_setup.bash</code> script sets up the environment (sources) only in the current workspace. So it does not source the parent (dependent) workspace.</p> </li> <li> <p>The <code>local_setup.bash</code>script sets up the environment (sources) only in the current workspace. So it does not source the parent (dependent) workspace.</p> </li> <li> <p>The <code>setup.bash</code> script, however, adds the <code>local_setup.bash</code> script to all workspaces that were dependencies when the workspace was created.</p> </li> </ul> <p>!!! note In this course, such complex systems are not needed; most of the time, a single <code>ros2_ws</code> is sufficient.</p>"},{"location":"ros2/practice/#2-task-package-build-and-usage","title":"<code>2.</code> task - Package build and usage","text":"Reminder of the directory structure. <pre><code>~/ros2_ws/\n\u251c\u2500\u2500build  \n\u251c\u2500\u2500install  \n\u251c\u2500\u2500log\n\u2514\u2500\u2500src/\n    \u251c\u2500\u2500 bundle_packages \n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 cone_detection_lidar\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u251c\u2500\u2500 launch\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 src\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 my_vehicle_bringup\n    \u2502\u00a0\u00a0 \u2502\u00a0\u00a0 \u2514\u2500\u2500 launch\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 other bundle package1\n    \u2502\u00a0\u00a0 \u251c\u2500\u2500 other bundle package2\n    \u2502\u00a0\u00a0 \u2514\u2500\u2500 img\n    \u2514\u2500\u2500 wayp_plan_tools\n        \u251c\u2500\u2500 csv\n        \u251c\u2500\u2500 launch\n        \u2514\u2500\u2500 src\n</code></pre> <p>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-A-Workspace/Creating-A-Workspace.html</p> <p>Let's open four terminals. In the first terminal, let's start the built-in <code>turtlesim_node</code> simulator, which is found in the <code>turtlesim</code> package.</p> <pre><code>ros2 run turtlesim turtlesim_node\n</code></pre> <p>!!! success In the second terminal, check the contents of <code>ros2_ws/src</code>, and if necessary clone and buildthe example package.</p> <p><pre><code>ls ~/ros2_ws/src | grep arj_\n</code></pre> or</p> <p><pre><code>cd ~ &amp;&amp; test -d \"ros2_ws/src/arj_packages\" &amp;&amp; echo Letezik || echo Nem letezik\n</code></pre> - <code>Option A:</code>If there is no package (the previous <code>ls</code> returns no result), then <code>git clone</code> and <code>colcon build</code>. - <code>Option B:</code> If there is a package but it is not the latest, then <code>git pull</code> and <code>colcon build</code>. - <code>Option C:</code> If there is a package and it is up-to-date, then no further action is needed.</p> <p><code>Option A:</code> <pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/sze-info/arj_packages\n</code></pre> <pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select arj_intro_cpp\n</code></pre></p> <p><code>Option B:</code> <pre><code>cd ~/ros2_ws/src/arj_packages\n</code></pre> <pre><code>git checkout -- .\n</code></pre> <pre><code>git pull\n</code></pre> <pre><code>cd ~/ros2_ws\n</code></pre></p> <pre><code>colcon build --packages-select arj_intro_cpp\n</code></pre> <p>The <code>git checkout --</code> . command is useful for discarding any local changes.</p> <p>In the third terminal, run the <code>cmd_gen_node</code> ROS node.</p> <p>First, we need to <code>source</code> if we are using our own packages:</p> <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <p>Then the node can be run:</p> <pre><code>ros2 run arj_intro_cpp cmd_gen_node\n</code></pre> <p>The turtle now moves as follows:</p> Turtle <p>The source code is available in thegithub.com/sze-info/arj_packagesrepository. The key point is that the <code>loop</code> function runs at a frequency of 5 Hz (200 ms):</p> <pre><code>void loop()\n{\n  // Publish transforms\n  auto cmd_msg = geometry_msgs::msg::Twist();\n  if (loop_count_ &lt; 20)\n  {\n    cmd_msg.linear.x = 1.0;\n    cmd_msg.angular.z = 0.0;\n  }\n  else\n  {\n    cmd_msg.linear.x = -1.0;\n    cmd_msg.angular.z = 1.0;\n  }\n  cmd_pub_-&gt;publish(cmd_msg);\n  loop_count_++;\n  if (loop_count_ &gt; 40)\n  {\n    loop_count_ = 0;\n  }\n}\n</code></pre> <p>!!! important \"Python equivalent\" The Python version of the C++ code is also available at github.com/sze-info/arj_packages. It is worth comparing the C++ and Python codes.</p> <p>In the last terminal, let's use Foxglove to view live data (don't forget to <code>source</code> here as well):</p> <pre><code>ros2 launch arj_intro_cpp foxglove_bridge.launch.py\n</code></pre> <p>Let's examine the data with Foxglove Studio via WebSocket (Open connection <code>ws://localhost:8765</code>):</p> <p></p> <p>Note: In the lab, <code>foxglove_bridge</code> is installed. At home, it can be installed with <code>sudo apt install ros-humble-foxglove-bridge</code> (after updating).</p> <p><pre><code>flowchart LR\n\nC[ /turtle1/cmd_vel]:::light --&gt; S([turtlesim_node]):::red\nC[ /turtle1/cmd_vel] --&gt; F([foxglove_bridge]):::red\nG([cmd_gen_node]):::red--&gt; C\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n</code></pre> We can start all three nodes together as follows:</p> <p><pre><code>ros2 launch arj_intro_cpp turtle.launch.py\n</code></pre> Let's briefly examine the contents of the package after running the <code>code ~/ros2_ws/src/arj_packages/arj_intro_cpp</code> command.</p>"},{"location":"ros2/practice/#3-task-creating-your-own-package","title":"<code>3.</code> Task - Creating your own package","text":"<p>The task is based on the official ROS2 documentation: docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html.Let's create a ROS 2 package named my_package.</p> <p>!!! important \"Python Equivalent\" We are currently creating a C++ package, but the [original]tutorial(https://docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html) also includes Python equivalents for the CMake (C++) package.</p> <p>First step is to navigate to the <code>src</code> directory of your workspace:</p> <p><pre><code>cd ~/ros2_ws/src\n</code></pre> Let's create a package named <code>my_package</code> and a node named <code>my_node</code>.</p> <p><pre><code>ros2 pkg create --build-type ament_cmake --node-name my_node my_package\n</code></pre> Build it as usual:</p> <p><pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select my_package\n</code></pre></p> <p>Then source:</p> <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <p>And it can be run:</p> <p><pre><code>ros2 run my_package my_node\n</code></pre> <pre><code># output:\n\nhello world my_package package\n</code></pre></p> <p>Let's examine the contents of <code>my_package</code>!</p> <p><pre><code>ls -R ~/ros2_ws/src/my_package\n</code></pre> <pre><code># output:\n/home/he/ros2_ws/src/my_package:\n  CMakeLists.txt  include  package.xml  src\n/home/he/ros2_ws/src/my_package/include:\n  my_package\n/home/he/ros2_ws/src/my_package/include/my_package:\n  [empty]\n/home/he/ros2_ws/src/my_package/src:\n  my_node.cpp\n</code></pre></p> <p><pre><code>tree ~/ros2_ws/src/my_package\n</code></pre> <pre><code># output:\nmy_package\n\u251c\u2500\u2500 CMakeLists.txt\n\u251c\u2500\u2500 include\n\u2502\u00a0\u00a0 \u2514\u2500\u2500 my_package\n\u251c\u2500\u2500 package.xml\n\u2514\u2500\u2500 src\n    \u2514\u2500\u2500 my_node.cpp\n</code></pre></p> <p><pre><code>cat ~/ros2_ws/src/my_package/src/my_node.cpp\n</code></pre> <pre><code>#include &lt;cstdio&gt;\n\nint main(int argc, char ** argv)\n{\n  (void) argc;\n  (void) argv;\n\n  printf(\"hello world my_package package\\n\");\n  return 0;\n}\n</code></pre> It is worth noting that the cpp file does not yet use any <code>ros2</code> headers.</p> <p>To run it: </p> <p><pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 run my_package my_node\n</code></pre></p> <p>Alternatively, you can open the entire folder from VS Code. <pre><code>code ~/ros2_ws/src/my_package\n</code></pre></p> <p>!!! tip If you provide a file after the <code>code</code> command, the file will open. If you provide a directory, the contents of that directory will open. It is often the case that you are in a specific package and want to open the current directory. You can do this with the <code>code .</code> command, where the <code>.</code> character represents the current directory in Linux.</p>"},{"location":"ros2/practice/#4-task-c-publishersubscriber","title":"<code>4.</code> Task C++ Publisher/Subscriber","text":"<p>The exercise is based on the official ROS 2 tutorials: docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html</p> <ul> <li>C++ publisher</li> <li>C++ subscriber</li> </ul>"},{"location":"ros2/practice/#create-the-cpp_pubsub-package","title":"Create the <code>cpp_pubsub</code> package","text":"<p>Open a new terminal and source the installation so that the <code>ros2</code> commands work.</p> <p>Navigate to the already created <code>ros2_ws</code> directory.</p> <p>It is important to create packages in the <code>src</code> directory, not in the root of the workspace. So navigate to the <code>ros2_ws/src</code> directory and run the package creation command: <pre><code>ros2 pkg create --build-type ament_cmake cpp_pubsub\n</code></pre></p> <p>The terminal will return a message confirming the creation of the <code>cpp_pubsub</code> package and all necessary files and folders.</p>"},{"location":"ros2/practice/#write-the-publisher-node","title":"Write the publisher node","text":"<p>Navigate to the <code>ros2_ws/src/cpp_pubsub/src</code> directory. This is the directory in every CMake package where the source files belong (e.g., with the <code>.cpp</code> extension).</p> <p>Download the example talker code: <pre><code>wget -O publisher_member_function.cpp https://raw.githubusercontent.com/ros2/examples/humble/rclcpp/topics/minimal_publisher/member_function.cpp\n</code></pre></p> <p>This command will create the <code>publisher_member_function.cpp</code> file. Open the folder with VS Code (<code>code .</code>) to edit the file.</p> <pre><code>#include &lt;chrono&gt;\n#include &lt;functional&gt;\n#include &lt;memory&gt;\n#include &lt;string&gt;\n\n#include \"rclcpp/rclcpp.hpp\"\n#include \"std_msgs/msg/string.hpp\"\n\nusing namespace std::chrono_literals;\n\n/* This example creates a subclass of Node and uses std::bind() to register a\n* member function as a callback from the timer. */\n\nclass MinimalPublisher : public rclcpp::Node\n{\n    public:\n    MinimalPublisher()\n    : Node(\"minimal_publisher\"), count_(0)\n    {\n        publisher_ = this-&gt;create_publisher&lt;std_msgs::msg::String&gt;(\"topic\", 10);\n        timer_ = this-&gt;create_wall_timer(\n        500ms, std::bind(&amp;MinimalPublisher::timer_callback, this));\n    }\n\n    private:\n    void timer_callback()\n    {\n        auto message = std_msgs::msg::String();\n        message.data = \"Hello, world! \" + std::to_string(count_++);\n        RCLCPP_INFO(this-&gt;get_logger(), \"Publishing: '%s'\", message.data.c_str());\n        publisher_-&gt;publish(message);\n    }\n    rclcpp::TimerBase::SharedPtr timer_;\n    rclcpp::Publisher&lt;std_msgs::msg::String&gt;::SharedPtr publisher_;\n    size_t count_;\n};\n\nint main(int argc, char * argv[])\n{\n    rclcpp::init(argc, argv);\n    rclcpp::spin(std::make_shared&lt;MinimalPublisher&gt;());\n    rclcpp::shutdown();\n    return 0;\n}\n</code></pre>"},{"location":"ros2/practice/#adding-dependencies","title":"Adding Dependencies","text":"<p>Navigate back one level to the <code>ros2_ws/src/cpp_pubsub</code> directory, where the <code>CMakeLists.txt</code> and <code>package.xml</code> files have already been created.</p> <p>Open the <code>package.xml</code> file with a text editor (e.g., <code>VS Code</code>). Tip: You can also open the entire directory, which simplifies some tasks later: <pre><code>code ~/ros2_ws/src/cpp_pubsub/\n</code></pre></p> <p>It is always a good idea to fill in the <code>&lt;description&gt;</code>, <code>&lt;maintainer&gt;</code>, and <code>&lt;license&gt;</code> tags:</p> <p><pre><code>&lt;description&gt;Examples of minimal publisher/subscriber using rclcpp&lt;/description&gt;\n&lt;maintainer email=\"you@email.com\"&gt;Your Name&lt;/maintainer&gt;\n&lt;license&gt;Apache License 2.0&lt;/license&gt;\n</code></pre> Add a new line after the <code>ament_cmake</code> buildtool dependency and insert the following dependencies according to the node's include directives:</p> <pre><code>&lt;depend&gt;rclcpp&lt;/depend&gt;\n&lt;depend&gt;std_msgs&lt;/depend&gt;\n</code></pre> <p>This declares that the package requires <code>rclcpp</code> and <code>std_msgs</code> at build and runtime.</p>"},{"location":"ros2/practice/#cmakeliststxt","title":"CMakeLists.txt","text":"<p>Let's open the <code>CMakeLists.txt</code> file. Add the following lines under the existing <code>find_package(ament_cmake REQUIRED)</code> dependency:</p> <pre><code>find_package(rclcpp REQUIRED)\nfind_package(std_msgs REQUIRED)\n</code></pre> <p>Next, add the executable file and name it <code>talker</code> so that it can be run using <code>ros2 run</code>:</p> <pre><code>add_executable(talker src/publisher_member_function.cpp)\nament_target_dependencies(talker rclcpp std_msgs)\n</code></pre> <p>Finally, add the <code>install(TARGETS...)</code> section so that <code>ros2</code> can find the executable we compiled:</p> <p><pre><code>install(TARGETS\ntalker\nDESTINATION lib/${PROJECT_NAME})\n</code></pre> The <code>CMakeLists.txt</code> file can be cleaned up by removing some unnecessary sections and comments, resulting in the following:</p> <pre><code>cmake_minimum_required(VERSION 3.5)\nproject(cpp_pubsub)\n\n# Default to C++14\nif(NOT CMAKE_CXX_STANDARD)\nset(CMAKE_CXX_STANDARD 14)\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\nadd_compile_options(-Wall -Wextra -Wpedantic)\nendif()\n\nfind_package(ament_cmake REQUIRED)\nfind_package(rclcpp REQUIRED)\nfind_package(std_msgs REQUIRED)\n\nadd_executable(talker src/publisher_member_function.cpp)\nament_target_dependencies(talker rclcpp std_msgs)\n\ninstall(TARGETS\ntalker\nDESTINATION lib/${PROJECT_NAME})\n\nament_package()\n</code></pre> <p>The package can now be built. Let's also add the subscriber node to see the entire system in action.</p> <p><pre><code>cd ~/ros2_ws/\n</code></pre> <pre><code>colcon build --packages-select cpp_pubsub\n</code></pre></p>"},{"location":"ros2/practice/#write-the-subscriber-node","title":"Write the subscriber node","text":"<p>The creation of the subscriber node is also described in section 3 of the following tutorial:docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html</p> <p>Navigate back to the <code>ros2_ws/src/cpp_pubsub/src</code> directory and download the subscriber node: <pre><code>wget -O subscriber_member_function.cpp https://raw.githubusercontent.com/ros2/examples/humble/rclcpp/topics/minimal_subscriber/member_function.cpp\n</code></pre></p> <p>If we list the files with <code>ls</code>, we should see the following:</p> <p><pre><code>publisher_member_function.cpp  subscriber_member_function.cpp\n</code></pre> Add the subscriber node to the <code>CMakeLists.txt</code> file:</p> <pre><code>add_executable(listener src/subscriber_member_function.cpp)\nament_target_dependencies(listener rclcpp std_msgs)\n\ninstall(TARGETS\n  talker\n  listener\n  DESTINATION lib/${PROJECT_NAME})\n</code></pre>"},{"location":"ros2/practice/#build-the-package","title":"Build The Package","text":"<p><pre><code>cd ~/ros2_ws/\n</code></pre> <pre><code>colcon build --packages-select cpp_pubsub\n</code></pre></p> <p>Source The code:</p> <p><pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> Run the Publisher <pre><code>ros2 run cpp_pubsub talker\n</code></pre></p> <pre><code>[INFO] [minimal_publisher]: Publishing: \"Hello World: 0\"\n[INFO] [minimal_publisher]: Publishing: \"Hello World: 1\"\n[INFO] [minimal_publisher]: Publishing: \"Hello World: 2\"\n[INFO] [minimal_publisher]: Publishing: \"Hello World: 3\"\n[INFO] [minimal_publisher]: Publishing: \"Hello World: 4\"\n</code></pre> <p>In another Terminal ,Source The setup file and run the subscriber <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 run cpp_pubsub listener\n</code></pre></p> <pre><code>[INFO] [minimal_subscriber]: I heard: \"Hello World: 10\"\n[INFO] [minimal_subscriber]: I heard: \"Hello World: 11\"\n[INFO] [minimal_subscriber]: I heard: \"Hello World: 12\"\n[INFO] [minimal_subscriber]: I heard: \"Hello World: 13\"\n[INFO] [minimal_subscriber]: I heard: \"Hello World: 14\"\n</code></pre>"},{"location":"ros2/practice/#5-task-python-publisher-subscriber","title":"<code>5.</code> Task - Python publisher / subscriber","text":"<p>The exercise is based on the official ROS 2 tutorials:docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html</p> PythonC++ <pre><code>import rclpy      ## ROS2 Python API \nfrom std_msgs.msg import String ## ROS2 Standard String\nfrom rclpy.node import Node \n\n\n\n\n## MinimalPublisher oszt\u00e1ly\nclass MinimalPublisher(Node):\n\n    def __init__(self):\n        super().__init__('minimal_publisher')\n        self.publisher_ = self.create_publisher(String, 'topic', 10)\n        timer_period = 0.5  # seconds\n        self.timer = self.create_timer(timer_period, self.timer_callback)\n        self.i = 0\n\n    def timer_callback(self):\n        msg = String()\n        msg.data = 'Hello World: %d' % self.i\n        self.publisher_.publish(msg)\n        self.get_logger().info('Publishing: \"%s\"' % msg.data)\n        self.i += 1\n\n\n\n\n\ndef main(args=None):\n    rclpy.init(args=args)\n    minimal_publisher = MinimalPublisher()\n    rclpy.spin(minimal_publisher)\n    minimal_publisher.destroy_node()\n    rclpy.shutdown()\n\n\nif __name__ == '__main__':\n    main()\n</code></pre> <pre><code>#include \"rclcpp/rclcpp.hpp\" // ROS2 C++ API \n#include \"std_msgs/msg/string.hpp\" // ROS2 standard String\n#include &lt;chrono&gt;\n#include &lt;functional&gt;\n#include &lt;memory&gt;\n#include &lt;string&gt;\nusing namespace std::chrono_literals;\n// MinimalPublisher oszt\u00e1ly\nclass MinimalPublisher : public rclcpp::Node\n{\n    public: MinimalPublisher() : Node(\"minimal_publisher\"), count_(0) {\n        publisher_ = this-&gt;create_publisher&lt;std_msgs::msg::String&gt;(\"topic\", 10);\n        timer_ = this-&gt;create_wall_timer(\n        500ms, std::bind(&amp;MinimalPublisher::timer_callback, this));\n    }\n\n    private:\n    void timer_callback(){\n        auto message = std_msgs::msg::String();\n        message.data = \"Hello, world! \" + std::to_string(count_++);\n        RCLCPP_INFO(this-&gt;get_logger(), \"Publishing: '%s'\", message.data.c_str());\n        publisher_-&gt;publish(message);\n    }\n    rclcpp::TimerBase::SharedPtr timer_;\n    rclcpp::Publisher&lt;std_msgs::msg::String&gt;::SharedPtr publisher_;\n    size_t count_;\n};\n\nint main(int argc, char * argv[]){\n    rclcpp::init(argc, argv);\n    rclcpp::spin(std::make_shared&lt;MinimalPublisher&gt;());\n    rclcpp::shutdown();\n    return 0;\n}\n</code></pre> <ul> <li>Python publisher</li> <li>Python subscriber</li> </ul>"},{"location":"ros2/practice/#sources","title":"Sources","text":"<ul> <li>docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Introducing-Turtlesim/Introducing-Turtlesim.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html</li> </ul>"},{"location":"ros2/ros2_humble/","title":"ROS 2 Humble","text":"<p>Simple Installation</p> <p>The installation can be done step-by-step, but we have also prepared a simple shell script-based installation.</p> <p>As mentioned in the introduction, there are basically four options for installing <code>ROS 2 Humble</code>:</p> <ol> <li>Dual boot, native Linux (mostly Ubuntu) installed alongside Windows \u2705 description</li> <li>Windows WSL2, lightweight Linux virtual machine \u2705 description</li> <li>Virtual machine for Windows \ud83d\udfe0</li> <li>Windows build \ud83d\udfe0</li> </ol> <p>We recommend the first two options out of these four, but the others are not prohibited either. Dual boot provides insight into the world of Linux, which is useful knowledge for an engineer nowadays. Care must be taken during installation, as a wrong setting can cause data loss, so a backup is also recommended. WSL (Windows Subsystem for Linux) is a lightweight compatibility layer for running Linux-based elements on Windows 10 or Windows 11 systems. As shown in the following figure, the Linux kernel can access hardware elements (CPU, memory, GPU, etc.) just as easily as the Windows kernel. In contrast, the virtual machine (option 3) is a much slower solution using more abstraction layers, recommended for those who either have a very modern, fast machine or have already installed such systems. The native Windows build (option 4) is theoretically available, but since most of the documentation is available for Linux, it will require a lot of extra work.</p> <p>Illustration of the first three options:</p> <p></p>"},{"location":"ros2/ros2_humble/#installation","title":"Installation","text":"<p>The following description applies to Ubuntu 22.04 Jammy. Note that other versions are also supported, and installation and descriptions for them are available here: docs.ros.org/en/humble/Installation/Alternatives.html</p> <p>The following description is based on docs.ros.org/en/humble/Installation.html.</p>"},{"location":"ros2/ros2_humble/#setting-the-locale","title":"Setting the Locale","text":"<p>Note</p> <p>This step is usually optional.</p> <p>Ensure that you have a locale that supports UTF-8.</p> <pre><code>locale # Check UTF-8\n\nsudo apt update &amp;&amp; sudo apt install locales\nsudo locale-gen en_US en_US.UTF-8\nsudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8\nexport LANG=en_US.UTF-8\n\nlocale # Check settings\n</code></pre>"},{"location":"ros2/ros2_humble/#setting-up-sources","title":"Setting Up Sources","text":"<p>You need to add the ROS 2 apt repository to your system.</p> <p>First, ensure that the Ubuntu Universe repository is enabled.</p> <p><pre><code>sudo apt install software-properties-common\nsudo add-apt-repository universe\n</code></pre> Add the ROS 2 GPG key with <code>apt</code>. <pre><code>sudo apt update &amp;&amp; sudo apt install curl -y\nsudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg\n</code></pre> Then add the repository to the sources list. <pre><code>echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME) main\" | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null\n</code></pre></p>"},{"location":"ros2/ros2_humble/#installing-ros2-packages","title":"Installing ROS2 Packages","text":"<p>Update:</p> <p><pre><code>sudo apt update\n</code></pre> ROS 2 packages are often built on updated Ubuntu systems. It is always recommended to ensure your system is up-to-date before installing new packages. <pre><code>sudo apt upgrade\n</code></pre> Desktop installation: Install ROS, RViz, demos, tutorials: <pre><code>sudo apt install ros-humble-desktop\n</code></pre> Developer tools, compilers, and other tools for building ROS packages: <pre><code>sudo apt install ros-dev-tools\n</code></pre> Set up your environment by sourcing the following file:</p> <p><pre><code>source /opt/ros/humble/setup.bash\n</code></pre> Tip: This can also be done in the <code>.bashrc</code> file with <code>echo \"source /opt/ros/humble/setup.bash\" &gt;&gt; ~/.bashrc</code>.</p>"},{"location":"ros2/ros2_humble/#verifying-the-installation","title":"Verifying the Installation","text":"<p>Verify the correctness of the installation with the <code>ros2 topic list</code> command.</p> <p><pre><code>$ ros2 topic list\n\n/parameter_events\n/rosout \n</code></pre> If everything is fine, the above two topics should appear. Then you can get to know the use of simple example nodes:docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools.html</p>"},{"location":"ros2/ros2_humble/#recommended-post-installation-settings","title":"Recommended Post-Installation Settings","text":""},{"location":"ros2/ros2_humble/#console-colors","title":"Console Colors","text":"<p>By default, the console output is not colored, but it is advisable to set this with the <code>RCUTILS_COLORIZED_OUTPUT</code> environment variable (even in <code>bashrc</code>). For example</p> <pre><code>export RCUTILS_COLORIZED_OUTPUT=1 \n</code></pre> <p> Details:docs.ros.org/en/humble/Tutorials/Demos/Logging-and-logger-configuration.html#id14</p>"},{"location":"ros2/ros2_humble/#colcon_cd","title":"<code>colcon_cd</code>","text":"<p>It is also advisable to set up the <code>colcon_cd</code> command, so you can quickly switch your working directory to a package directory. For example, the <code>colcon_cd some_ros_package</code> command quickly jumps to the <code>~/ros2_ws/src/some_ros_package</code> directory.</p> <p>Details:docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Colcon-Tutorial.html#setup-colcon-cd</p>"},{"location":"ros2/ros2_humble/#windows-installation","title":"Windows /installation","text":"<p>In the terminal <code>install_humble.sh</code></p> <p><pre><code>wget https://raw.githubusercontent.com/sze-info/arj/main/docs/telepites/install_humble.sh\n</code></pre> <pre><code>sudo chmod +x install_humble.sh\n</code></pre> Home: <pre><code>./install_humble.sh\n</code></pre> In Lab: <pre><code>./install_humble.sh campus\n</code></pre></p>"},{"location":"ros2/ros2_humble/#workspace-reset","title":"Workspace reset","text":"<p>If you want to delete the entire <code>ros2_ws</code>, then re-clone and build it (takes about 5 minutes), you can do it with the following single long command: <pre><code>cd ~ ; rm ws_reset.sh; wget https://raw.githubusercontent.com/sze-info/arj/main/docs/telepites/ws_reset.sh; sudo chmod +x ws_reset.sh; ./ws_reset.sh\n</code></pre></p>"},{"location":"ros2/ubuntu/","title":"Ubuntu dual boot","text":""},{"location":"ros2/vscodegit/","title":"VS Code and Git","text":"<p><code>VS Code</code> is a simple code and text editor for Linux, Windows, and Mac systems, which can become a full-fledged IDE (integrated development environment) with various extensions. Its name is an abbreviation of Visual Studio Code, it is free, open-source, and developed by Microsoft. It is a popular development environment (e.g., in 2021, according to the Stack Overflow Developer Survey, 70% of 82,000 respondents used it, making it one of the most popular IDEs).</p>"},{"location":"ros2/vscodegit/#navigation-in-the-development-environment","title":"Navigation in the Development Environment","text":"<p>The following sections introduce the most important interfaces.</p> <p></p> <p>Perhaps one of the most important keyboard shortcuts is <code>Ctrl-Shift-P</code>, which brings up the Command Palette, where you can browse settings, files, and commands.</p>"},{"location":"ros2/vscodegit/#overview-of-source-control","title":"Overview of Source Control","text":"<p>Source control software, such as Git, is used in modern software development for the following reasons:</p> <ul> <li>Change Tracking: Allows tracking of all modifications to the source code, making it easy to revert to previous versions if a bug is found or a new feature does not work properly.</li> <li>Collaboration: Multiple developers can work on the same project simultaneously. Source control software helps manage different changes and resolve potential conflicts.</li> <li>Backup: Stores every version of the project, so if something goes wrong or is lost, it can be easily restored to a previous state.</li> <li>Experimentation: Allows developers to create different versions or branches and try out new features or fixes without affecting the main project code.</li> <li>Documentation: Source control systems allow recording commit messages related to changes, helping document the reasons and goals of modifications.</li> <li>Integration and Continuous Development: Supports automated testing and continuous integration processes (CI/CD), ensuring that all changes are easily manageable and traceable.</li> </ul> <p></p>"},{"location":"ros2/vscodegit/#using-git-source-control-in-vs-code","title":"Using Git Source Control in VS Code","text":"<p>Visual Studio Code has integrated source control (SCM) and includes support for Git. Many other source control providers are available on the extensions page in the VS Code Marketplace.</p>"},{"location":"ros2/vscodegit/#git-repository","title":"Git Repository","text":"<p>Ensure Git is installed. VS Code will use your computer's Git installation (at least version <code>2.0.0</code> is required), so you need to install Git before using these features.</p> <p>The <code>Source control</code> icon in the left activity bar always provides an overview of how many changes are currently in the repository. Selecting the icon displays the details of the current repository changes: CHANGES, STAGED CHANGES, and MERGE CHANGES.</p> <p>Clicking on individual items allows you to view text changes within each file in detail. Note that for unstaged changes, the right editor still allows editing the file.</p> <p>Indicators related to the repo status can also be found in the bottom left corner of VS Code: the current branch, dirty indicators, and the number of incoming and outgoing commits from the current branch. You can checkout any branch of the repository by clicking on the status indicator and selecting the Git reference from the list.</p> <p>Tip</p> <p>You can open VS Code in a Git repository directory. The command for this in the directory is: <code>code .</code> or, for example: <code>code ~/ros2_ws/src/arj_packages/</code>, if you want to open the <code>arj_packages</code> repo for the subject. VS Code's Git features will continue to work as usual, displaying all changes within the repository, but file modifications outside the scope directory will be shaded with a tooltip indicating they are outside the current workspace.</p>"},{"location":"ros2/vscodegit/#commit","title":"Commit","text":"<p>Staging (git add) and unstaging (git reset) can be performed with context menu actions or by dragging files.</p> <p>Configure your Git username and email address. When committing, ensure that the username and/or email address is set in the Git configuration. Details: Git commit information.</p> <p></p> <p>You can enter a commit message to indicate the changes, then press <code>Ctrl+Enter</code> (macOS: <code>\u2318+Enter</code>) to finalize. If there are staged changes, only those changes will be committed. Otherwise, you will be prompted to select which changes you want to commit.</p> <p>For example, in the previous screenshot, only the staged changes to \"overview.png\" are included in the commit. Subsequent staging and committing operations can include changes to \"versioncontrol.md\" and the other two \".png\" images as separate commits.</p> <p>More precise Commit operations can be found in the Views and More Actions <code>...</code> menu at the top of the source control view.</p> <p></p> <p>Tip: If you commit changes on the wrong branch, undo the commit with the Command Palette Git: Undo Last Commit command (<code>Ctrl+Shift+P</code>).</p>"},{"location":"ros2/vscodegit/#cloning-a-repository","title":"Cloning a Repository","text":"<p>If you don't have a repository cloned yet, you can choose between Open Folder from the local machine or Clone Repository (from a remote machine) in the Source Control view.</p> <p></p> <p>Selecting the Clone Repository option will prompt you for the remote repository URL (e.g., on GitHub) and the directory where the local repository will be placed.</p> <p>For a GitHub repository, you can find the URL in the GitHub Code dialog.</p> <p></p> <p>Then paste this URL into the Git: Clone prompt.</p> <p></p> <p>The Clone from GitHub option will also appear. After authenticating your GitHub account in VS Code, you can search for your own (even private) repositories by name.</p>"},{"location":"ros2/vscodegit/#built-in-terminal","title":"Built-in Terminal","text":"<p>The built-in terminal of the development environment works on both Windows and Linux.</p> <p></p> <p></p>"},{"location":"ros2/vscodegit/#useful-to-know","title":"Useful to Know","text":"<ul> <li>For example, <code>code .</code> opens the contents of the current folder.</li> <li>For example, <code>code ~/.bashrc</code> opens the contents of <code>~/.bashrc</code> for editing.</li> </ul>"},{"location":"ros2/vscodegit/#wsl-vs-code-video","title":"WSL VS Code Video","text":""},{"location":"ros2/vscodegit/#recommended-settings-for-ros-2","title":"Recommended Settings for ROS 2","text":"<p>For ROS 2 C++ development, VS Code does not recognize ROS header files by default, so features like IntelliSense do not work properly:</p> Include path in VS Code <p>A simple solution is to set the <code>/opt/ros/humble/**</code> path in the <code>includePath settings</code>. (Of course, this works for non-humble versions as well, where you need to specify the appropriate path). It looks like this:</p> Include path settings in VS Code <p>Once saved, VS Code will work accordingly with IntelliSense and other features.</p> <p>Sources: code.visualstudio.com/docs/sourcecontrol/overview</p>"},{"location":"ros2/windows_subsystem/","title":"Windows WSL2","text":"<p>The Windows Subsystem for Linux is a compatibility layer for running Linux-based elements natively on Windows 10 or Windows 11 systems. It is worth choosing to use WSL if you do not want to install native Ubuntu (e.g., 18.04 / 22.04) on your computers. The system used in the course can be created in several ways:</p> <ul> <li>Installing WSL and importing a Snapshot link</li> <li>Installing WSL and installing ROS using a Script link </li> </ul>"},{"location":"ros2/windows_subsystem/#installing-wsl-and-importing-a-snapshot","title":"Installing WSL and importing a Snapshot","text":"<p>Video tutorial: </p> <p>Steps in the video:</p> <ol> <li>WSL snapshot (backup file) download:: WSL snapshot let\u00f6lt\u00e9se  ~2.5 GB</li> <li>Extract the snapshot <code>.zip</code> &gt;&gt; <code>.tar</code></li> <li>Powershell (Admin) enable WSL feature, then install WSL: <pre><code>Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux\n</code></pre> <pre><code>wsl --install --no-distribution\n</code></pre></li> <li>Powershell, import WSL Snapshot file (tar): <pre><code>wsl --import ajr1 .\\ajr1\\ .\\ajr24a.tar\n</code></pre></li> <li>Install VS Code and WSL extension:</li> </ol> <p></p> <p>!!! danger The <code>wsl -l -v</code> command lists the installed WSL versions. The <code>VERSION</code> column must be 2, otherwise, an outdated version of WSL has been installed. Example of correct output: <code>bash     NAME            STATE           VERSION     Ubuntu          Stopped         2     Ubuntu-22.04    Stopped         2     Ubuntu-24.04    Running         2     ajr1            Stopped         2</code>      If the VERSION column shows <code>1</code>, you can update the version with the <code>wsl --update</code> command. ```</p>"},{"location":"ros2/windows_subsystem/#additional-recommended-settings","title":"Additional recommended settings","text":"<p>In the Windows Terminal program, it is recommended to set the <code>Default Profile</code> to <code>ajr1</code> so that the program always starts with this profile. Additionally, the <code>Open windows from previous session</code> setting can be useful to start the program in the last state (e.g., with multiple panels).</p> <p></p> <p>You can then create panels with the <code>Alt</code>+<code>Shift</code>+<code>minus</code> or <code>Alt</code>+<code>Shift</code>+<code>plus</code> key combinations. This splits the terminal window (<code>Split pane</code>) into multiple sections vertically or horizontally.</p> <p> </p>"},{"location":"ros2/windows_subsystem/#installing-wsl-and-installing-ros-using-a-script","title":"Installing WSL and installing ROS using a Script","text":"<p>Video tutorial for installing WSL on Windows 11 (Windows 10 version below, but with largely similar content):</p> <p>Steps in the video:</p> <ul> <li>Open a PowerShell window as an administrator.</li> <li>Copy and paste the following command to enable WSL: <pre><code>Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux\n</code></pre></li> <li>Restart the computer by typing <code>Y</code>. (optional)</li> <li>Open the Microsoft Store and search for Windows Subsystem for Linux Preview. Install it.</li> <li>Also, in the Microsoft Store, search for Ubuntu 22.04 and install it, or PowerShell (Admin): <pre><code>wsl --install -d Ubuntu-22.04\n</code></pre></li> <li>For easier management, it is recommended to install the Windows Terminal program. Search for Windows Terminal in the Microsoft Store and install it.</li> <li>Start the Windows Terminal program and open the settings with the Ctrl+, (Control and comma) key combination. From the drop-down list in the Default Profile setting, select Ubuntu 22.04.</li> <li>Restart the Windows Terminal. On the first start, provide a username and password of your choice.</li> <li>We recommend using the VS Code editor for developing the solution. Install it from here: code.visualstudio.com/download</li> <li>Finally, install the VS Code Remote Development extension to make it accessible using WSL: marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack</li> </ul> <p>The video tutorial for installing WSL on Windows 10 is available here:</p> <p>You can find a guide for installing VS Code here:</p>"},{"location":"ros2advanced/","title":"Theory - ROS 2 advanced","text":""},{"location":"ros2advanced/projects/","title":"Small Assignment and Large Semester Project","text":"<p>The purpose of the small assignment is to provide students with practical experience in ROS 2 and GitHub alongside the basic theoretical knowledge acquired in class. The small assignment can be completed in a relatively short time: an instructor can finish it in a few hours, and an average student can complete it in a few afternoons. Its length can be short, typically 30-100 lines of code per node.</p> <p>In contrast, the large semester project takes a bit more time but allows for more interesting tasks and provides ample time to complete them. Moreover, good and excellent grades can only be achieved through this project.</p> <p>Another way to earn grades is through midterm exams, but only modest grades can be obtained this way.</p> <pre><code>flowchart TD\n\nK([Mandatory&lt;/br&gt;small assignment]):::light ------&gt; |unsuccessful| X0\nK --&gt; A([Signature]):::green \nA --&gt;|Midterm direction| ZH1([Midterm 1]):::light\nA --&gt; |Semester project direction| N([Large semester project]):::light\nPZH --&gt; |unsuccessful| X1\nZH2 --&gt; |unsuccessful| PZH([Make-up Midterm]):::light\nZH1 --&gt; ZH2([Midterm 2]):::light\nZH2 --&gt; |successful| OK1\nPZH --&gt; |successful| OK1\nN ----&gt; |successful| OK2\nX0([Signature denied]):::red\nX1([1, fail]):::red\nOK2([4/5 grade]):::green\nOK1([2/3 grade]):::green\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\nclassDef green fill:#138b7b,stroke:#152742,stroke-width:2px,color:#fff\n</code></pre>"},{"location":"ros2advanced/projects/#deadlines-and-semester-schedule","title":"Deadlines and Semester Schedule","text":"<p>It's important to know that the small assignment is a prerequisite for the signature. Failure to register on GitHub or submit the assignment link early in the semester can result in an unsuccessful term. These are small tasks, but their completion is strictly monitored.</p> <pre><code>flowchart LR\n\nH2([2nd occasion]) --- H2A([Github&lt;br&gt;registration])--- H2B([Start Copilot&lt;br&gt;registration])\nH3([3rd occasion]) --- H3A([Submit assignment&lt;br&gt;Github link]) --- H3B([Copilot&lt;br&gt;registration complete])\nH5([5th occasion]) --- H5A([Finalize small&lt;br&gt;assignment])\nH7([7th occasion]) --- H7A([Midterm 1]) --- H7B([Submit large semester&lt;br&gt;Github link])\nH10([10th occasion]) --- H10A([Midterm 2])\nH13([13th occasion]) --- H13A([Make-up Midterm])\nV2([Exam period 2nd week]) --- V2A([Finalize large&lt;br&gt;semester project])\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\nclassDef green fill:#138b7b,stroke:#152742,stroke-width:2px,color:#fff\n\nclass H2,H3,H5,H7,H10,H13,V2 white\nclass H2A,H2B,H3B,H7A,H7B,H10A,V2A light\nclass H3A,H5A,H13A red</code></pre>"},{"location":"ros2advanced/ros2launch/","title":"<code>ROS 2</code> Launch and Other Advanced Concepts","text":""},{"location":"ros2advanced/ros2launch/#introduction","title":"Introduction","text":"<p>The ROS 2 launch system helps users define the configuration of their system and then execute it according to that configuration. The configuration step includes:     - which programs to run,     - what arguments the running programs should receive,     - ROS-specific conventions that allow for easy reuse of components.</p> <p>It is also important to mention that the solution supervises the launched processes and can react to changes in their runtime state.</p> <p>Launch files can be created using Python, XML, or YAML.</p>"},{"location":"ros2advanced/ros2launch/#preparations","title":"Preparations","text":""},{"location":"ros2advanced/ros2launch/#create-the-example_launch-package","title":"Create the <code>example_launch</code> package","text":"<p>If the <code>example_launch</code> package already exists, delete it. (In the lab, it is possible that someone created it in a previous semester.)</p> <pre><code>cd ~ &amp;&amp; test -d \"ros2_ws/src/example_launch\" &amp;&amp; echo Exists || echo Does not exist\n</code></pre> <pre><code>rm -r ~/ros2_ws/src/example_launch\n</code></pre> <p>Open a new terminal and source the installation (if not in <code>bashrc</code>) to make the <code>ros2</code> commands work.</p> <p>Navigate to the already created <code>ros2_ws</code> directory.</p> <p>It is important to create packages in the <code>src</code> directory, not in the root of the workspace. So navigate to the <code>ros2_ws/src</code> folder and run the package creation command:</p> <pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>ros2 pkg create --build-type ament_cmake example_launch\n</code></pre> <p>The terminal will return a message confirming the creation of the <code>example_launch</code> package and all necessary files and folders.</p>"},{"location":"ros2advanced/ros2launch/#launch-folder","title":"Launch Folder","text":"<p>Create a folder for the launch files:</p> <pre><code>cd ~/ros2_ws/src/example_launch\n</code></pre> <pre><code>mkdir launch\n</code></pre>"},{"location":"ros2advanced/ros2launch/#creating-a-launch-file","title":"Creating a Launch File","text":"<pre><code>cd launch\n</code></pre> <pre><code>code turtlesim_mimc_launch.py\n</code></pre> <p>Create a launch file using the elements of the <code>turtlesim</code> package, using Python.</p> <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n        return LaunchDescription([\n                Node(\n                        package='turtlesim',\n                        namespace='turtlesim1',\n                        executable='turtlesim_node',\n                        name='sim'\n                ),\n                Node(\n                        package='turtlesim',\n                        namespace='turtlesim2',\n                        executable='turtlesim_node',\n                        name='sim'\n                ),\n                Node(\n                        package='turtlesim',\n                        executable='mimic',\n                        name='mimic',\n                        remappings=[\n                                ('/input/pose', '/turtlesim1/turtle1/pose'),\n                                ('/output/cmd_vel', '/turtlesim2/turtle1/cmd_vel'),\n                        ]\n                )\n        ])\n</code></pre> <p>The launch file created as described above launches three nodes from the <code>turtlesim</code> package. The goal is to open two turtlesim windows and replicate the movement of one turtle with the other. The only difference in launching the two turtlesim nodes is the namespace. Using unique namespaces allows launching two identical nodes simultaneously without name conflicts. Thus, both turtles will receive instructions on the same topic and report their positions on the same topic. The unique namespaces allow distinguishing the messages of the two turtles.</p> <p>The last node is also from the <code>turtlesim</code> package, but the executable file is different: <code>mimic</code>. This node is supplemented with remappings. For example, the simple <code>/input/pose</code> corresponds to <code>/turtlesim1/turtle1/pose</code> and the previously known <code>/output/cmd_vel</code> is now <code>/turtlesim2/turtle1/cmd_vel</code>. This means that <code>mimic</code> subscribes to the <code>/turtlesim1/sim</code> pose topic and republishes it so that the <code>/turtlesim2/sim</code> velocity command subscribes to it. Thus, <code>turtlesim2</code> will mimic the movement of <code>turtlesim1</code>.</p>"},{"location":"ros2advanced/ros2launch/#reviewing-code-details","title":"Reviewing Code Details","text":"<p>These expressions import Python <code>launch</code> modules.</p> <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n</code></pre> <p>Then the launch description begins:</p> <pre><code>def generate_launch_description():\n    return LaunchDescription([\n\n    ])\n</code></pre> <p>The first two instructions in the launch description start the two turtlesim windows:</p> <pre><code>Node(\n        package='turtlesim',\n        namespace='turtlesim1',\n        executable='turtlesim_node',\n        name='sim'\n),\nNode(\n        package='turtlesim',\n        namespace='turtlesim2',\n        executable='turtlesim_node',\n        name='sim'\n),\n</code></pre> <p>Finally, the node that implements the movement mimicry is also started:</p> <pre><code>Node(\n        package='turtlesim',\n        executable='mimic',\n        name='mimic',\n        remappings=[\n            ('/input/pose', '/turtlesim1/turtle1/pose'),\n            ('/output/cmd_vel', '/turtlesim2/turtle1/cmd_vel'),\n        ]\n)\n</code></pre>"},{"location":"ros2advanced/ros2launch/#using-ros2-launch","title":"Using <code>ROS2</code> Launch","text":"<p>The created launch file can be started as follows:</p> <p><pre><code>cd ~/ros2_ws/src/example_launch/launch # enter the folder containing the launch file\n</code></pre> <pre><code>ros2 launch turtlesim_mimc_launch.py\n</code></pre></p> <p>Two turtlesim windows will open, and the following <code>[INFO]</code> output will be visible, listing the started nodes: <pre><code>[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [turtlesim_node-1]: process started with pid [11714]\n[INFO] [turtlesim_node-2]: process started with pid [11715]\n[INFO] [mimic-3]: process started with pid [11716]\n</code></pre></p> <p>To test the system, publish a message to move <code>turtle1</code> in a new terminal:</p> <pre><code>ros2 topic pub -r 1 /turtlesim1/turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: -1.8}}\"\n</code></pre> <p>Besides the direct method shown above, a launch file can also be run by a package:</p> <pre><code>ros2 launch &lt;package_name&gt; &lt;launch_file_name&gt;\n</code></pre> <p>For packages containing launch files, it is advisable to create an <code>exec_depend</code> dependency on the <code>ros2launch</code> package in the package's <code>package.xml</code> file:</p> <pre><code>&lt;exec_depend&gt;ros2launch&lt;/exec_depend&gt;\n</code></pre> <p>This ensures that the <code>ros2 launch</code> command is available after building the package.</p>"},{"location":"ros2advanced/ros2launch/#study-the-launched-system","title":"Study the Launched System","text":"<p>With all previously launched nodes running, run the <code>rqt_graph</code> tool in a new terminal to graphically visualize the system created by the launch file:</p> <pre><code>rqt_graph\n</code></pre>"},{"location":"ros2advanced/ros2launch/#add-to-the-package-to-launch-from-anywhere","title":"Add to the Package to Launch from Anywhere","text":"<pre><code>cd ~/ros2_ws/src/example_launch\n</code></pre> <pre><code>code .\n</code></pre> Lexus <p>Insert the following line before <code>&lt;test_depend&gt;</code> in <code>package.xml</code>:</p> <pre><code>&lt;exec_depend&gt;ros2launch&lt;/exec_depend&gt;\n</code></pre> <p>Insert the following two lines before <code>ament_package()</code> in <code>CMakeLists.txt</code>:</p> <pre><code>install(DIRECTORY launch\n    DESTINATION share/${PROJECT_NAME})\n</code></pre> <p>Build as usual:</p> <pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select example_launch\n</code></pre> <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <p>This command can now be issued from anywhere:</p> <pre><code>ros2 launch example_launch turtlesim_mimc_launch.py\n</code></pre>"},{"location":"ros2advanced/ros2launch/#sources","title":"Sources","text":"<ul> <li>foxglove.dev/blog/how-to-use-ros2-launch-files</li> <li>youtube.com/watch?v=PqNGvmE2Pv4&amp;t</li> <li>docs.ros.org/en/humble/Tutorials/Intermediate/Launch/Creating-Launch-Files.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html</li> </ul>"},{"location":"ros2advanced/semesterproject/","title":"Semester Project","text":"<p>Completing the semester project requires more time, but it allows for the development of much more interesting tasks over several weeks. Based on the semester project, after completing the course, you can even create a thesis, dissertation, project work, or TDK paper, and there is also the possibility of fulfilling the mandatory professional practice.</p>"},{"location":"ros2advanced/semesterproject/#examples","title":"Examples","text":"<p>Example of a semester project prepared by the instructors:</p> <ul> <li>github.com/horverno/simple_random_trees: This package uses a simple random tree algorithm for path planning. Its implementation focuses on visualization rather than a comprehensive random tree-based path planning system. The <code>/display_tree node</code> advertises a <code>/path_marker_topic</code>, which is of type <code>visualization_msgs/marker_array</code>. The functions implementing the tree data structure are placed in separate header files. Implemented under <code>ROS 2 Humble</code>.</li> </ul> <p>The following examples were not necessarily created as semester projects but would be acceptable as such:</p> <ul> <li>github.com/jkk-research/wayp_plan_tools</li> <li>github.com/jkk-research/sim_wayp_plan_tools</li> <li>github.com/jkk-research/pointcloud_to_grid</li> <li>github.com/jkk-research/urban_road_filter</li> <li>github.com/dobaybalazs/curb_detection</li> <li>github.com/kkira07/Szakdolgozat</li> <li>github.com/szenergy/rviz_markers</li> <li>github.com/linklab-uva/f1tenth_gtc_tutorial</li> <li>github.com/Farraj007/Jkk-task</li> <li>github.com/leander-dsouza/breakout_gazebo</li> <li>github.com/fjp/ros-turtle-pong</li> </ul> <p>Note: We use the ROS 2 Humble version in the course, but the semester project (with justification) can be accepted in other versions as well.</p>"},{"location":"ros2advanced/semesterproject/#positive-aspects-of-the-semester-task","title":"Positive aspects of the semester task:","text":"<ul> <li>\ud83d\udc4d Well-followed documentation in Hungarian and/or English, illustrated with images. Use of Markdown.</li> <li>\ud83d\udc4d Basic information in the <code>README.md</code>, (optional) documentation in the <code>/wiki</code>.</li> <li>\ud83d\udc4d Issues.</li> <li>\ud83d\udc4d Branches.</li> <li>\ud83d\udc4d Gitignore.</li> <li>\ud83d\udc4d License.</li> <li>\ud83d\udc4d Repository topics, including the course code and SZE. Based on the topics, the repository can also be listed here: github.com/topics/sze.</li> <li>\ud83d\udc4d Extra points can be awarded if the current material is supplemented/corrected (naturally through a pull request).</li> </ul>"},{"location":"ros2advanced/semesterproject/#serious-mistakes-that-can-significantly-lower-the-grade-of-the-semester-project","title":"Serious mistakes that can significantly lower the grade of the semester project:","text":"<ul> <li>\ud83d\ude21 Compressed files in the GitHub repository (e.g., <code>zip</code> and even worse, <code>rar</code>). An exception can be made if the goal is direct compressed file handling, but source code, images, etc., should never be uploaded this way.</li> <li>\ud83d\ude21 Not original work, or the borrowed code is not referenced.</li> <li>\ud83d\ude21 In a team, only one student commits. (This obviously does not apply to single-person tasks).</li> <li>\ud83d\ude21 Few commits. The appropriate number of commits is important because it allows us to judge how the workflow progressed, who worked on what and when.</li> <li>\ud83d\ude21 No <code>README.md</code>, missing brief documentation or images.</li> <li>\ud83d\ude21 Documentation uploaded as pdf/docx instead of in the <code>/wiki</code>.</li> <li>\ud83d\ude21 File upload instead of commit.</li> <li>\ud83d\ude21 Source code screenshotted instead of using markdown syntax highlighting. (Since code in images cannot be copied, searched, etc.).</li> </ul>"},{"location":"ros2advanced/semesterproject/#ideas-for-topic-selection","title":"Ideas for topic selection","text":"<ul> <li>Inspiration can be found in previous or current theses/dissertations: horverno.github.io/temaajanlatok</li> <li>It is advisable to choose a topic that you would enjoy working on for weeks/months. If, for example, visualization, algorithm practice, 3D, or artificial intelligence is appealing, then it is advisable to choose a topic accordingly.</li> <li>Previous theses, semester projects are available and can be requested here. It is important that these must not be shared further, they are available for educational purposes only.</li> <li>Numerous ROS 2 projects here: github.com/fkromer/awesome-ros2</li> </ul> <p>Tip</p> <p>It is highly recommended to obtain the GitHub Student Developer Pack, which includes Copilot. You can read more about it here: sze-info.github.io/ajr/bevezetes/copilot/#github-copilot-beszerzese-sze-hallgatoknak</p> <p></p>"},{"location":"ros2advanced/semesterproject/#evaluation-criteria","title":"Evaluation criteria","text":"<p>The criteria were developed based on the evaluation criteria of a similar course at \u00d3buda University. - The ratio of own work to the used codebase (with proper references) - Work producing evaluable results - The quality of the presentation (ppt, videos, live demo, any additional tools used) - The completeness of the solution - Proper <code>ROS 2</code> communication / best practice application - The structure of the program - The quality of the implementation - The documentation of the code - Consultation - The difficulty of the chosen task</p>"},{"location":"ros2advanced/semesterproject/#recommended-method-for-creating-the-semester-repo-template","title":"Recommended method for creating the semester repo: <code>template</code>","text":"<p>We have created a so-called template repo in both C++ and Python, which makes it easier to create the first repository containing a package:</p> <ul> <li>github.com/sze-info/ros2_cpp_template</li> <li>github.com/sze-info/ros2_py_template</li> </ul> <p>Info</p> <p>You can read about it here.</p> <p></p>"},{"location":"ros2advanced/semesterproject/#meme","title":"Meme","text":"<p>Credit: pycoders</p> <p></p> <p>Credit: knowyourmeme</p>"},{"location":"ros2advanced/smallassignment/","title":"Small Assignment","text":"<p>The goal of the small assignment is for students to gain practical experience with ROS 2 and GitHub alongside the beginner-level theoretical knowledge acquired in class. The small assignment can be completed in a short amount of time: an instructor can finish it in a few hours, and an average student can complete it in a few afternoons. It is important to note that the assignment is a requirement for a signature.</p> <p>Expected qualifications:</p> <ul> <li>One package, 1 or 2 nodes</li> <li>At least 1 publisher or 1 subscriber (more are allowed)</li> <li>Short documentation that includes the build process and node-topic relationships, detailed as in the examples</li> <li>Correct naming</li> <li>Use of a template or a custom solution, but with the level of detail as in the examples</li> <li>Preferably compiles without errors, but <code>build warnings</code> are often acceptable; the key is learning</li> <li>As many commits as possible to show the workflow</li> <li>Short length: 30-100 lines of code per node + CMakeLists.txt, package.xml, README.md, launch files (longer is acceptable but not required)</li> <li>Preferably illustrated with images (see examples)</li> <li>Preferably a mermaid diagram showing the relationships between nodes and topics (see examples, description)</li> </ul> <p>Danger</p> <p>The small assignment will be acceptable if the node can be built and produces the output as specified in the task description! If this is not met, the student will have one week to correct it from the time the issue is posted!</p>"},{"location":"ros2advanced/smallassignment/#examples","title":"Examples","text":"<p>Example small assignments created by instructors:</p> <ul> <li>github.com/szepilot/sze_sw1_szinusz: The package consists of two nodes. The <code>/gen_node</code> generates sine waves and random numbers, which are advertised in two <code>std_msgs/float32</code> topics. The <code>/sum_node</code> sums the generated topics and advertises them in another <code>std_msgs/float32</code> topic. Implemented under <code>ROS 2 Humble</code>.</li> <li>github.com/horverno/hor_d20_batman_turtle: The package consists of one node, which can draw a \"Batman logo\" in the turtlesim simulator by plotting the trajectory. The advertised topic is of type <code>geometry_msgs/twist</code>. Implemented under <code>ROS 2 Humble</code>.</li> <li>github.com/gfigneczi1/ign_b7e_array_sorter: The package consists of one node. The <code>/array_sorter</code> node subscribes to a <code>std_msgs/msg/float32_multi_array</code> type topic, then advertises its sorted version in ascending order. Implemented under <code>ROS 2 Humble</code>.</li> <li>github.com/gfigneczi1/ign_b7e_temp_sens: The package consists of two nodes. The <code>/sensor_node</code> generates simulated sensor data: temperature and humidity, advertised in two separate <code>sensor_msgs/Temperature</code> and <code>sensor_msgs/RelativeHumidity</code> type topics. The <code>/monitor_node</code> monitors these data, and if the temperature exceeds a certain threshold or the humidity exceeds another, it sends an alert in a <code>std_msgs/String</code> type topic. Implemented under <code>ROS 2 Humble</code>.</li> <li>The package consists of one node. The <code>/minecraft_node</code> advertises a <code>visualization_msgs/Marker</code> type topic. Subscribing to the topic allows displaying a Minecraft character in RViz2. Implemented under <code>ROS 2 Humble</code>.</li> <li>github.com/umiklos/ung_isl_ajr_point_and_orientation: The package consists of two nodes. One node generates a <code>geometry_msgs/Point</code> type, and the other node advertises a <code>geometry_msgs/Pose</code> type by adding orientation. Implemented under <code>ROS 2 Humble</code>.</li> <li>github.com/umiklos/ung_isl_ajr_data_generation_and_control: The package consists of two nodes. The <code>/sensor_data_generator</code> generates simulated data with a fictitious sensor, such as distance and speed, advertised in two separate <code>sensor_msgs/Range</code> and <code>geometry_msgs/Twist</code> type topics. The other node, the <code>/control_node</code>, monitors these data and makes control decisions for the robot, which are printed in the terminal. Implemented under <code>ROS 2 Humble</code>.</li> <li>The package consists of two nodes. The <code>/imu_data_publisher</code> provides accelerometer and gyroscope sensor data, advertised in a <code>sensor_msgs/Imu</code> type topic. The other node, the <code>/imu_data_analyzer</code>, analyzes these IMU data and creates reports on the robot's status in a <code>diagnostic_msgs/DiagnosticArray</code> type topic. Implemented under <code>ROS 2 Humble</code>.</li> </ul> <p>It is recommended, but not mandatory, to choose from <code>diagnostic_msgs</code>, <code>geometry_msgs</code>, <code>nav_msgs</code>, <code>sensor_msgs</code>, <code>shape_msgs</code>, <code>std_msgs</code>, <code>trajectory_msgs</code>, <code>visualization_msgs</code>.</p>"},{"location":"ros2advanced/smallassignment/#recommended-method-for-creating-the-small-assignment-repo-template","title":"Recommended method for creating the small assignment repo: <code>template</code>","text":"<p>We have created a so-called template repo in both C++ and Python, which facilitates the creation of the first repository containing a package:</p> <ul> <li>github.com/sze-info/ros2_cpp_template</li> <li>github.com/sze-info/ros2_py_template</li> </ul> <p>Tip</p> <p>Read more about it here.</p> <p></p>"},{"location":"ros2advanced/smallassignment/#repo-name","title":"Repo name","text":"<ul> <li>The repository name should follow this pattern: <code>VVV_NNN_optional</code>, where</li> <li><code>VVV</code> is the first 3 characters of the last name, in lowercase</li> <li><code>NNN</code> is the first 3 characters of the Neptun code, in lowercase</li> <li><code>optional</code> is an optional addition, in lowercase</li> <li>The above should be separated by an underscore <code>_</code> and all in lowercase</li> <li>Example: Istv\u00e1n Szab\u00f3, with Neptun code F99AXW, creating a small assignment about random numbers could have a URL like: <code>github.com/szaboistvan/sza_f99_random</code>.</li> </ul>"},{"location":"ros2halado/","title":"ROS 2 halad\u00f3 funkci\u00f3k","text":""},{"location":"ros2halado/docker/","title":"Docker","text":"<p>Sz\u00e1mos tutorial \u00e9s le\u00edr\u00e1s \u00e9rhet\u0151 el a Docker haszn\u00e1lat\u00e1r\u00f3l, ebb\u0151l viszont kev\u00e9s f\u00f3kusz\u00e1l a robotik\u00e1ra.</p>"},{"location":"ros2halado/docker/#forrasok","title":"Forr\u00e1sok","text":"<ul> <li>articulatedrobotics.xyz</li> <li>Youtube playlist articulatedrobotics</li> </ul>"},{"location":"ros2halado/mcap/","title":"MCAP f\u00e1jlok","text":""},{"location":"ros2halado/mcap/#mcap-fajlok","title":"<code>MCAP</code> f\u00e1jlok","text":"<p>Az <code>ROS 2</code> az log adatokhoz az <code>MCAP</code> form\u00e1tumot haszn\u00e1lja. Ez a form\u00e1tum nem dedik\u00e1ltan az ROS saj\u00e1t form\u00e1tuma, hanem egy ny\u00edlt forr\u00e1sk\u00f3d\u00fa kont\u00e9nerf\u00e1jl t\u00edpus tetsz\u0151leges multimod\u00e1lis log-adatokhoz. T\u00e1mogatja az id\u0151b\u00e9lyegz\u0151vel ell\u00e1tott, el\u0151re sorba rendezett adatokat. \u00cdgy ide\u00e1lis a pub/sub vagy robotikai alkalmaz\u00e1sokban val\u00f3 haszn\u00e1latra is, a <code>ROS 2</code> is ez\u00e9rt d\u00f6nt\u00f6tt mellette. A k\u00f6vetkez\u0151kben arr\u00f3l lesz sz\u00f3, hogyan lehets\u00e9ges a form\u00e1tum C++,   Go, Python, Rust,   Swift vagy TypeScript nyelven t\u00f6rt\u00e9n\u0151 szerkeszt\u00e9se. Illetve egy python p\u00e9ld\u00e1n kereszt\u00fcl gyakorlati oldalr\u00f3l is szeml\u00e9ltetj\u00fck ezt.</p> <p>Az MCAP egy fejlett logf\u00e1jlform\u00e1tum, amely kifejezetten a pub/sub \u00fczenetek \u00e9s multimod\u00e1lis szenzoradatok id\u0151b\u00e9lyeggel ell\u00e1tott csatorn\u00e1inak t\u00e1rol\u00e1s\u00e1ra szolg\u00e1l. Nem k\u00f6t\u0151dik egyetlen soros\u00edt\u00e1si form\u00e1tumhoz sem, \u00edgy k\u00e9pes b\u00e1rmilyen form\u00e1tum\u00fa bin\u00e1ris \u00fczenetek, p\u00e9ld\u00e1ul Protobuf, DDS (CDR), ROS, JSON \u00e9s m\u00e1sok r\u00f6gz\u00edt\u00e9s\u00e9re \u00e9s visszaj\u00e1tsz\u00e1s\u00e1ra. Az MCAP nagy teljes\u00edtm\u00e9ny\u0171 \u00edr\u00e1st tesz lehet\u0151v\u00e9 a sororient\u00e1lt, csak hozz\u00e1f\u0171z\u0151 tervez\u00e9s\u00e9nek k\u00f6sz\u00f6nhet\u0151en, amely minimaliz\u00e1lja a lemez I/O m\u0171veleteket \u00e9s cs\u00f6kkenti az adatveszt\u00e9s kock\u00e1zat\u00e1t nem tiszta le\u00e1ll\u00edt\u00e1sok eset\u00e9n.</p> <p>Az MCAP \u00f6n\u00e1ll\u00f3 form\u00e1tum, mivel az \u00fczenetek s\u00e9m\u00e1it is az adatok mellett t\u00e1rolja, \u00edgy a f\u00e1jlok a j\u00f6v\u0151ben is olvashat\u00f3ak maradnak, m\u00e9g akkor is, ha a k\u00f3db\u00e1zis id\u0151k\u00f6zben v\u00e1ltozik. Az MCAP f\u00e1jlok opcion\u00e1lis indexet tartalmaznak, ami gyors \u00e9s hat\u00e9kony adatolvas\u00e1st tesz lehet\u0151v\u00e9, m\u00e9g alacsony s\u00e1vsz\u00e9less\u00e9g\u0171 internetkapcsolaton kereszt\u00fcl is. Opcion\u00e1lis t\u00f6m\u00f6r\u00edt\u00e9st is k\u00edn\u00e1l, p\u00e9ld\u00e1ul LZ4 vagy Zstandard form\u00e1j\u00e1ban, mik\u00f6zben tov\u00e1bbra is t\u00e1mogatja a hat\u00e9kony indexelt olvas\u00e1st.</p> <p>Az MCAP sz\u00e9les k\u00f6r\u0171 nyelvi t\u00e1mogat\u00e1st ny\u00fajt, nat\u00edv olvas\u00f3 \u00e9s \u00edr\u00f3 k\u00f6nyvt\u00e1rakkal C++, Go, Python, Rust, Swift \u00e9s TypeScript nyelveken. A form\u00e1tum rugalmasan konfigur\u00e1lhat\u00f3 opcion\u00e1lis funkci\u00f3kkal, mint a darabol\u00e1s, indexel\u00e9s, CRC ellen\u0151rz\u0151\u00f6sszegek \u00e9s t\u00f6m\u00f6r\u00edt\u00e9s, hogy a megfelel\u0151 kompromisszumokat k\u00edn\u00e1lja az adott alkalmaz\u00e1shoz. Az MCAP gy\u00e1rt\u00e1sra k\u00e9sz form\u00e1tum, amelyet sz\u00e9les k\u00f6rben haszn\u00e1lnak k\u00fcl\u00f6nb\u00f6z\u0151 c\u00e9gek, p\u00e9ld\u00e1ul auton\u00f3m j\u00e1rm\u0171vek \u00e9s dr\u00f3nok eset\u00e9ben, \u00e9s ez az alap\u00e9rtelmezett logform\u00e1tum a ROS 2-ben.</p> <p>Az <code>MCAP</code> f\u00e1jlform\u00e1tum ROS 2 agnosztikus, teh\u00e1t nem f\u00fcgg mag\u00e1t\u00f3l az ROS 2-t\u0151l, \u00edgy b\u00e1rmilyen Python projektben haszn\u00e1lhat\u00f3. Fontos megjegyezni, hogy a <code>rosbag2-api</code> python csomag viszont ROS 2 f\u00fcgg\u0151. \u00cdgy c\u00e9lszer\u0171 ink\u00e1bb az <code>mcap-ros2-support</code> python csomag haszn\u00e1lata, amely nem ig\u00e9nyel ROS 2-t, \u00edgy p\u00e9ld\u00e1ul Windowson is futtathat\u00f3.</p> <p>A Python MCAP ROS2 support csomag (<code>mcap-ros2-support</code>) lehet\u0151v\u00e9 teszi a ROS2 t\u00e1mogat\u00e1st a Python MCAP f\u00e1jlform\u00e1tum olvas\u00f3 sz\u00e1m\u00e1ra. Telep\u00edts\u00fck a k\u00f6vetkez\u0151 parancshoz hasonl\u00f3 m\u00f3don:</p> <pre><code>pip install mcap mcap-ros2-support matplotlib numpy pandas scipy\n</code></pre>"},{"location":"ros2halado/mcap/#mcap-fajl-olvasasa-pelda","title":"MCAP f\u00e1jl olvas\u00e1sa p\u00e9lda","text":"<p>A github.com/jkk-research/jkk_utils/tree/ros2/mcap_scripts el\u00e9r\u00e9sen t\u00f6bb hasonl\u00f3 p\u00e9lda is megtal\u00e1lhat\u00f3:</p> <pre><code>from mcap_ros2.decoder import DecoderFactory\nfrom mcap.reader import make_reader\ndef main():\n    with open('C:\\\\temp\\\\test.mcap', \"rb\") as f:\n        reader = make_reader(f, decoder_factories=[DecoderFactory()])\n        #list all topics and types\n        channels = reader.get_summary().channels.items()\n        print(\"Available topics are the following:\")\n        for index, (channel_key, channel_value) in enumerate(channels):\n            print(\"%2d. topic: %s\" % (index+1, channel_value.topic))\n</code></pre>"},{"location":"ros2halado/mcap/#forrasok","title":"Forr\u00e1sok","text":"<ul> <li>docs.ros.org/en/humble/How-To-Guides/Visualizing-ROS-2-Data-With-Foxglove-Studio.html</li> <li>github.com/jkk-research/jkk_utils/tree/ros2/mcap_scripts</li> <li>mcap.dev</li> <li>mcap.dev/docs/python/raw_reader_writer_example</li> <li>pypi.org/project/mcap-ros2-support (\u2714\ufe0f recommended, no ROS 2 dependency)</li> <li>pypi.org/project/rosbag2-api (\u274c ROS 2 dependency)</li> </ul>"},{"location":"ros2halado/pointcloud_to_grid/","title":"<code>pointcloud_to_grid</code> ROS 2 package","text":"<p>This package converts <code>sensor_msgs/PointCloud2</code> LIDAR data to <code>nav_msgs/OccupancyGrid</code> 2D map data based on intensity and / or height.</p> <p></p> <p>Link: github.com/jkk-research/pointcloud_to_grid</p>"},{"location":"ros2halado/py_cpp/","title":"Comparison of Python and C++","text":"PythonC++ <pre><code>#  ros2 topic type /lexus3/gps/duro/current_pose\n#  geometry_msgs/msg/PoseStamped\n#  ros2 interface show geometry_msgs/msg/PoseStamped\n\nimport rclpy\nfrom rclpy.node import Node\nfrom geometry_msgs.msg import PoseStamped\n\n\nclass SimplePoseSub(Node):\n\n    def __init__(self):\n        super().__init__('simple_pose_sub')\n        self.sub1_ = self.create_subscription(PoseStamped, '/lexus3/gps/duro/current_pose', self.topic_callback, 10)\n\n\n\n    def topic_callback(self, msg):\n\n        self.get_logger().info('x: %.3f, y: %.3f', msg.pose.position.x, msg.pose.position.y)\n\n\n\n\ndef main(args=None):\n\n    rclpy.init(args=args)                   ## Initialize the ROS 2 client library\n    simple_pose_sub = SimplePoseSub()\n    rclpy.spin(simple_pose_sub)             ## Create a node and spin\n    simple_pose_sub.destroy_node()\n    rclpy.shutdown()                        ## Shutdown the ROS 2 client library\n\nif __name__ == '__main__':\n    main()\n</code></pre> <pre><code>// ros2 topic type /lexus3/gps/duro/current_pose\n// geometry_msgs/msg/PoseStamped\n// ros2 interface show geometry_msgs/msg/PoseStamped\n\n#include \"rclcpp/rclcpp.hpp\"\n#include &lt;memory&gt;\n#include \"geometry_msgs/msg/pose_stamped.hpp\"\nusing std::placeholders::_1;\n\nclass SimplePoseSub : public rclcpp::Node{\npublic:\n    SimplePoseSub() : Node(\"simple_pose_sub\")\n    {\n        sub1_ = this-&gt;create_subscription&lt;geometry_msgs::msg::PoseStamped&gt;(\"/lexus3/gps/duro/current_pose\", 10, std::bind(&amp;SimplePoseSub::topic_callback, this, _1));\n    }\n\nprivate:\n    void topic_callback(const geometry_msgs::msg::PoseStamped &amp;msg) const\n    {\n        RCLCPP_INFO(this-&gt;get_logger(), \"x: %.3f, y: %.3f\", msg.pose.position.x, msg.pose.position.y);\n    }\n    rclcpp::Subscription&lt;geometry_msgs::msg::PoseStamped&gt;::SharedPtr sub1_;\n    };\n\nint main(int argc, char *argv[])\n{\n    rclcpp::init(argc, argv);               // Initialize the ROS 2 client library\n    rclcpp::spin(\n        std::make_shared&lt;SimplePoseSub&gt;()); // Create a node and spin\n\n    rclcpp::shutdown();                     // Shutdown the ROS 2 client library\n    return 0;\n\n}\n</code></pre>"},{"location":"ros2halado/qos/","title":"DDS protokoll","text":"<p>A DDS (Data Distribution Service) az Object Management Group (OMG) \u00e1ltal standardiz\u00e1lt kommuink\u00e1ci\u00f3s protokoll.</p> <p></p> <p>A DDS protokoll sz\u00e9les k\u00f6rben haszn\u00e1lt az ipari automatiz\u00e1l\u00e1sban, a h\u00e1l\u00f3zatos\u00edtott rendszerekben \u00e9s m\u00e1s ter\u00fcleteken, ahol az elosztott adatkommunik\u00e1ci\u00f3 \u00e9s a val\u00f3s idej\u0171 adatfeldolgoz\u00e1s kiemelt fontoss\u00e1ggal b\u00edr. DDS-\u00e1tvitel rugalmass\u00e1g\u00e1b\u00f3l profit\u00e1l vesztes\u00e9ges vezet\u00e9k n\u00e9lk\u00fcli h\u00e1l\u00f3zatokkal rendelkez\u0151 k\u00f6rnyezetekben, ahol a \"legjobb er\u0151fesz\u00edt\u00e9s\" (<code>best effort</code>) elv lenne megfelel\u0151bb vagy val\u00f3s idej\u0171 sz\u00e1m\u00edt\u00e1stechnikai rendszerekben, ahol pedig a megfelel\u0151 min\u0151s\u00e9g. Az id\u0151z\u00edt\u00e9sek betart\u00e1s\u00e1hoz sz\u00fcks\u00e9g van a szolg\u00e1ltat\u00e1si profilra. A QoS \"h\u00e1zirendek\" halmaza egy QoS \"profilt\" alkot. Tekintettel az adott forgat\u00f3k\u00f6nyvh\u00f6z megfelel\u0151 QoS-ir\u00e1nyelvek kiv\u00e1laszt\u00e1s\u00e1nak bonyolults\u00e1g\u00e1ra, a kommunik\u00e1ci\u00f3 el\u0151re defini\u00e1lt QoS-profilokat biztos\u00edt \u00e1ltal\u00e1nos haszn\u00e1lati esetekre (pl. szenzoradatok). </p>"},{"location":"ros2halado/qos/#szolgaltatasminoseg-qos","title":"Szolg\u00e1ltat\u00e1smin\u0151s\u00e9g (QoS)","text":"<p>A szolg\u00e1ltat\u00e1smin\u0151s\u00e9g  angol sz\u00f3val Quality of Service vagy r\u00f6viden QoS. Az alap QoS-profil a k\u00f6vetkez\u0151 h\u00e1zirendek be\u00e1ll\u00edt\u00e1sait tartalmazza:</p>"},{"location":"ros2halado/qos/#mult-history","title":"M\u00falt (<code>history</code>)","text":"<ul> <li>Utols\u00f3 megtart\u00e1sa (<code>keep last</code>): legfeljebb N mint\u00e1t t\u00e1rolhat, a sorm\u00e9lys\u00e9g opci\u00f3val konfigur\u00e1lhat\u00f3.</li> <li>Mind megtart\u00e1sa (<code>keep all</code>): az \u00f6sszes mint\u00e1t t\u00e1rolja, az alapul szolg\u00e1l\u00f3 k\u00f6ztes szoftver konfigur\u00e1lt er\u0151forr\u00e1s-korl\u00e1tjait\u00f3l f\u00fcgg\u0151en.</li> </ul>"},{"location":"ros2halado/qos/#melyseg-depth","title":"M\u00e9lys\u00e9g (<code>depth</code>)","text":"<ul> <li>Sor m\u00e9rete: csak akkor teljes\u00fcl, ha az \"el\u0151zm\u00e9nyek\" h\u00e1zirend \"utols\u00f3 meg\u0151rz\u00e9sre\" van \u00e1ll\u00edtva.</li> </ul>"},{"location":"ros2halado/qos/#megbizhatosag-relyability","title":"Megb\u00edzhat\u00f3s\u00e1g (<code>relyability</code>)","text":"<ul> <li>Legjobb er\u0151fesz\u00edt\u00e9s (<code>best effort</code>): pr\u00f3b\u00e1ljon meg mint\u00e1kat sz\u00e1ll\u00edtani, de elvesz\u00edtheti azokat, ha a h\u00e1l\u00f3zat nem robusztus.</li> <li>Megb\u00edzhat\u00f3 (<code>reliable</code>): garant\u00e1lja a mint\u00e1k kisz\u00e1ll\u00edt\u00e1s\u00e1t, t\u00f6bbsz\u00f6r is pr\u00f3b\u00e1lkozhat.</li> </ul>"},{"location":"ros2halado/qos/#tartossag-durability","title":"Tart\u00f3ss\u00e1g (<code>durability</code>)","text":"<ul> <li>\u00c1tmeneti helyi (<code>transient local</code>): a kiad\u00f3 felel\u0151s a \u201ek\u00e9s\u0151n csatlakoz\u00f3\u201d el\u0151fizet\u00e9sek tart\u00f3s mint\u00e1i\u00e9rt.</li> <li>Ill\u00e9kony: nem t\u00f6rt\u00e9nik k\u00eds\u00e9rlet a mint\u00e1k fennmarad\u00e1s\u00e1ra.</li> </ul>"},{"location":"ros2halado/qos/#hatarido-idozites-deadline","title":"Hat\u00e1rid\u0151, id\u0151z\u00edt\u00e9s (<code>deadline</code>)","text":"<ul> <li>Id\u0151tartam: a v\u00e1rhat\u00f3 maxim\u00e1lis id\u0151tartam a k\u00f6vetkez\u0151 \u00fczenetek k\u00f6zz\u00e9t\u00e9tele k\u00f6z\u00f6tt egy t\u00e9m\u00e1ban</li> </ul>"},{"location":"ros2halado/qos/#elettartam-lifespan","title":"\u00c9lettartam (<code>lifespan</code>)","text":"<ul> <li>Id\u0151tartam: az \u00fczenet k\u00f6zz\u00e9t\u00e9tele \u00e9s fogad\u00e1sa k\u00f6z\u00f6tti maxim\u00e1lis id\u0151tartam an\u00e9lk\u00fcl, hogy az \u00fczenet elavultnak vagy lej\u00e1rtnak min\u0151s\u00fclne (a lej\u00e1rt \u00fczeneteket a rendszer eldobja, \u00e9s gyakorlatilag soha nem \u00e9rkezik meg).</li> </ul>"},{"location":"ros2halado/qos/#elenkseg-liveliness","title":"\u00c9l\u00e9nks\u00e9g (<code>liveliness</code>)","text":"<ul> <li>Automatikus: a rendszer a node \u00f6sszes publisherj\u00e9t \u00e9l\u0151nek tekinti egy \u00fajabb \"elenged\u00e9si id\u0151tartamra\", ha valamelyik kiad\u00f3ja k\u00f6zz\u00e9tett egy \u00fczenetet.</li> <li>Manu\u00e1lis: a rendszer a publishert egy m\u00e1sik \" elenged\u00e9si id\u0151tartamra\" \u00e9l\u0151nek tekinti, ha manu\u00e1lisan (a publisher API-j\u00e1nak h\u00edv\u00e1s\u00e1val) azt \u00e1ll\u00edtja, hogy m\u00e9g \u00e9letben van.</li> </ul>"},{"location":"ros2halado/qos/#elengedesi-idotartam-lease-duration","title":"Elenged\u00e9si id\u0151tartam (<code>lease duration</code>)","text":"<ul> <li>Id\u0151tartam: az a maxim\u00e1lis id\u0151tartam, ameddig a kommunik\u00e1ci\u00f3s ad\u00f3nak jeleznie kell, hogy \u00e9letben van, miel\u0151tt a rendszer \u00fagy \u00edt\u00e9ln\u00e9 meg, hogy elvesztette az \u00e9l\u0151s\u00e9g\u00e9t.</li> </ul>"},{"location":"ros2halado/qos/#qos-kompatibilitas","title":"QoS kompatibilit\u00e1s","text":""},{"location":"ros2halado/qos/#gyakorlat","title":"Gyakorlat","text":""},{"location":"ros2halado/qos/#forrasok","title":"Forr\u00e1sok","text":"<ul> <li>docs.ros.org/en/humble/Concepts/Intermediate/About-Quality-of-Service-Settings.html</li> <li>docs.ros.org/en/humble/Tutorials/Intermediate/Launch/Creating-Launch-Files.html</li> </ul>"},{"location":"ros2halado/ros2launch/","title":"<code>ROS 2</code> launch \u00e9s <code>ROS 2</code> egy\u00e9b halad\u00f3 koncepci\u00f3k","text":""},{"location":"ros2halado/ros2launch/#bevezeto","title":"Bevezet\u0151","text":"<p>Az ROS 2 launch rendszere seg\u00edti a felhaszn\u00e1l\u00f3 \u00e1ltal defini\u00e1lt rendszer konfigur\u00e1ci\u00f3j\u00e1nak megad\u00e1s\u00e1t, majd a konfigur\u00e1ci\u00f3 szerinti v\u00e9grehajt\u00e1s\u00e1t. A konfigur\u00e1ci\u00f3s l\u00e9p\u00e9s a k\u00f6vetkez\u0151ket tartalmazza:   - mely programok ker\u00fcljenek futtat\u00e1sra,   - milyen argumentumokat kapjanak a futtatott programok,   - ROS-specifikus konvenci\u00f3knak megfelel\u0151 \u00f6sszetev\u0151k, amelyek a komponensek k\u00f6nny\u0171 \u00fajrahasznos\u00edthat\u00f3s\u00e1g\u00e1t teszik lehet\u0151v\u00e9.</p> <p>Fontos megeml\u00edteni tov\u00e1bb\u00e1, hogy a megold\u00e1s fel\u00fcgyeli az elind\u00edtott folyamatokat, \u00e9s k\u00e9pes reag\u00e1lni a folyamatok fut\u00e1si \u00e1llapot\u00e1ban bek\u00f6vetkez\u0151 v\u00e1ltoz\u00e1sokra.</p> <p>Launch f\u00e1jlok k\u00e9sz\u00edt\u00e9se t\u00f6rt\u00e9nhet Python, XML, vagy YAML seg\u00edts\u00e9g\u00e9vel.</p>"},{"location":"ros2halado/ros2launch/#elokeszuletek","title":"El\u0151k\u00e9sz\u00fcletek","text":""},{"location":"ros2halado/ros2launch/#hozzuk-letre-a-example_launch-package-t","title":"Hozzuk l\u00e9tre a <code>example_launch</code> package-t","text":"<p>Ha esetleg m\u00e1r l\u00e9tezne a <code>example_launch</code> package akkor t\u00f6r\u00f6lj\u00fck. (G\u00e9pteremben elk\u00e9pzelehet\u0151, hogy el\u0151z\u0151 f\u00e9l\u00e9vben valaki l\u00e9trehozta.)</p> <pre><code>cd ~ &amp;&amp; test -d \"ros2_ws/src/example_launch\" &amp;&amp; echo Letezik || echo Nem letezik\n</code></pre> <pre><code>rm -r  ~/ros2_ws/src/example_launch\n</code></pre> <p>Nyissunk egy \u00faj termin\u00e1lt, \u00e9s source-oljuk a telep\u00edt\u00e9st (ha nincs <code>bashrc</code>-ben), hogy a <code>ros2</code> parancsok m\u0171k\u00f6djenek.</p> <p>Navig\u00e1ljunk az m\u00e1r l\u00e9trehozott <code>ros2_ws</code> k\u00f6nyvt\u00e1rba.</p> <p>Fontos, hogy a csomagokat az <code>src</code> k\u00f6nyvt\u00e1rban kell l\u00e9trehozni, nem a munkater\u00fclet gy\u00f6ker\u00e9ben. Teh\u00e1t navig\u00e1ljunk a <code>ros2_ws/src</code> mapp\u00e1ba, \u00e9s futtassuk a package l\u00e9trehoz\u00f3 parancsot:</p> <pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>ros2 pkg create --build-type ament_cmake example_launch\n</code></pre> <p>A termin\u00e1l egy \u00fczenetet k\u00fcld vissza, amely meger\u0151s\u00edti a <code>example_launch</code> csomag \u00e9s az \u00f6sszes sz\u00fcks\u00e9ges f\u00e1jl \u00e9s mappa l\u00e9trehoz\u00e1s\u00e1t.</p>"},{"location":"ros2halado/ros2launch/#launch-mappa","title":"Launch mappa","text":"<p>Hozzunk l\u00e9tre egy mapp\u00e1t a launch f\u00e1jlok r\u00e9sz\u00e9re:</p> <pre><code>cd ~/ros2_ws/src/example_launch\n</code></pre> <pre><code>mkdir launch\n</code></pre>"},{"location":"ros2halado/ros2launch/#launch-fajl-letrehozasa","title":"Launch f\u00e1jl l\u00e9trehoz\u00e1sa","text":"<pre><code>cd launch\n</code></pre> <pre><code>code turtlesim_mimc_launch.py\n</code></pre> <p>\u00c1ll\u00edtsunk \u00f6ssze egy launch f\u00e1jlt a <code>turtlesim</code> csomag elemeivel, Python nyelv alkalmaz\u00e1s\u00e1val.</p> <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n\ndef generate_launch_description():\n    return LaunchDescription([\n        Node(\n            package='turtlesim',\n            namespace='turtlesim1',\n            executable='turtlesim_node',\n            name='sim'\n        ),\n        Node(\n            package='turtlesim',\n            namespace='turtlesim2',\n            executable='turtlesim_node',\n            name='sim'\n        ),\n        Node(\n            package='turtlesim',\n            executable='mimic',\n            name='mimic',\n            remappings=[\n                ('/input/pose', '/turtlesim1/turtle1/pose'),\n                ('/output/cmd_vel', '/turtlesim2/turtle1/cmd_vel'),\n            ]\n        )\n    ])\n</code></pre> <p>A fent le\u00edrt m\u00f3don l\u00e9trehozott launch f\u00e1jl a kor\u00e1bbiakban megismert <code>turtlesim</code> csomag h\u00e1rom node-j\u00e1t ind\u00edtja el. A c\u00e9l k\u00e9t turtlesim ablak megnyit\u00e1sa, majd az egyik tekn\u0151s mozg\u00e1s\u00e1nak megism\u00e9tl\u00e9se a m\u00e1sik tekn\u0151ssel. A k\u00e9t turtlesim node ind\u00edt\u00e1s\u00e1ban mind\u00f6ssze a n\u00e9vt\u00e9r (namespace) t\u00e9r el. Az egyedi n\u00e9vterek alkalmaz\u00e1sa lehet\u0151v\u00e9 teszi k\u00e9t azonos node egyidej\u0171 elind\u00edt\u00e1s\u00e1t n\u00e9vkonfliktus n\u00e9lk\u00fcl. \u00cdgy mindk\u00e9t tekn\u0151s ugyanazon a topicon fogad utas\u00edt\u00e1sokat, \u00e9s ugyanazon a topicon k\u00f6zli a helyzet\u00e9t. Az egy\u00e9ni n\u00e9vterek lehet\u0151v\u00e9 teszik a k\u00e9t tekn\u0151s \u00fczeneteinek megk\u00fcl\u00f6nb\u00f6ztet\u00e9s\u00e9t.</p> <p>Az utols\u00f3 node szint\u00e9n a <code>turtlesim</code> csomagb\u00f3l van, viszont a futtathat\u00f3 f\u00e1jl elt\u00e9r: <code>mimic</code>. Ez a csom\u00f3pont ki van eg\u00e9sz\u00edtve n\u00e9vmegfeleltet\u00e9sekkel. P\u00e9ld\u00e1ul az egyszer\u0171 <code>/input/pose</code> megfelel\u0151je ezesetben <code>/turtlesim1/turtle1/pose</code> \u00e9s a kor\u00e1bban megismert <code>/output/cmd_vel</code> most <code>/turtlesim2/turtle1/cmd_vel</code>. Ez azt jelenti, hogy <code>mimic</code> feliratkozik a <code>/turtlesim1/sim</code> pose topic-ra, \u00e9s \u00fajra publisholja \u00fagy, hogy <code>/turtlesim2/sim</code> sebess\u00e9g utas\u00edt\u00e1sa feliratkozzon r\u00e1. Teh\u00e1t, <code>turtlesim2</code> ut\u00e1nozni fogja <code>turtlesim1</code> mozg\u00e1s\u00e1t. </p>"},{"location":"ros2halado/ros2launch/#kod-reszleteinek-attekintese","title":"K\u00f3d r\u00e9szleteinek \u00e1ttekint\u00e9se","text":"<p>Ezek a kifejez\u00e9sek Python <code>launch</code> modulokat import\u00e1lnak.</p> <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\n</code></pre> <p>Ezt k\u00f6vet\u0151en kezd\u0151dik a launch le\u00edr\u00e1sa:</p> <pre><code>def generate_launch_description():\n  return LaunchDescription([\n\n  ])\n</code></pre> <p>A launch le\u00edr\u00e1sban szerepl\u0151 els\u0151 k\u00e9t utas\u00edt\u00e1s ind\u00edtja a k\u00e9t turtlesim ablakot:</p> <pre><code>Node(\n    package='turtlesim',\n    namespace='turtlesim1',\n    executable='turtlesim_node',\n    name='sim'\n),\nNode(\n    package='turtlesim',\n    namespace='turtlesim2',\n    executable='turtlesim_node',\n    name='sim'\n),\n</code></pre> <p>V\u00e9g\u00fcl megt\u00f6rt\u00e9nik a mozg\u00e1s ut\u00e1nz\u00e1s\u00e1t megval\u00f3s\u00edt\u00f3 node ind\u00edt\u00e1sa is:</p> <pre><code>Node(\n    package='turtlesim',\n    executable='mimic',\n    name='mimic',\n    remappings=[\n      ('/input/pose', '/turtlesim1/turtle1/pose'),\n      ('/output/cmd_vel', '/turtlesim2/turtle1/cmd_vel'),\n    ]\n)\n</code></pre>"},{"location":"ros2halado/ros2launch/#ros2-launch-hasznalata","title":"<code>ROS2</code> launch haszn\u00e1lata","text":"<p>A l\u00e9trehozott launch f\u00e1jl elind\u00edt\u00e1sa az al\u00e1bbi m\u00f3don t\u00f6rt\u00e9nik:</p> <p><pre><code>cd ~/ros2_ws/src/example_launch/launch # bel\u00e9p\u00fcnk a launch f\u00e1jlt tartalmaz\u00f3 mapp\u00e1ba\n</code></pre> <pre><code>ros2 launch turtlesim_mimc_launch.py\n</code></pre></p> <p>K\u00e9t turtlesim ablak fog megny\u00edlni, \u00e9s a k\u00f6vetkez\u0151 <code>[INFO]</code> kimenet lesz l\u00e1that\u00f3, felsorolva az ind\u00edtott node-okat: <pre><code>[INFO] [launch]: Default logging verbosity is set to INFO\n[INFO] [turtlesim_node-1]: process started with pid [11714]\n[INFO] [turtlesim_node-2]: process started with pid [11715]\n[INFO] [mimic-3]: process started with pid [11716]\n</code></pre></p> <p>Hogy kipr\u00f3b\u00e1ljuk az elind\u00edtott rendszer m\u0171k\u00f6d\u00e9s\u00e9t, egy \u00faj termin\u00e1lban hirdess\u00fcnk olyan \u00fczenetet, amellyel a <code>turtle1</code> mozgathat\u00f3:</p> <pre><code>ros2 topic pub -r 1 /turtlesim1/turtle1/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.0, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: -1.8}}\"\n</code></pre> <p>A fent bemutatott direkt m\u00f3don k\u00edv\u00fcl egy launch f\u00e1jl futtathat\u00f3 csomag \u00e1ltal is:</p> <pre><code>ros2 launch &lt;csomag_megnevez\u00e9se&gt; &lt;launch_f\u00e1jl_neve&gt;\n</code></pre> <p>Olyan csomagok eset\u00e9ben, amelyek launch f\u00e1jlt tartalmaznak, \u00e9rdemes l\u00e9trehozni egy <code>exec_depend</code> f\u00fcgg\u0151s\u00e9get a <code>ros2launch</code> csomagra vonatkoz\u00f3an a csomag <code>package.xml</code> f\u00e1jlj\u00e1ban:</p> <pre><code>&lt;exec_depend&gt;ros2launch&lt;/exec_depend&gt;\n</code></pre> <p>Ezzel biztos\u00edthat\u00f3, hogy az <code>ros2 launch</code> parancs el\u00e9rhet\u0151 a csomag buildel\u00e9se ut\u00e1n.</p>"},{"location":"ros2halado/ros2launch/#tanulmanyozzuk-az-elinditott-rendszert","title":"Tanulm\u00e1nyozzuk az elind\u00edtott rendszert","text":"<p>\u00dagy, hogy minden eddig elind\u00edtott node fut, egy \u00fajabb termin\u00e1lban futtassuk az <code>rqt_graph</code> eszk\u00f6zt, amely grafikusan szeml\u00e9lteti a launch f\u00e1jl seg\u00edts\u00e9g\u00e9vel kialak\u00edtott rendszert:</p> <pre><code>rqt_graph\n</code></pre>"},{"location":"ros2halado/ros2launch/#adjuk-hozza-a-package-hez-hogy-barhonnan-indithassuk","title":"Adjuk hozz\u00e1 a package-hez, hogy b\u00e1rhonnan ind\u00edthassuk","text":"<pre><code>cd ~/ros2_ws/src/example_launch\n</code></pre> <pre><code>code .\n</code></pre> <p>A package.xml-hez a <code>&lt;test_depend&gt;</code> el\u00e9 sz\u00farjuk be k\u00f6vetkez\u0151 sort:</p> <pre><code>&lt;exec_depend&gt;ros2launch&lt;/exec_depend&gt;\n</code></pre> <p>A CMakeLists.txt-hez a <code>ament_package()</code> el\u00e9 sz\u00farjuk be k\u00f6vetkez\u0151 2 sort:</p> <pre><code>install(DIRECTORY launch\n  DESTINATION share/${PROJECT_NAME})\n</code></pre> <p>Buildelj\u00fck a szok\u00e1so m\u00f3don:</p> <pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select example_launch\n</code></pre> <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <p>Ez a parancs most m\u00e1r b\u00e1rhonnan kiadhat\u00f3:</p> <pre><code>ros2 launch example_launch turtlesim_mimc_launch.py\n</code></pre>"},{"location":"ros2halado/ros2launch/#forrasok","title":"Forr\u00e1sok","text":"<ul> <li>foxglove.dev/blog/how-to-use-ros2-launch-files</li> <li>youtube.com/watch?v=PqNGvmE2Pv4&amp;t </li> <li>docs.ros.org/en/humble/Tutorials/Intermediate/Launch/Creating-Launch-Files.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html</li> </ul>"},{"location":"ros2halado/rqt/","title":"<code>rqt</code> haszn\u00e1lata","text":""},{"location":"ros2halado/rqt/#rqt_console-a-log-uzenetek-megjelenitesre","title":"<code>rqt_console</code> a log \u00fczenetek megjelen\u00edt\u00e9sre","text":""},{"location":"ros2halado/rqt/#rqt_tf_tree-a-transzformaciok-vizualizaciojara","title":"<code>rqt_tf_tree</code> a transzform\u00e1ci\u00f3k vizualiz\u00e1ci\u00f3j\u00e1ra","text":""},{"location":"ros2halado/rqt/#rqt_graph-a-node-ok-es-topic-ok-vizualizaciojara","title":"<code>rqt_graph</code> a node-ok \u00e9s topic-ok vizualiz\u00e1ci\u00f3j\u00e1ra","text":""},{"location":"ros2halado/rqt/#forrasok","title":"Forr\u00e1sok","text":"<ul> <li>docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools/Using-Rqt-Console/Using-Rqt-Console.html</li> <li>docs.ros.org/en/humble/Tutorials/Intermediate/Launch/Creating-Launch-Files.html</li> <li>docs.ros.org/en/humble/Tutorials/Intermediate/Launch/Creating-Launch-Files.html</li> <li>docs.ros.org/en/humble/Tutorials/Intermediate/Tf2/Writing-A-Tf2-Broadcaster-Cpp.html</li> </ul>"},{"location":"ros2halado/state/","title":"Behavior tree","text":"<p>Forr\u00e1s: www.behaviortree.dev</p>"},{"location":"ros2halado/state/#allapotgepek-state-machine","title":"\u00c1llapotg\u00e9pek (State machine)","text":"<p>Forr\u00e1s: github.com/jbreckmckye/robot3-viz</p>"},{"location":"ros2halado/state/#forrasok","title":"Forr\u00e1sok","text":"<ul> <li>www.behaviortree.dev/docs/Intro</li> <li>en.wikipedia.org/wiki/Finite-state_machine</li> <li>github.com/jbreckmckye/robot3-viz</li> </ul>"},{"location":"ros2halado/vizualizacio/","title":"<code>ROS 2</code> vizualiz\u00e1ci\u00f3","text":""},{"location":"ros2halado/vizualizacio/#visualization_msgsmsgmarker-tipus","title":"<code>visualization_msgs/msg/Marker</code> t\u00edpus","text":"<p><code>visualization_msgs/msg/Marker</code> dokument\u00e1ci\u00f3</p>"},{"location":"ros2halado/vizualizacio/#visualization_msgsmsgmarkerarray-tipus","title":"<code>visualization_msgs/msg/MarkerArray</code> t\u00edpus","text":"<p><code>visualization_msgs/msg/MarkerArray</code> dokument\u00e1ci\u00f3</p>"},{"location":"ros2halado/vizualizacio/#mesh","title":"Mesh","text":"<pre><code>git clone https://github.com/szenergy/rviz_markers\ngit checkout ros2-humble\ncd ~/ros2_ws \ncolcon build --packages-select rviz_markers\nsource ~/ros2_ws/install/setup.bash\n</code></pre>"},{"location":"ros2halado/vizualizacio/#szinek","title":"Sz\u00ednek","text":"<p>A Google Material Design sz\u00ednrendszer egy \u00e1tfog\u00f3 tervez\u00e9si rendszer, amely pl. ROS-ban \u00e9s Rviz-ben is haszn\u00e1lhat\u00f3. A k\u00e9nyelem kedv\u00e9\u00e9rt a k\u00f6vetkez\u0151kben felsoroljuk a hexadecim\u00e1lis \u00e9rt\u00e9keket (pl. <code>#F44336</code>) \u00e9s az rgb-v\u00e9 alak\u00edtott \u00e9rt\u00e9keket (pl. <code>0,96 0,26 0,21</code>), ami a ROS 2-ben \u00e1ltal\u00e1nosan elfogadott.</p> <p>B\u0151vebben:  - github.com/jkk-research/colors</p> <code>100</code> <code>500</code> <code>900</code>  1.00 0.80 0.82 <code>md_red_100</code>  0.96 0.26 0.21 <code>md_red_500</code>  0.72 0.11 0.11 <code>md_red_900</code>  0.97 0.73 0.82 <code>md_pink_100</code>  0.91 0.12 0.39  <code>md_pink_500</code>  0.53 0.05 0.31 <code>md_pink_900</code>  0.82 0.77 0.91 <code>md_deep_purple_100</code>  0.40 0.23 0.72  <code>md_deep_purple_500</code>  0.19 0.11 0.57 <code>md_deep_purple_900</code>  0.73 0.87 0.98 <code>md_blue_100</code>  0.13 0.59 0.95  <code>md_blue_500</code>  0.05 0.28 0.63 <code>md_blue_900</code>  0.70 0.87 0.86 <code>md_teal_100</code>  0.00 0.59 0.53  <code>md_teal_500</code>  0.00 0.30 0.25 <code>md_teal_900</code>  0.78 0.90 0.79 <code>md_green_100</code>  0.30 0.69 0.31  <code>md_green_500</code>  0.11 0.37 0.13 <code>md_green_900</code>  0.94 0.96 0.76 <code>md_lime_100</code>  0.80 0.86 0.22  <code>md_lime_500</code>  0.51 0.47 0.09 <code>md_lime_900</code>  1.00 0.93 0.70 <code>md_amber_100</code>  1.00 0.76 0.03  <code>md_amber_500</code>  1.00 0.44 0.00 <code>md_amber_900</code>  1.00 0.88 0.70 <code>md_orange_100</code>  1.00 0.60 0.00  <code>md_orange_500</code>  0.90 0.32 0.00 <code>md_orange_900</code>  0.84 0.80 0.78 <code>md_brown_100</code>  0.47 0.33 0.28  <code>md_brown_500</code>  0.24 0.15 0.14 <code>md_brown_900</code>  0.96 0.96 0.96 <code>md_grey_100</code>  0.62 0.62 0.62  <code>md_grey_500</code>  0.13 0.13 0.13 <code>md_grey_900</code>"},{"location":"ros2halado/vizualizacio/#forrasok","title":"Forr\u00e1sok","text":"<ul> <li>docs.ros.org/en/humble/How-To-Guides/Visualizing-ROS-2-Data-With-Foxglove-Studio.html</li> <li>docs.ros.org/en/humble/Tutorials/Intermediate/Launch/Creating-Launch-Files.html</li> <li>docs.ros.org/en/humble/Tutorials/Intermediate/Tf2/Writing-A-Tf2-Broadcaster-Cpp.html</li> <li>github.com/jkk-research/colors</li> </ul>"},{"location":"safety/","title":"Theory - Safety V&amp;V","text":""},{"location":"safety/practice/","title":"Practice - Safety V&amp;V","text":""},{"location":"self_paced/","title":"\u00d6n\u00e1ll\u00f3 feladatok, otthoni gyakorl\u00e1s","text":""},{"location":"self_paced/linux/","title":"Linux Practice","text":""},{"location":"self_paced/linux/#creating-directory-structure-terminal","title":"Creating Directory Structure - Terminal","text":"<p>To complete this task, install the <code>tree</code> command: <pre><code>sudo apt install tree\n</code></pre></p> <p>You will need the <code>touch</code>, <code>chmod</code>, and <code>mkdir</code> commands to complete this task.</p> <p>Create the following directory structure, which should look like this when you run <code>cd ~ &amp;&amp; tree tmp_dir/</code>:</p> <pre><code>~/tmp_dir/\n\u251c\u2500\u2500 animals\n\u2502   \u251c\u2500\u2500 cat\n\u2502   \u2514\u2500\u2500 dog\n\u2502       \u251c\u2500\u2500 komondor\n\u2502       \u251c\u2500\u2500 puli\n\u2502       \u2514\u2500\u2500 vizsla\n\u251c\u2500\u2500 colors\n\u2502   \u251c\u2500\u2500 blue\n\u2502   \u251c\u2500\u2500 green\n\u2502   \u2514\u2500\u2500 red\n\u251c\u2500\u2500 py_exec.py\n\u251c\u2500\u2500 simple_text.txt\n\u2514\u2500\u2500 top\n    \u2514\u2500\u2500 middle\n        \u2514\u2500\u2500 bottom\n            \u2514\u2500\u2500 hello.txt\n13 directories, 3 files\n</code></pre> <p>The <code>ls -l  ~/tmp_dir/</code> command should show <code>rwx</code> values similar to the following:</p> <pre><code>drwxr-xr-x 4 he he 4096 Feb 17 14:54 animals\ndrwxr-xr-x 5 he he 4096 Feb 17 14:55 colors\n-rwxrwxrwx 1 he he    0 Feb 17 14:52 py_exec.py\n-rw-r--r-- 1 he he    0 Feb 17 14:53 simple_text.txt\ndrwxr-xr-x 3 he he 4096 Feb 17 14:43 top\n</code></pre>"},{"location":"self_paced/linux/#solution-guide","title":"Solution Guide","text":"<pre><code>mkdir -p top/middle/bottom\nmkdir -p colors/{red,green,blue}\nmkdir -p animals/{cat,dog/{vizsla,puli,komondor}}\n</code></pre>"},{"location":"self_paced/linux/#text-files","title":"Text Files","text":"<p>If not already created, create a <code>~/tmp_text/</code> directory.</p> <p>Inside the directory, create a <code>hello.py</code> file and populate it with the following content from the terminal:</p> <p><pre><code>import sys\nprint('\\nHello vilag!\\nA verzio pedig:\\n' + sys.version)\n</code></pre> Make it executable and run it.</p>"},{"location":"self_paced/linux/#solution-guide_1","title":"Solution Guide","text":"<pre><code>chmod +x hello.py\n./hello.py\n</code></pre>"},{"location":"self_paced/mermaid/","title":"Mermaid Practice","text":"<p>Mermaid can be a useful addition to our markdown files (e.g., <code>README.md</code>). It allows us to create various charts and flowcharts relatively easily.</p>"},{"location":"self_paced/mermaid/#vs-code-extension","title":"VS Code Extension","text":"<p>Click on the Extensions icon on the left or press <code>Ctrl</code> + <code>Shift</code> + <code>X</code> and type \"mermaid\" to find the Markdown Preview extension. Install it with one click, and you can use it. After that, you can see the preview in Markdown (<code>Ctrl</code> + <code>Shift</code> + <code>V</code> or the top icon).</p> Mermaid, VS Code extension Mermaid, VS Code <p>It is also recommended to use the Mermaid Markdown Syntax Highlighting and Color Highlight extensions. This way, the graph code will appear as follows:</p> Mermaid, VS Code highlight"},{"location":"self_paced/mermaid/#examples","title":"Examples","text":""},{"location":"self_paced/mermaid/#simple-example","title":"Simple Example","text":"<p>One of the simplest flowchart codes consists of the following 2 lines:</p> <pre><code>graph LR;\nnode1 --&gt; topic --&gt; node2\n</code></pre> <p>The first line defines the graph type, and the second (or subsequent) lines define the connections with arrows <code>--&gt;</code>.</p> <pre><code>graph LR;\nnode1 --&gt; topic --&gt; node2</code></pre>"},{"location":"self_paced/mermaid/#shapes-instead-of-rectangles","title":"Shapes Instead of Rectangles","text":"<p>The <code>LR</code> stands for left-right. Shapes can be rounded <code>([ ])</code>, square <code>[ ]</code>, hexagons <code>{ }</code>, parallelograms <code>[/ /]</code>, and more. In ROS, we learned that nodes are rounded, while topics are square. Identifiers like <code>id1</code>, <code>id2</code>, <code>id3</code> can be placed before the brackets. Connections can be defined either on separate lines (as here) or on a single line (later example).</p> <pre><code>graph LR;\nid1([node1])\nid2([node2])\nid3[topic]\n\nid1 --&gt; id3 --&gt; id2\n</code></pre> <pre><code>graph LR;\nid1([node1])\nid2([node2])\nid3[topic]\n\nid1 --&gt; id3 --&gt; id2</code></pre>"},{"location":"self_paced/mermaid/#top-down-instead-of-left-right","title":"Top-Down Instead of Left-Right","text":"<p>The <code>TD</code> stands for top-down:</p> <pre><code>graph TD;\nid1([node1])\nid2([node2])\nid3[topic]\n\nid1 --&gt; id3 --&gt; id2\n</code></pre> <pre><code>graph TD;\nid1([node1])\nid2([node2])\nid3[topic]\n\nid1 --&gt; id3 --&gt; id2</code></pre>"},{"location":"self_paced/mermaid/#using-colors","title":"Using Colors","text":"<p>With <code>classDef</code>, we can define colors, lines, and then assign them to the appropriate class with <code>:::</code> after three colons:</p> <pre><code>graph TD;\nid1([node1]):::red\nid2([node2]):::red\nid3[topic]:::light\n\nid1 --&gt; id3 --&gt; id2\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n</code></pre> <pre><code>graph TD;\nid1([node1]):::red\nid2([node2]):::red\nid3[topic]:::light\n\nid1 --&gt; id3 --&gt; id2\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre>"},{"location":"self_paced/mermaid/#more-nodes-and-topics","title":"More Nodes and Topics","text":"<p>An example with more nodes and topics:</p> <pre><code>graph LR;\n\ngen([ /gen_node]) --&gt; sine\ngen --&gt; rand[ /rand&lt;br/&gt;std_msgs/Float32]\nsine[ /sine&lt;br/&gt;std_msgs/Float32] --&gt; sum([ /sum_node])\nsum --&gt; out[ /out&lt;br/&gt;std_msgs/Float32]\nrand --&gt; sum\nin[ /in&lt;br/&gt;std_msgs/Float32] --&gt; sum\n</code></pre> <pre><code>graph LR;\n\ngen([ /gen_node]) --&gt; sine\ngen --&gt; rand[ /rand&lt;br/&gt;std_msgs/Float32]\nsine[ /sine&lt;br/&gt;std_msgs/Float32] --&gt; sum([ /sum_node])\nsum --&gt; out[ /out&lt;br/&gt;std_msgs/Float32]\nrand --&gt; sum\nin[ /in&lt;br/&gt;std_msgs/Float32] --&gt; sum</code></pre>"},{"location":"self_paced/mermaid/#the-previous-example-with-colors","title":"The Previous Example with Colors","text":"<pre><code>graph LR\n\ngen([ /gen_node]):::red --&gt; sine\ngen --&gt; rand[ /rand&lt;br/&gt;std_msgs/Float32]:::light \nsine[ /sine&lt;br/&gt;std_msgs/Float32]:::light --&gt; sum([ /sum_node]):::red\nsum --&gt; out[ /out&lt;br/&gt;std_msgs/Float32]:::light \nrand --&gt; sum\nin[ /in&lt;br/&gt;std_msgs/Float32]:::light --&gt; sum\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n</code></pre> <pre><code>graph LR\n\ngen([ /gen_node]):::red --&gt; sine\ngen --&gt; rand[ /rand&lt;br/&gt;std_msgs/Float32]:::light \nsine[ /sine&lt;br/&gt;std_msgs/Float32]:::light --&gt; sum([ /sum_node]):::red\nsum --&gt; out[ /out&lt;br/&gt;std_msgs/Float32]:::light \nrand --&gt; sum\nin[ /in&lt;br/&gt;std_msgs/Float32]:::light --&gt; sum\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre>"},{"location":"self_paced/mermaid/#alternative-version-using-class","title":"Alternative Version Using <code>class</code>","text":"<p>Instead of three colons <code>:::</code>, we can simply list the classes after the <code>class</code> keyword:</p> <pre><code>graph LR\n\ngen([ /gen_node]) --&gt; sine\ngen --&gt; rand[ /rand&lt;br/&gt;std_msgs/Float32] \nsine[ /sine&lt;br/&gt;std_msgs/Float32] --&gt; sum([ /sum_node])\nsum --&gt; out[ /out&lt;br/&gt;std_msgs/Float32]\nrand --&gt; sum\nin[ /in&lt;br/&gt;std_msgs/Float32] --&gt; sum\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n\nclass gen,sum red\nclass rand,sine,in,out light\n</code></pre> <pre><code>graph LR\n\ngen([ /gen_node]) --&gt; sine\ngen --&gt; rand[ /rand&lt;br/&gt;std_msgs/Float32] \nsine[ /sine&lt;br/&gt;std_msgs/Float32] --&gt; sum([ /sum_node])\nsum --&gt; out[ /out&lt;br/&gt;std_msgs/Float32]\nrand --&gt; sum\nin[ /in&lt;br/&gt;std_msgs/Float32] --&gt; sum\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n\nclass gen,sum red\nclass rand,sine,in,out light</code></pre> <pre><code>flowchart LR\n\nA[/ max_deg&lt;/br&gt;param /]:::gray --&gt; D([display_tree&lt;/br&gt;node]):::gray\nB[/ max_dist&lt;/br&gt;param /]:::gray --&gt; D\nC[/ seed_size&lt;/br&gt;param /]:::gray --&gt; D\nD --&gt; |visualization_msgs/marker_array| P[ /path_marker_topic&lt;/br&gt;topic]:::gray\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef gray fill:#f6f8fa,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n</code></pre>"},{"location":"self_paced/mermaid/#parameters","title":"Parameters","text":"<p>It is often useful to visualize defined parameters. Currently, there is no standard notation for this, but hexagons <code>{ }</code> or parallelograms <code>[/ /]</code> can be options.</p> <pre><code>flowchart LR\n\nA[/ max_deg&lt;/br&gt;param /]:::gray --&gt; D([display_tree&lt;/br&gt;node]):::gray\nB[/ max_dist&lt;/br&gt;param /]:::gray --&gt; D\nC[/ seed_size&lt;/br&gt;param /]:::gray --&gt; D\nD --&gt; |visualization_msgs/marker_array| P[ /path_marker_topic&lt;/br&gt;topic]:::gray\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef gray fill:#f6f8fa,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\nclassDef green fill:#138b7b,stroke:#152742,stroke-width:2px,color:#fff</code></pre>"},{"location":"self_paced/mermaid/#system-design","title":"System Design","text":"<pre><code>flowchart TD\n    S[State Machine &lt;br&gt;/plan_state_machine] -.-&gt;|/plan_state*| LS[LIDAR segmentation&lt;br&gt;/prcp_ground_obstacle_segm_lidar]\n    S -.-&gt; CS[Cone detection camera&lt;br&gt; and de-projection]\n    S -.-&gt; O[Object fusion]\n    CS --&gt;|/prcp_obj_list_camera| O\n    LS --&gt;|/prcp_obj_list_lidar| O\n    O --&gt;|/prcp_obj_list_fused| T[Trajectory planner&lt;br&gt;/plan_trajectory_planner]\n    T --&gt; C[Control&lt;br&gt;/ctrl_vehicle_control]\n    S -.-&gt; T\n    S -.-&gt; C\n    O --&gt; M[Map Creation&lt;br&gt;/prc_slam]\n    M --&gt;|/prcp_map| T\n    L[Localization&lt;br&gt;/prcp_odometry_kf_prediction] --&gt; T\n    C --&gt; CAN[To CAN]\n\n    classDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \n    classDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\n    classDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#15274\n    classDef dash fill:#ffffff,stroke:#152742,stroke-width:2px,color:#15274, stroke-dasharray: 5 5\n    classDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n    classDef green fill:#138b7b,stroke:#152742,stroke-width:2px,color:#fff\n    class CS,LS,L,T,M,C white\n    class O light\n    class S dash\n    class CAN red\n</code></pre> <pre><code>flowchart TD\n    S[State Machine &lt;br&gt;/plan_state_machine] -.-&gt;|/plan_state*| LS[LIDAR segmentation&lt;br&gt;/prcp_ground_obstacle_segm_lidar]\n    S -.-&gt; CS[Cone detection camera&lt;br&gt; and de-projection]\n    S -.-&gt; O[Object fusion]\n    CS --&gt;|/prcp_obj_list_camera| O\n    LS --&gt;|/prcp_obj_list_lidar| O\n    O --&gt;|/prcp_obj_list_fused| T[Trajectory planner&lt;br&gt;/plan_trajectory_planner]\n    T --&gt; C[Control&lt;br&gt;/ctrl_vehicle_control]\n    S -.-&gt; T\n    S -.-&gt; C\n    O --&gt; M[Map Creation&lt;br&gt;/prc_slam]\n    M --&gt;|/prcp_map| T\n    L[Localization&lt;br&gt;/prcp_odometry_kf_prediction] --&gt; T\n    C --&gt; CAN[To CAN]\n    classDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \n    classDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\n    classDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#15274\n    classDef dash fill:#ffffff,stroke:#152742,stroke-width:2px,color:#15274, stroke-dasharray: 5 5\n    classDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff\n    classDef green fill:#138b7b,stroke:#152742,stroke-width:2px,color:#fff\n    class CS,LS,L,T,M,C white\n    class O light\n    class S dash\n    class CAN red</code></pre>"},{"location":"self_paced/mermaid/#pie-chart","title":"Pie Chart","text":"<p>Based on metrics.ros.org/rosdistro_rosdistro.html, a pie chart:</p> <pre><code>pie title ROS distros used\n    \"Melodic (ROS 1)\" : 0.0010\n    \"Noetic (ROS 1)\" : 0.0951\n    \"Humble\" : 0.3333\n    \"Iron\" : 0.1905\n    \"Rolling\" : 0.1904\n</code></pre> <pre><code>pie title ROS distros used\n    \"Melodic (ROS 1)\" : 0.001\n    \"Noetic (ROS 1)\" : 0.095\n    \"Humble\" : 0.33\n    \"Iron\" : 0.19\n    \"Rolling\" : 0.19</code></pre>"},{"location":"self_paced/mermaid/#links","title":"Links","text":"<ul> <li>Mermaid flowchart</li> <li>Mermaid pie chart</li> <li>Mermaid intro</li> </ul>"},{"location":"self_paced/ros1lidarsimple/","title":"ROS szenzoradatok feldolgoz\u00e1sa C++ node-al","text":"<p>Vigy\u00e1zat: ROS 1-es feladat.</p> <p> </p>"},{"location":"self_paced/ros1lidarsimple/#a-feladat-leirasa","title":"A feladat le\u00edr\u00e1sa","text":"<p>Els\u0151 feladatunk, hogy 3D LIDAR szenzoradatokat tartalmaz\u00f3 rosbag-et j\u00e1tszunk vissza \u00e9s az adatokon egyszer\u0171 akad\u00e1lyfelismer\u00e9st val\u00f3s\u00edtsunk meg, majd ezt vizualiz\u00e1ljuk. Az akdad\u00e1lyfelismer\u00e9s naiv, de sokszor m\u0171k\u00f6d\u0151k\u00e9pes m\u00f3dja, hogy a j\u00e1rm\u0171 el\u0151tt egy virtu\u00e1lis t\u00e9glatestben vizsg\u00e1ljuk, hogy van-e objektumot reprezent\u00e1l\u00f3 voxel (3d pixel) / 3d pont. Ezt vizualiz\u00e1ljuk \u00fagy, hogy a kijel\u00f6lt t\u00e9glatesbe es\u0151 voxeleket k\u00fcl\u00f6n point cloud-k\u00e9nt hirdess\u00fck, illetve a t\u00e9glatestet is jel\u00f6lj\u00fck z\u00f6ld illetve piros sz\u00ednnel. Err\u0151l illusztr\u00e1ci\u00f3:</p> <p> </p>"},{"location":"self_paced/ros1lidarsimple/#elokeszuletek","title":"El\u0151k\u00e9sz\u00fcletek","text":"<p>Melodic</p> <p>Noetic</p> <p>Az el\u0151z\u0151 gyakorlatok ut\u00e1n tov\u00e1bbhaladva, azok eredm\u00e9nyeit felhaszn\u00e1lva l\u00e9p\u00fcnk tov\u00e1bb. T\u00f6lts\u00fck le a t\u00f6bb szenzoradatot is tartalmaz\u00f3 rosbag f\u00e1jlt.</p> <pre><code>cd ~/rosbag-gyak\nwget www.sze.hu/~herno/PublicDataAutonomous/leaf-2019-09-12-15-10-46-gps-lidar-zala.bag\nwget https://raw.githubusercontent.com/horverno/ros-gyakorlatok/master/3-ros-node-szenzoradatok/leaf-v1.rviz\n</code></pre> <p>Jelen\u00edts\u00fck meg az inform\u00e1ci\u00f3kat. </p> <pre><code>rosbag info leaf-2019-09-12-15-10-46-gps-lidar-zala.bag\n</code></pre> <p>Legink\u00e1bb 2 topic lesz sz\u00e1munkra fontos:</p> <pre><code>/points_raw      182 msgs    : sensor_msgs/PointCloud2\n/scan            482 msgs    : sensor_msgs/LaserScan\n</code></pre> <pre><code>$ rosmsg info sensor_msgs/PointCloud2\nstd_msgs/Header header\n  uint32 seq\n  time stamp\n  string frame_id\nuint32 height\nuint32 width\nsensor_msgs/PointField[] fields\n  uint8 INT8=1\n  uint8 UINT8=2\n  uint8 INT16=3\n  uint8 UINT16=4\n  uint8 INT32=5\n  uint8 UINT32=6\n  uint8 FLOAT32=7\n  uint8 FLOAT64=8\n  string name\n  uint32 offset\n  uint8 datatype\n  uint32 count\nbool is_bigendian\nuint32 point_step\nuint32 row_step\nuint8[] data\nbool is_dense\n</code></pre> <pre><code>$ rosmsg info sensor_msgs/LaserScan \nstd_msgs/Header header\n  uint32 seq\n  time stamp\n  string frame_id\nfloat32 angle_min\nfloat32 angle_max\nfloat32 angle_increment\nfloat32 time_increment\nfloat32 scan_time\nfloat32 range_min\nfloat32 range_max\nfloat32[] ranges\nfloat32[] intensities\n</code></pre>"},{"location":"self_paced/ros1lidarsimple/#rviz","title":"rviz","text":"<p>Jelen\u00edts\u00fck meg rviz seg\u00edts\u00e9g\u00e9vel az adatokat, <code>roscore</code> ind\u00edt\u00e1sa \u00e9s <code>rosbag</code> visszaj\u00e1tsz\u00e1s ut\u00e1n ut\u00e1n: <pre><code>rosbag play -l leaf-2019-09-12-15-10-46-gps-lidar-zala.bag\n</code></pre> Megjelen\u00edt\u00e9s <code>rviz</code>-zel:</p> <pre><code>rosrun rviz rviz -d ~/rosbag-gyak/leaf-v1.rviz\n</code></pre> <p></p>"},{"location":"self_paced/ros1lidarsimple/#package-es-node-keszitese-egyszeru-lidar-szuresre-vizualizaciora","title":"Package \u00e9s node k\u00e9sz\u00edt\u00e9se egyszer\u0171 LIDAR sz\u0171r\u00e9sre, vizualiz\u00e1ci\u00f3ra","text":"<p>K\u00e9sz\u00edts\u00fck el a gyakorl\u00f3 workspace-t:</p> <p><pre><code>cd ~ ; mkdir -p gyak_ws/src ; cd gyak_ws/src\n</code></pre> Majd ebben a packaget:</p> <pre><code>catkin create pkg lidar_tutorial --catkin-deps roscpp pcl_conversions pcl_ros sensor_msgs visualization_msgs\n</code></pre> <p>Ind\u00edtsuk a VS code-t (<code>code .</code> parancs)</p> <p>Ments\u00fck le a 3 cpp f\u00e1jlt: <pre><code>cd ~/gyak_ws/src/lidar_tutorial/src ; wget https://raw.githubusercontent.com/horverno/ros-gyakorlatok/master/3-ros-node-szenzoradatok/lidar_and_marker.cpp ; wget https://raw.githubusercontent.com/horverno/ros-gyakorlatok/master/3-ros-node-szenzoradatok/lidar_filter.cpp ; wget https://raw.githubusercontent.com/horverno/ros-gyakorlatok/master/3-ros-node-szenzoradatok/pub_marker.cpp\n</code></pre></p> <p>A VS code automatikus kieg\u00e9sz\u00edt\u00e9s funkci\u00f3ja akkor m\u0171k\u00f6dik j\u00f3l, a hi\u00e1nyz\u00f3nak jel\u00f6lt incuden\u00e1l, (pl. <code>ros/ros.h</code>), kattintsunk a s\u00e1rga villanyk\u00f6rte ikonra, majd <code>Edit \"includepath\" settings</code> r\u00e9szre megy\u00fcnk \u00e9s az <code>Include path</code> mez\u0151be a k\u00f6vetkez\u0151ket \u00edrjuk:</p> <p><pre><code>${workspaceFolder}/**\n/opt/ros/melodic/include\n/opt/ros/melodic/include/pcl\n/usr/include\n/usr/include/pcl-1.7\n/usr/include/eigen3\n</code></pre> Megjegyz\u00e9s a k\u00e9s\u0151bbiekben (AutoWare haszn\u00e1latakor) hasznos lehet m\u00e9g a k\u00f6vetkez\u0151 is: <pre><code>~/autoware_ws/Autoware/ros/devel/include\n</code></pre></p> <p>A <code>CMakeLists.txt</code> v\u00e9g\u00e9re a k\u00f6vetkez\u0151ket \u00edrjuk:</p> <p><pre><code>add_executable(publish_marker src/pub_marker.cpp)\ntarget_link_libraries(publish_marker ${catkin_LIBRARIES})\n\nadd_executable(basic_lidar_filter src/lidar_filter.cpp)\ntarget_link_libraries(basic_lidar_filter ${catkin_LIBRARIES})\n\nadd_executable(lidar_and_marker src/lidar_and_marker.cpp)\ntarget_link_libraries(lidar_and_marker ${catkin_LIBRARIES})\n</code></pre> L\u00e9pj\u00fcnk vissza a workspace-be (<code>cd ~/gyak_ws</code>), majd buildelj\u00fcnk:</p> <pre><code>catkin build\n</code></pre> <p>Szerkessz\u00fck a <code>~/.bashrc</code>-t (<code>code ~/.bashrc</code>)</p> <pre><code>source ~/gyak_ws/devel/setup.bash\n</code></pre> <p>Az egyszer\u0171 filter (<code>lidar_filter.cpp</code>) tartalma a k\u00f6vetkez\u0151:</p> <pre><code>#include &lt;ros/ros.h&gt;\n#include &lt;pcl_conversions/pcl_conversions.h&gt;\n#include &lt;pcl/point_cloud.h&gt;\n#include &lt;pcl/point_types.h&gt;\n#include &lt;pcl/filters/voxel_grid.h&gt;\n#include &lt;pcl/filters/crop_box.h&gt;\n\nros::Publisher pub;\nros::Publisher marker_pub;\n\nvoid cloud_cb(const pcl::PCLPointCloud2ConstPtr &amp;cloud)\n{\n    pcl::PCLPointCloud2 cloud_filtered;\n\n    // Define min and max for X, Y and Z\n    float minX = 0.0, minY = -1.0, minZ = -1.384;\n    float maxX = 16.0, maxY = +1.0, maxZ = -0.15;\n\n    pcl::CropBox&lt;pcl::PCLPointCloud2&gt; boxFilter;\n    boxFilter.setMin(Eigen::Vector4f(minX, minY, minZ, 1.0));\n    boxFilter.setMax(Eigen::Vector4f(maxX, maxY, maxZ, 1.0));\n    boxFilter.setInputCloud(cloud);\n    boxFilter.filter(cloud_filtered);\n    if(cloud_filtered.data.size() &gt; 10) \n        ROS_WARN_STREAM(\"Object in the selected area\");\n\n    // Publish the filtered LIDAR data\n    pub.publish(cloud_filtered);\n\n}\n\nint main(int argc, char **argv)\n{\n    // Initialize ROS\n    ros::init(argc, argv, \"lidar_filt\");\n    ros::NodeHandle nh;\n    // Create a ROS subscriber for the input point cloud\n    ros::Subscriber sub = nh.subscribe(\"points_raw\", 1, cloud_cb);\n\n    // Create a ROS publisher for the output point cloud\n    pub = nh.advertise&lt;pcl::PCLPointCloud2&gt;(\"points_filt\", 1);\n\n    // Spin\n    ros::spin();\n}\n</code></pre> <p>Magyar\u00e1zat: A <code>main</code>-ben feliratkozunk a <code>points_raw</code> topicra, ami a nyers LIDAR adatokat tartalmazza, valamint elkezdj\u00fck hirdetni a <code>points_filt</code> topicot, ebbe ker\u00fclnek majd a megsz\u0171rt adatok. A <code>cloud_cb</code> f\u00fcggv\u00e9ny v\u00e9gzi a sz\u0171r\u00e9st \u00e9s a <code>ROS_WARN_STREAM</code> seg\u00edts\u00e9g\u00e9vel jelez, amennyiben objektum van a kijel\u00f6lt ter\u00fcleten. A <code>cloud_filtered.data.size() &gt; 10</code> azt jelenti, hogy a sz\u0171rt pontfelh\u0151 elemsz\u00e1ma nagyobb-e mint 10 voxel (3d pont).</p>"},{"location":"self_paced/ros1lidarsimple/#a-node-ok-futtatasa","title":"A node-ok futtat\u00e1sa","text":"<p>A egyszer\u0171 LIDAR filter node \u00edgy ind\u00edthat\u00f3: <pre><code>rosrun lidar_tutorial basic_lidar_filter\n</code></pre></p> <p>A marker publik\u00e1l\u00f3 node pedig \u00edgy: <pre><code>rosrun lidar_tutorial publish_marker \n</code></pre></p> <p>A filtert \u00e9s a markert kombin\u00e1l\u00f3 node: <pre><code>rosrun lidar_tutorial lidar_and_marker \n</code></pre></p>"},{"location":"self_paced/ros1node/","title":"ROS node-ok k\u00e9sz\u00edt\u00e9se pythonban \u00e9s C++-ban","text":""},{"location":"self_paced/ros1node/#elokeszuletek","title":"El\u0151k\u00e9sz\u00fcletek","text":"<p>Az el\u0151z\u0151 alkalommal let\u00f6lt\u00f6tt rosbag f\u00e1jl most is kelleni fog.</p> <pre><code>mkdir ~/rosbag-gyak\ncd ~/rosbag-gyak\nwget www.sze.hu/~herno/PublicDataAutonomous/leaf-2019-03-13-a-no-lidar.bag\n</code></pre> <p>Vigy\u00e1zat: ROS 1-es feladat.</p> <p> </p>"},{"location":"self_paced/ros1node/#catkin-workspace-keszitese","title":"Catkin workspace k\u00e9sz\u00edt\u00e9se","text":"<p>Nyissuk meg, a home folderban l\u00e9v\u0151 <code>.bashrc</code> f\u00e1jlt (pl VS code seg\u00edts\u00e9g\u00e9vel) \u00e9s ellen\u0151rizz\u00fck, hogy tartalmaz-e egy <code>source /opt/ros/melodic/setup.bash</code> sort valahol a f\u00e1jl v\u00e9g\u00e9n.</p> <pre><code>code ~/.bashrc\n</code></pre> <p>Opcion\u00e1lis: Elk\u00e9pzelhet\u0151, hogy a <code>catkin build</code> nincs telep\u00edtve a g\u00e9p\u00fcnk\u00f6n, csak a r\u00e9gi <code>catkin_make</code>. Ekkor telep\u00edts\u00fck a k\u00f6vetkez\u0151 paranccsal. <pre><code>sudo apt-get install python-catkin-tools\n</code></pre> Fontos megjegyz\u00e9s: Lehet\u0151leg NE haszn\u00e1ljuk a r\u00e9gi <code>_make</code>, hanem az \u00faj <code>catkin build</code> parancsot (catkin tools). A kett\u0151 nagyj\u00e1b\u00f3l ugyanazt tudja, de nem lehet mixelni \u0151ket egy workspace-n bel\u00fcl. Ha m\u00e9gis ilyesmi t\u00f6rt\u00e9nt volna, build el\u0151tt tiszt\u00edtsuk meg <code>catkin clean</code> seg\u00edts\u00e9g\u00e9vel. err\u0151l b\u0151vebben: p\u00e9ld\u00e1ul a catkin-tools.readthedocs.io \u00e9s a  catkin-tools.readthedocs.io/en/latest/migration.html oldalakon olvashattok. A <code>catkin build</code> tov\u00e1bbi el\u0151nyei: - V\u00e1ltoz\u00e1sok eset\u00e9n robosztusabb konfigur\u00e1ci\u00f3 (pl. csomag hozz\u00e1ad\u00e1sa/elt\u00e1vol\u00edt\u00e1sa, cmake v\u00e1ltoz\u00f3 m\u00f3dos\u00edt\u00e1sa stb. eset\u00e9n) - K\u00f6nnyebben olvashat\u00f3 kimenet - P\u00e1rhuzamos ford\u00edt\u00e1s, amennyiben a package-k nem f\u00fcggnek egym\u00e1st\u00f3l - Izol\u00e1lt build a <code>catkin build package_neve</code> seg\u00edts\u00e9g\u00e9vel - <code>catkin clean</code> a vesz\u00e9lyes <code>rm -rf</code> t\u00f6rl\u00e9s helyett - Hasznos parancsok, mint: <code>catkin list</code>, <code>catkin locate</code>, <code>catkin profile</code></p> <p>Hozzunk l\u00e9tre egy gyakolr\u00f3 catkin workspace-t:</p> <pre><code>mkdir -p ~/gyakorlo_ws/src\ncd ~/gyakorlo_ws/\ncatkin init\n</code></pre> <p>Ha <code>ls</code> paranccsal list\u00e1zzuk a k\u00f6nyvt\u00e1r tartalm\u00e1t, a tipikus workspace fel\u00e9p\u00edt\u00e9st l\u00e1thatjuk. (El\u0151sz\u00f6r csak az <code>src</code>-t, de build ut\u00e1n a t\u00f6bbi is meg fog jelenni.)</p> <p><pre><code>build  devel  logs  src\n</code></pre> Egy workspace t\u00f6bb pacake-t tartalmaz. Most k\u00e9sz\u00edts\u00fck el a <code>gyakorlo_pkg</code> nev\u0171 pacake-t, ami majd t\u00f6bb node-ot tartalmaz, majd nyissuk meg VS code seg\u00edts\u00e9g\u00e9vel az <code>src</code> mapp\u00e1t.</p> <p><pre><code>cd ~/gyakorlo_ws/src\ncatkin create pkg gyakorlo_pkg --catkin-deps nav_msgs std_msgs rospy roscpp\ncode .\n</code></pre> Eddig \u00edgy n\u00e9z ki a workspace.</p> <p></p> <p>Megjegyz\u00e9s, hogy a fenti k\u00e9phez hasonl\u00f3t kapjunk <code>ctr</code> + <code>k</code>, majd <code>ctr</code> + <code>t</code> seg\u00edts\u00e9g\u00e9vel v\u00e1lthatunk egy vil\u00e1gosabb t\u00e9m\u00e1ra illetve az Extension gommb seg\u00edts\u00e9g\u00e9vel (<code>ctr</code> + <code>shift</code> + <code>x</code>) telep\u00edthet\u00fcnk hasznos kieg\u00e9sz\u00edt\u0151ket, mint p\u00e9ld\u00e1ul:</p> <ul> <li>C/C++ (ms-vscode.cpptools) </li> <li>Python (ms-python.python) </li> <li>Cmake (twxs.cmake) </li> <li>Material Icon Theme (pkief.material-icon-theme) </li> </ul>"},{"location":"self_paced/ros1node/#c-fajlok-beszerzese","title":"C++ f\u00e1jlok beszerz\u00e9se","text":"<p>A <code>gyakorlo_ws/src/gyakorlo_pkg/src</code> mapp\u00e1ba t\u00f6lts\u00fcnk le k\u00e9t cpp f\u00e1jlt.</p> <pre><code>cd ~/gyakorlo_ws/src/gyakorlo_pkg/src\nwget https://raw.githubusercontent.com/horverno/ros-gyakorlatok/master/2-ros-node-tobb-nyelven/kiir.cpp\nwget https://raw.githubusercontent.com/horverno/ros-gyakorlatok/master/2-ros-node-tobb-nyelven/szamol.cpp\n</code></pre> <p></p> <p>Felt\u00e9telezve a C/C++  kieg\u00e9sz\u00edt\u0151t, annak \u00e9rdek\u00e9ben, hogy a VS code automatikus kieg\u00e9sz\u00edt\u00e9s funkci\u00f3ja j\u00f3l m\u0171k\u00f6dj\u00f6n, a hi\u00e1nyz\u00f3nak jel\u00f6lt incuden\u00e1l, (<code>ros/ros.h</code>), kattintsunk a s\u00e1rga villanyk\u00f6rte ikonra, majd <code>Edit \"includepath\" settings</code> \u00e9s eg\u00e9sz\u00edts\u00fck ki egy veszz\u0151vel, plusz a <code>\"/opt/ros/melodic/include\"</code> (ill. r\u00e9gebben <code>\"/opt/ros/melodic/include\"</code>) sorral. Megjegyz\u00e9s: az \u00faj fel\u00fcleten lehet, hogy grafikusan kell megadni az <code>Include path</code> mez\u0151ben. Ezut\u00e1n m\u00e1r megtal\u00e1lja az ROS-specifikus dolgokat. (Ekkor gyakolatilag a <code>.vscode</code> k\u00f6nyvt\u00e1rban tal\u00e1lhat\u00f3 <code>c_cpp_properties.json</code>-t szerkesztj\u00fck \u00e1t.)</p> <p></p> <pre><code>{\n    \"configurations\": [\n        {\n            \"name\": \"Linux\",\n            \"includePath\": [\n                \"${workspaceFolder}/**\",\n                \"/opt/ros/melodic/include\"\n            ],\n            \"defines\": [],\n            \"compilerPath\": \"/usr/bin/gcc\",\n            \"cStandard\": \"c11\",\n            \"cppStandard\": \"c++11\",\n            \"intelliSenseMode\": \"clang-x64\"\n        }\n    ],\n    \"version\": 4\n}\n</code></pre> <p>K\u00e9t node-ot szeretn\u00e9nk a k\u00e9t cpp f\u00e1jlb\u00f3l l\u00e9trehozni.  A <code>csak_kiiras_node</code> csak ki\u00edrn\u00e1 a beolvasott gps \u00e9s leaf biciklo modell \u00e1ltal sz\u00e1molt odometri\u00e1t. A <code>tavolsag_szamitas_node</code> publisholn\u00e1 a k\u00e9t odometria k\u00fcl\u00f6nbs\u00e9g\u00e9t (t\u00e1vols\u00e1g\u00e1t). M\u00f3dos\u00edtsuk a <code>CMakeLists.txt</code>-t \u00edgy.</p> <pre><code>cmake_minimum_required(VERSION 2.8.3)\nproject(gyakorlo_pkg)\n\nadd_compile_options(-std=c++11)\n\nfind_package(catkin REQUIRED COMPONENTS\n  nav_msgs\n  roscpp\n  rospy\n  std_msgs\n)\n\ncatkin_package(\n#  INCLUDE_DIRS include\n#  LIBRARIES gyakorlo_pkg\n#  CATKIN_DEPENDS nav_msgs roscpp rospy std_msgs\n#  DEPENDS system_lib\n)\n\ninclude_directories(\n# include\n  ${catkin_INCLUDE_DIRS}\n)\n\n\nadd_executable(tavolsag_szamitas_node src/szamol.cpp)\ntarget_link_libraries(tavolsag_szamitas_node ${catkin_LIBRARIES})\n\nadd_executable(csak_kiiras_node src/kiir.cpp)\ntarget_link_libraries(csak_kiiras_node ${catkin_LIBRARIES})\n</code></pre> <p>Nyissuk meg a <code>.bashrc</code> f\u00e1jlt (<code>code ~/.bashrc</code>) \u00e9s adjuk hozz\u00e1 a <code>source ~/gyakorlo_ws/devel/setup.bash</code> sort. Innent\u0151l kezdve b\u00e1rhonnan el\u00e9rhetj\u00fck a workspace-t, \u00e9s b\u00e1rhonnan elind\u00edthatjuk a a package k\u00fcl\u00f6nb\u00f6z\u0151 node-jait <code>rosrun</code> seg\u00edts\u00e9g\u00e9vel.  Buildelj\u00fck a <code>catkin build</code> seg\u00edts\u00e9g\u00e9vel, most \u00faj terminalban vagy <code>source ~/.bashrc</code> ut\u00e1n el\u00e9rhet\u0151k lesznek a node-ok. </p> <pre><code>cd /\nroscd gyakorlo_pkg\ncatkin build\n</code></pre> <p>Most m\u00e1r b\u00e1rhonnan ind\u00edthat\u00f3 a 2 node.</p> <pre><code>rosrun gyakorlo_pkg csak_kiiras_node\nrosrun gyakorlo_pkg tavolsag_szamitas_node\n</code></pre> <p>Vizsg\u00e1ljuk meg a c++ f\u00e1jlok m\u0171k\u00f6d\u00e9s\u00e9t \u00e9s a node-ok v\u00e9grahajt\u00e1s\u00e1t!</p>"},{"location":"self_paced/ros1node/#ros-node-pythonban","title":"ROS node pythonban","text":"<p>Pythonban nem kell k\u00fcl\u00f6n a CMakeListset <code>add_executable(..)</code> sorral kieg\u00e9sz\u00edten\u00fcnk. Minden .py f\u00e1jl, aminek van futtat\u00e1si joga (<code>chmod</code>) \u00e9s a scripts mapp\u00e1ban tal\u00e1lhat\u00f3, automatikusan node lesz.</p> <p>A scripts mapp\u00e1ba tegy\u00fck bele, az el\u0151z\u0151 alkalommal megismert plotter f\u00e1jlt, \u00e9s adjunk futtathat\u00f3 jogot.</p> <pre><code>wget https://raw.githubusercontent.com/horverno/ros-gyakorlatok/master/1-rosbag-es-topicok/plotterLeaf.py\nsudo chmod +x plotterLeaf.py\n</code></pre> <p>A C++-hoz hasonl\u00f3an, most m\u00e1r b\u00e1rhonnan ind\u00edthat\u00f3 a node.</p> <pre><code>rosrun gyakorlo_pkg plotterLeaf.py\n</code></pre>"},{"location":"self_paced/ros1node/#onallo-feladat","title":"\u00d6n\u00e1ll\u00f3 feladat","text":"<p>Jelezz\u00fck ki a <code>/distance</code> topicot k\u00e9t tizedesjegyig, sz\u00e1mk\u00e9nt a <code>plotterLeaf.py</code> node-ban.</p>"},{"location":"self_paced/ros1node/#segitseg-az-onallo-feladathoz","title":"Seg\u00edts\u00e9g az \u00f6n\u00e1ll\u00f3 feladathoz.","text":"<p>Ha nem tudjuk a t\u00edpust, akkor n\u00e9zz\u00fck meg <code>rostopic type</code> illetve, ha \u00f6sszetett lett volna a t\u00edpus akkor <code>rosmsg show</code>, de ez most nem kell.</p> <pre><code>import std_msgs.msg as rosmsg # m\u00e1r import\u00e1lva\nrospy.Subscriber(\"/disctance\", rosmsg.t\u00edpus, self.saj\u00e1tCallback) # feliratkoz\u00e1s\n\ndef saj\u00e1tCallback(self, msg):\n    # itt adhatunk \u00e1t egy oszt\u00e1lyv\u00e1ltoz\u00f3t\n\nclass PlotHandler &gt;&gt; saj\u00e1t QLabel\n                  &gt;&gt; friss\u00edt\u00e9se setText-el\n</code></pre>"},{"location":"self_paced/ros1node/#forras","title":"Forr\u00e1s","text":"<p>ROS-gyakorlatok GitHub Pages kezd\u0151oldal:  horverno.github.io/ros-gyakorlatok</p>"},{"location":"self_paced/ros1rosbag/","title":"Rosbag gyakorl\u00e1s","text":""},{"location":"self_paced/ros1rosbag/#video","title":"Vide\u00f3","text":"<p>A gyakorlat a jobb \u00e9rthet\u0151s\u00e9g \u00e9s az otthoni feldolgoz\u00e1s miatt ak\u00e1r vide\u00f3k\u00e9nt is megtekinthet\u0151. A vide\u00f3 sz\u00f6veges magyar\u00e1zat n\u00e9lk\u00fcli, r\u00f6vid\u00edtett, cser\u00e9be mutatja a parancsok kiad\u00e1s\u00e1t\u00f3l elv\u00e1rhat\u00f3 m\u0171k\u00f6d\u00e9st: youtu.be/Hu7YseOh3qk</p>"},{"location":"self_paced/ros1rosbag/#elokeszuletek","title":"El\u0151k\u00e9sz\u00fcletek","text":"<p>A k\u00f6vetkez\u0151 p\u00e9ld\u00e1k egy Turtlebot3 robot \u00e9s egy Nissan Leaf \u00f6nvezet\u0151 aut\u00f3 <code>.bag</code> f\u00e1jlait haszn\u00e1lj\u00e1k majd. A <code>.bag</code> az ROS log f\u00e1jt\u00edpusa, m\u00e9r\u00e9seket ment\u00e9s\u00e9re, visszaj\u00e1tsz\u00e1s\u00e1ra, szerkezt\u00e9s\u00e9re stb. szolg\u00e1l.</p> <p>Vigy\u00e1zat: ROS 1-es feladat.</p> <p></p> <p></p> <p>Nyissunk egy termin\u00e1lt (<code>ctr</code>+<code>alt</code>+<code>t</code>), hozzunk l\u00e9tre egy <code>rosbag-gyak</code> mapp\u00e1t, majd l\u00e9pj\u00fcnk bele.</p> <pre><code>mkdir ~/rosbag-gyak\ncd ~/rosbag-gyak\n</code></pre> <p>T\u00f6lts\u00fck le a 2 rosbag f\u00e1jlt.</p> <pre><code>wget www.sze.hu/~herno/PublicDataAutonomous/turtlebot-2019-03-11-SLAM-no-camera.bag\nwget www.sze.hu/~herno/PublicDataAutonomous/leaf-2019-03-13-a-no-lidar.bag\n</code></pre> <p>Vizsg\u00e1ljuk meg, hogy t\u00e9nyleg ~46MB m\u00e9ret\u0171-e Turtlebot \u00e9s ~9MB m\u00e9ret\u0171-e a Leaf <code>.bag</code> f\u00e1jl.</p> <pre><code>ls --size \nls --size --block-size=M\nls -l --block-size=M\n</code></pre> <p>N\u00e9zz\u00fck meg a k\u00f6vetkez\u0151 vide\u00f3t, ez a Turtlebot <code>.bag</code> f\u00e1jl r\u00f6gz\u00edt\u00e9sekor k\u00e9sz\u00fclt: youtu.be/QwagQFvhbNU </p> <p>Megjegyz\u00e9s: jkk-research.github.io/ illetve a www.sze.hu/~herno/PublicDataAutonomous linken tov\u00e1bbi <code>.bag</code> f\u00e1jlok tal\u00e1lhat\u00f3ak.</p> <p>A terminalban ind\u00edtsunk egy <code>roscore</code>-t. K\u00e9s\u0151bb le\u00e1\u00e1\u00edthat\u00f3 <code>ctr</code> + <code>c</code> seg\u00edts\u00e9g\u00e9vel.</p> <pre><code>roscore\n</code></pre> <p>Nyissunk egy \u00fajabb tabot a termin\u00e1lban (<code>ctr</code>+<code>shift</code>+<code>t</code>). Ha nem <code>rosbag-gyak</code>-ban lenn\u00e9nk, <code>cd</code>-zz\u00fcnk. A <code>-l</code> kapcsol\u00f3 loopolja a bag-et, a <code>play</code> mondja meg, hogy lej\u00e1tszuk \u00e9s nem p\u00e9ld\u00e1ul r\u00f6gz\u00edtj\u00fck a bag-et.</p> <pre><code>cd ~/rosbag-gyak\nrosbag play -l turtlebot-2019-03-11-SLAM-no-camera.bag \n</code></pre> <p>K\u00e9s\u0151bb ugyan\u00edgy j\u00e1tszhatjuk le a <code>leaf-2019-03-13-a-no-lidar.bag</code>-et is.</p> <p></p>"},{"location":"self_paced/ros1rosbag/#topicok-terminalbol","title":"Topicok terminalb\u00f3l","text":"<p>Nyissunk egy \u00fajabb tabot a termin\u00e1lban (<code>ctr</code>+<code>shift</code>+<code>t</code>), majd vizsg\u00e1ljuik meg a topicokat.</p> <p><pre><code>rostopic list \n</code></pre> Ezt kellene l\u00e1tnunk.</p> <pre><code>    /battery_state\n    /clock\n    /cmd_vel\n    /cmd_vel_rc100\n    /constraint_list\n    /diagnostics\n    /firmware_version\n    /flat_imu\n    /imu\n    /joint_states\n    /landmark_poses_list\n    /magnetic_field\n    /map\n    /move_base/TebLocalPlannerROS/parameter_descriptions\n    /move_base/TebLocalPlannerROS/parameter_updates\n    /move_base/global_costmap/costmap\n    /move_base/global_costmap/costmap_updates\n    /move_base/global_costmap/footprint\n    /move_base/global_costmap/inflation_layer/parameter_descriptions\n    /move_base/global_costmap/inflation_layer/parameter_updates\n    /move_base/global_costmap/obstacle_layer/parameter_descriptions\n    /move_base/global_costmap/obstacle_layer/parameter_updates\n    /move_base/global_costmap/parameter_descriptions\n    /move_base/global_costmap/parameter_updates\n    /move_base/global_costmap/static_layer/parameter_descriptions\n    /move_base/global_costmap/static_layer/parameter_updates\n    /move_base/local_costmap/costmap\n    /move_base/local_costmap/costmap_updates\n    /move_base/local_costmap/footprint\n    /move_base/local_costmap/inflation_layer/parameter_descriptions\n    /move_base/local_costmap/inflation_layer/parameter_updates\n    /move_base/local_costmap/obstacle_layer/parameter_descriptions\n    /move_base/local_costmap/obstacle_layer/parameter_updates\n    /move_base/local_costmap/parameter_descriptions\n    /move_base/local_costmap/parameter_updates\n    /move_base/parameter_descriptions\n    /move_base/parameter_updates\n    /move_base/status\n    /odom\n    /rosout\n    /rosout_agg\n    /rpms\n    /scan\n    /scan_matched_points2\n    /sensor_state\n    /submap_list\n    /tf\n    /tf_static\n    /trajectory_node_list\n</code></pre> <p>Vizsg\u00e1ljunk meg min\u00e9l t\u00f6bb topicot <code>rostopic type</code> illetve <code>rosmsg show</code>-val. A <code>rostopic type /odom</code> parancs hat\u00e1s\u00e1ra megtudhatjuk az <code>/odom</code> topic t\u00edpus\u00e1t, ami <code>nav_msgs/Odometry</code>.  Ha ki akarjuk der\u00edteni a <code>nav_msgs/Odometry</code> fel\u00e9p\u00edt\u00e9s\u00e9t a <code>rosmsg show nav_msgs/Odometry</code>-re lesz sz\u00fcks\u00e9g\u00fcnk. A k\u00e9t parancsot k\u00e9nyelmesebb egybe kiadni, az els\u0151 parancs kimenete lesz a m\u00e1sodik eleje egy <code>|</code>- karakter seg\u00edts\u00e9g\u00e9vel, az eg\u00e9sz egyben pedig \u00edgy n\u00e9z ki:</p> <pre><code>rostopic type /odom | rosmsg show\n</code></pre> <p>Erre megkapjuk, ugyanazt, mint a <code>rosmsg show nav_msgs/Odometry</code>-val, is kapunk, teh\u00e1t az odometria \u00fczenet fel\u00e9p\u00edt\u00e9s\u00e9t.</p> <p><pre><code>    std_msgs/Header header\n    uint32 seq\n    time stamp\n    string frame_id\n    string child_frame_id\n    geometry_msgs/PoseWithCovariance pose\n    geometry_msgs/Pose pose\n        geometry_msgs/Point position\n        float64 x\n        float64 y\n        float64 z\n        geometry_msgs/Quaternion orientation\n        float64 x\n        float64 y\n        float64 z\n        float64 w\n    float64[36] covariance\n    geometry_msgs/TwistWithCovariance twist\n    geometry_msgs/Twist twist\n        geometry_msgs/Vector3 linear\n        float64 x\n        float64 y\n        float64 z\n        geometry_msgs/Vector3 angular\n        float64 x\n        float64 y\n        float64 z\n    float64[36] covariance\n</code></pre> Vizsg\u00e1ljunk meg min\u00e9l t\u00f6bb topicot <code>rostopic echo</code>-val. Le\u00e1ll\u00edt\u00e1s <code>ctr</code> + <code>c</code></p> <pre><code>rostopic echo /odom\n</code></pre> <pre><code>    header: \n    seq: 22203\n    stamp: \n        secs: 1552323858\n        nsecs: 875916038\n    frame_id: \"odom\"\n    child_frame_id: \"base_footprint\"\n    pose: \n    pose: \n        position: \n        x: -0.379863917828\n        y: 0.126037299633\n        z: 0.0\n        orientation: \n        x: 0.0\n        y: 0.0\n        z: -0.485380351543\n        w: 0.874303102493\n    covariance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n    twist: \n    twist: \n        linear: \n        x: 0.151097133756\n        y: 0.0\n        z: 0.0\n        angular: \n        x: 0.0\n        y: 0.0\n        z: 0.0535195507109\n    covariance: [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n</code></pre> <p>Tip</p> <p>A gyakorlat \u00edr\u00e1sakor az <code>rqt_plot</code> volt tal\u00e1n az egyetlen megjelen\u00edt\u0151 az adatokra, manaps\u00e1g erre jobb alternat\u00edv\u00e1nak \u00e9rezz\u00fck a Foxglove Studiot. Ezt a szoftvert t\u00f6bb helyen fogjuk haszn\u00e1lni a tananyagban.</p>"},{"location":"self_paced/ros1rosbag/#rqt_plot","title":"rqt_plot","text":"<p>Ind\u00edtsuk az rqt_plot-ot terminalbol, adjuk hozz\u00e1 p\u00e9ld\u00e1ul az <code>/imu/linear_acceleration</code> topciot.  Megjegyz\u00e9s: az rosbag visszaj\u00e1tsz\u00e1s\u00e1n\u00e1l nem \u00e1ll\u00edtottuk be, hogy id\u0151t gener\u00e1ljon (pedig lehetne), de \u00edgy a m\u00e9r\u00e9s a ploton \u00fajrakezd\u0151dhet.</p> <pre><code>rosrun rqt_plot rqt_plot\n</code></pre> <p></p> <p>Tov\u00e1bbi inform\u00e1ci\u00f3: wiki.ros.org/rqt_plot</p> <p></p>"},{"location":"self_paced/ros1rosbag/#rviz","title":"rviz","text":"<p>Ind\u00edtsuk az rviz-t.</p> <pre><code>rosrun rviz rviz\n</code></pre> <p>Adjunk hozz\u00e1 k\u00fcl\u00f6nb\u00f6z\u0151 topicokat: <code>Add</code> &gt;&gt; <code>By topic</code> &gt;&gt; Kiv\u00e1laszt &gt;&gt; <code>Ok</code>. P\u00e9ld\u00e1ul \u00edgy n\u00e9zzen ki:</p> <p></p> <p>Tov\u00e1bbi inform\u00e1ci\u00f3: wiki.ros.org/rviz</p> <p></p>"},{"location":"self_paced/ros1rosbag/#python","title":"python","text":"<p>A k\u00f6vetkez\u0151kben a listenerTurtle.py seg\u00edts\u00e9g\u00e9vel feliratkozunk az <code>/odom</code> \u00e9s az <code>/imu</code> topicokra \u00e9s els\u0151 k\u00f6rben ki\u00edratjuk az odom x \u00e9s y poz\u00edci\u00f3j\u00e1t, valamint az imu line\u00e1ris gyorsul\u00e1sait. Anonymous m\u00f3don feliratkozunk a k\u00e9t topcira, <code>listener</code> n\u00e9vvel (a n\u00e9v gyakolratilag mell\u00e9kes). K\u00e9t \u00fagynevazett callback f\u00fcgv\u00e9nyt haszn\u00e1lunk a feliratkz\u00e1shoz.</p> <pre><code>import rospy\nimport std_msgs.msg as rosmsg\nimport nav_msgs.msg as navmsg\nimport sensor_msgs.msg as senmsg\n\ndef odometryCallBack(msg):\n    print(\"odom(x,y): %8.4f %8.4f \" % (msg.pose.pose.position.x, msg.pose.pose.position.y))\n\ndef imuCallBack(msg):\n    print(\"imu(xyz):  %8.4f %8.4f %8.4f\" % (msg.linear_acceleration.x, msg.linear_acceleration.y, msg.linear_acceleration.z))\n\nrospy.init_node(\"listener\", anonymous=True)\nrospy.Subscriber(\"/odom\", navmsg.Odometry, odometryCallBack)\nrospy.Subscriber(\"/imu\", senmsg.Imu, imuCallBack)\nrospy.spin()\n</code></pre> <p>Ha nem szeretn\u00e9nk kl\u00f3nozni a teljes repository-t, akkor <code>wget</code>-tel is let\u00f6lthetj\u00fck a listenerTurtle.py-t, a plotterLeaf.py-t \u00e9s a plotterTurtle.py-t.</p> <pre><code>wget https://raw.githubusercontent.com/horverno/ros-gyakorlatok/master/1-rosbag-es-topicok/listenerTurtle.py\nwget https://raw.githubusercontent.com/horverno/ros-gyakorlatok/master/1-rosbag-es-topicok/plotterTurtle.py\nwget https://raw.githubusercontent.com/horverno/ros-gyakorlatok/master/1-rosbag-es-topicok/plotterLeaf.py\n</code></pre> <p>A plotterTurtle.py \u00e9s a plotterLeaf.py hasonl\u00f3 az el\u0151z\u0151h\u00f6z, de terminal helyett GUI-ba \u00edrja az adatokat. A <code>pyqt</code> \u00e9s a <code>pyqtgraph</code> seg\u00edts\u00e9g\u00e9vel felhaszn\u00e1l\u00f3i fel\u00fcleteket k\u00e9sz\u00edthet\u00fcnk, amiket nem csup\u00e1n scripk\u00e9nt, de futtathat\u00f3 \u00e1llom\u00e1nyk\u00e9nt, vagy ak\u00e1r telep\u00edt\u0151k\u00e9nt is haszn\u00e1lhatunk. Els\u0151 l\u00e9p\u00e9sk\u00e9nt ellen\u0151rizz\u00fck, hogy telep\u00edtve vannak-e a sz\u00fcks\u00e9ges package-k, a k\u00f6vetkez\u0151 importokkal:</p> <pre><code>import PyQt5\nimport pyqtgraph\n</code></pre> <p>Amennyiben <code>ModuleNotFoundError</code>-t kapunk telep\u00edts\u00fck a k\u00e9t package-t:</p> <p><pre><code>sudo apt install python3-pip\npip3 install numpy rospkg pyqt5 pyqtgraph PyYaml\n</code></pre> Vagy python 2: <pre><code>sudo apt install python-pip\npip install pyqt5 pyqtgraph\n</code></pre></p> <p>A Nissan leaf helyzet\u00e9t t\u00f6bb fajta m\u00f3don is sz\u00e1m\u00edthatjuk. Lehet a bicikli kinematikai modellel \u00e9s lehet a GPS alapj\u00e1n. A g\u00e9pj\u00e1rm\u0171-szer\u0171 (n\u00e9gy ker\u00e9kkel rendelkez\u0151, els\u0151 tengelyen korm\u00e1nyozhat\u00f3) robot egyszer\u0171s\u00edtett kinematikai le\u00edr\u00e1s\u00e1ra haszn\u00e1lhatjuk a bicikli modellt, ami k\u00f6nnyen szmolhat\u00f3, azonban az id\u0151 f\u00fcggv\u00e9ny\u00e9ben egyre nagyobb pontatlans\u00e1ga lesz. Ez a <code>/leaf/odom</code> topicon \u00e9rhet\u0151 el a Leaf .bag f\u00e1jl visszaj\u00e1tsz\u00e1s\u00e1val. A GPS poz\u00edci\u00f3 mag\u00e1t\u00f3l \u00e9rthet\u0151d\u0151bb, szerencs\u00e9re a m\u00e9r\u00e9s sor\u00e1n egy k\u00fcl\u00f6nlegesen pontos GPS-t haszn\u00e1ltunk, ez a <code>/gps/odom</code> topicon \u00e9rhet\u0151 el.  Vizualiz\u00e1ljuk a k\u00e9t topicot a plotterLeaf.py seg\u00edts\u00e9g\u00e9vel.</p> <pre><code>python plotterLeaf.py\n</code></pre> <p></p> <p>Sokkal \u00f6sszetetteb dolgot is megval\u00f3s\u00edthatunk a Turtlebot .bag f\u00e1jl visszaj\u00e1tsz\u00e1s\u00e1val. Itt nagyon sok topicot vizualiz\u00e1lhatunk. </p> <p></p> <p>Vizsg\u00e1ljuk meg a f\u00e1jokat <code>VS code</code> seg\u00edts\u00e9g\u00e9vel (<code>cd ~/rosbag-gyak</code>, ha nem ott lenn\u00e9nk)</p> <p><pre><code>code .\n</code></pre> Ez egy VS code k\u00f6rnyezetet nyit meg, az aktu\u00e1lis mapp\u00e1val, majd visszaadja a terminal prompt-ot.</p>"},{"location":"self_paced/ros1rosbag/#forras","title":"Forr\u00e1s","text":"<p>ROS-gyakorlatok GitHub Pages kezd\u0151oldal:  horverno.github.io/ros-gyakorlatok</p>"},{"location":"self_paced/ros2git/","title":"Git Basics","text":""},{"location":"self_paced/ros2git/#some-commands","title":"Some Commands","text":"<ul> <li><code>git clone</code>: Clone a git repository</li> <li><code>git config --global user.name \"Sanyika\"</code>: Set username</li> <li><code>git config --global user.email \"sanyika@gggmail.com\"</code>: Set email</li> <li><code>git init</code>: Initialize a local repository</li> <li><code>git add &lt;file&gt;</code>: Add a file</li> <li><code>git status</code>: Check current status</li> <li><code>git commit -m \"My beautiful commit\"</code>: Commit with a message</li> <li><code>git push</code>: Push changes</li> <li><code>git pull</code>: Pull changes, update local repository</li> <li><code>git branch &lt;new_branch_name&gt;</code>: Create a new branch</li> <li><code>git checkout &lt;branch_name&gt;</code>: Switch to a branch</li> <li><code>git checkout -- .</code>: Discard all unstaged changes locally. In newer git versions, <code>git restore .</code> works similarly.</li> <li><code>git merge &lt;branch_name&gt;</code>: Merge a branch into the current branch</li> </ul> <p>Source: link</p>"},{"location":"self_paced/ros2git/#terminology","title":"Terminology","text":"<ul> <li>Local repository: The local working repository, e.g., <code>~/ros2_ws/src/my_repo</code></li> <li>Remote repository: Usually an online remote backup repository, e.g., <code>github.com/my_name/my_repo</code></li> </ul>"},{"location":"self_paced/ros2git/#preparations","title":"Preparations","text":"<p>If you haven't done so already, register on GitHub.</p>"},{"location":"self_paced/ros2git/#using-the-template","title":"Using the Template","text":"<p>Navigate to https://github.com/sze-info/ros2_cpp_template.</p> <p>Here, use the green button to create a package named <code>my_awesome_package</code> with your user:</p> <p></p> <p>Then you will see this page, where you need to fill in the repository name and click the green button to create the repository:</p> <p></p>"},{"location":"self_paced/ros2git/#clone-your-package-with-git-clone","title":"Clone Your Package with <code>git clone</code>","text":"<p>If your GitHub username is <code>mycoolusername</code> and the repository (and package) name is <code>my_awesome_package</code>, you can do it like this:</p> <p><pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/mycoolusername/my_awesome_package\n</code></pre> <pre><code>git clone https://github.com/horverno/my_awesome_package\n</code></pre></p>"},{"location":"self_paced/ros2git/#replace-everything-in-vs-code","title":"Replace Everything in VS Code","text":"<p><pre><code>cd ~/ros2_ws/src/my_awesome_package\n</code></pre> <pre><code>code .\n</code></pre></p> <ol> <li>Replace <code>ros2_cpp_template</code> with <code>my_awesome_package</code></li> <li>Replace <code>sze-info</code> with <code>mycoolusername</code></li> <li>Replace <code>todo</code> as appropriate</li> </ol> <p></p>"},{"location":"self_paced/ros2git/#build","title":"Build","text":"<p>The package can now be built:</p> <p><pre><code>cd ~/ros2_ws/\n</code></pre> <pre><code>colcon build --packages-select my_awesome_package\n</code></pre> The terminal will return a message confirming that the <code>my_awesome_package</code> package has been built.</p>"},{"location":"self_paced/ros2git/#run","title":"Run","text":"<p>Run in the usual way:</p> <p><pre><code>source ~/ros2_ws/install/local_setup.bash\n</code></pre> <pre><code>ros2 launch my_awesome_package launch_example1.launch.py\n</code></pre></p>"},{"location":"self_paced/ros2git/#track-changes-with-git-status","title":"Track Changes with <code>git status</code>","text":"<p>When we replaced the package name, several files were modified:</p> <p><pre><code>cd ~/ros2_ws/src/my_awesome_package\n</code></pre> <pre><code>git status\n</code></pre></p> Git status <p>The same in VS Code looks like this:</p> Git status in VS Code"},{"location":"self_paced/ros2git/#update-remote-repository-with-git-push","title":"Update Remote Repository with <code>git push</code>","text":"<p>We want to add all changes to the commit:</p> <pre><code>git add .\n</code></pre> <p>Fill in the commit message:</p> <pre><code>git commit -m \"Initial commit of my_awesome_package\"\n</code></pre> <p>Actually push the changes to GitHub servers:</p> <pre><code>git push\n</code></pre> Git status after add <p>In VS Code, this is simpler: Commit, then Sync Changes:</p> Git status Sync (push)"},{"location":"self_paced/ros2git/#update-local-repository-with-git-pull","title":"Update Local Repository with <code>git pull</code>","text":"<p>In case the local version is not the latest, the remote stored on GitHub can be updated:</p> Git status (pull)"},{"location":"self_paced/ros2git/#sources","title":"Sources","text":"<ul> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html</li> </ul>"},{"location":"self_paced/ros2launchmarker/","title":"Description","text":"<p>As an independent task, let's create a package named <code>my_launch_pkg</code>, in which a <code>run_transforms_and_markers.launch.py</code> will start the following:</p> <ul> <li>A node that publishes the <code>map</code>, <code>orbit1</code>, and <code>orbit2</code> frames (<code>ros2 run arj_transforms_cpp pub_transforms</code>)</li> <li>The <code>rqt_reconfigure</code> (<code>ros2 run rqt_reconfigure rqt_reconfigure</code>)</li> <li>The static <code>orbit3</code> frame (<code>ros2 run tf2_ros static_transform_publisher --x 1.0 --y 0.2 --z 1.4 --qx 0.0 --qy 0.0 --qz 0.0 --qw 1.0 --frame-id orbit2 --child-frame-id orbit3</code>)</li> <li>And the launch that starts Rviz2 (<code>ros2 launch arj_transforms_cpp rviz1.launch.py</code>)</li> </ul> <p>Verify the correct operation in rviz2.</p> <p>So, at the end of the independent task, it should be possible to start it with the following command:</p> <pre><code>ros2 launch my_launch_pkg run_transforms_and_markers.launch.py\n</code></pre>"},{"location":"self_paced/ros2launchmarker/#create-the-my_launch_pkg-package","title":"Create the <code>my_launch_pkg</code> package","text":"<p>Prerequisite: the <code>arj_transforms_cpp</code> package must already be built and runnable.</p> <p>If the <code>my_launch_pkg</code> package already exists, delete it. (In the lab, it is possible that someone created it in the previous semester.)</p> <pre><code>cd ~ &amp;&amp; test -d \"ros2_ws/src/my_launch_pkg\" &amp;&amp; echo Exists || echo Does not exist\n</code></pre> <pre><code>rm -r ~/ros2_ws/src/my_launch_pkg\n</code></pre> <p>Open a new terminal and source the installation (if not in <code>bashrc</code>), so that the <code>ros2</code> commands work.</p> <p>Navigate to the already created <code>ros2_ws</code> directory.</p> <p>It is important to create the packages in the <code>src</code> directory, not in the root of the workspace. So navigate to the <code>ros2_ws/src</code> folder and run the package creation command:</p> <pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>ros2 pkg create --build-type ament_cmake my_launch_pkg\n</code></pre> <p>The terminal will return a message confirming the creation of the <code>my_launch_pkg</code> package and all necessary files and folders.</p>"},{"location":"self_paced/ros2launchmarker/#launch-folder","title":"Launch folder","text":"<p>Create a folder for the launch files:</p> <pre><code>cd ~/ros2_ws/src/my_launch_pkg\n</code></pre> <pre><code>mkdir launch\n</code></pre>"},{"location":"self_paced/ros2launchmarker/#create-the-launch-file","title":"Create the launch file","text":"<pre><code>cd launch\n</code></pre> <pre><code>code run_transforms_and_markers.launch.py\n</code></pre> <p>Compose a launch file:</p> <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch_ros.substitutions import FindPackageShare\n\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # ros2 run arj_transforms_cpp pub_transforms\n        Node(\n            package='arj_transforms_cpp',\n            executable='pub_transforms',\n        ),\n        # ros2 run rqt_reconfigure rqt_reconfigure\n        Node(\n            package='rqt_reconfigure',\n            executable='rqt_reconfigure',\n        ),\n        # ros2 run tf2_ros static_transform_publisher --x 1.0 --y 0.2 --z 1.4 --qx 0.0 --qy 0.0 --qz 0.0 --qw 1.0 --frame-id orbit2 --child-frame-id orbit3\n        Node(\n            package='tf2_ros',\n            executable='static_transform_publisher',\n            arguments=['1.0', '0.2', '1.4','0', '0', '0', '1', 'orbit2','orbit3'],\n        ),     \n        # ros2 launch arj_transforms_cpp rviz1.launch.py\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource([\n                FindPackageShare(\"arj_transforms_cpp\"), '/launch/', 'rviz1.launch.py'])\n        ),\n    ])\n</code></pre>"},{"location":"self_paced/ros2launchmarker/#using-ros2-launch","title":"Using <code>ROS2</code> launch","text":"<p>The created launch file can be started as follows:</p> <p><pre><code>cd ~/ros2_ws/src/my_launch_pkg/launch # enter the folder containing the launch file\n</code></pre> <pre><code>ros2 launch run_transforms_and_markers.launch.py\n</code></pre></p> <p>In addition to the direct method shown above, a launch file can also be run by the package:</p> <pre><code>ros2 launch &lt;package_name&gt; &lt;launch_file_name&gt;\n</code></pre> <p>For packages that contain launch files, it is advisable to create an <code>exec_depend</code> dependency on the <code>ros2launch</code> package in the package's <code>package.xml</code> file:</p> <pre><code>&lt;exec_depend&gt;ros2launch&lt;/exec_depend&gt;\n</code></pre> <p>This ensures that the <code>ros2 launch</code> command is available after the package is built.</p>"},{"location":"self_paced/ros2launchmarker/#add-to-the-package-to-be-runnable-from-anywhere","title":"Add to the package to be runnable from anywhere","text":"<pre><code>cd ~/ros2_ws/src/my_launch_pkg\n</code></pre> <pre><code>code .\n</code></pre> <p>Insert the following line before <code>&lt;test_depend&gt;</code> in the package.xml:</p> <pre><code>&lt;exec_depend&gt;ros2launch&lt;/exec_depend&gt;\n</code></pre> <p>Insert the following 2 lines before <code>ament_package()</code> in the CMakeLists.txt:</p> <pre><code>install(DIRECTORY launch\n  DESTINATION share/${PROJECT_NAME})\n</code></pre> <p>Build in the usual way:</p> <pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select my_launch_pkg\n</code></pre> <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <p>This command can now be issued from anywhere:</p> <pre><code>ros2 launch my_launch_pkg run_transforms_and_markers.launch.py\n</code></pre>"},{"location":"self_paced/ros2launchmarker/#sources","title":"Sources","text":"<ul> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html</li> </ul>"},{"location":"sensing/","title":"Sensing","text":"<p>Sensing refers to the reading of raw data.</p> <p></p> <p>In the case of sensing, it is important to note that this does not yet mean high-level data processing. Sensors can include cameras, microphones, LIDARs, etc. As the figure shows, in the material, we discuss sensing together with actuation.</p> <p>Note</p> <p>In Hungarian, it is easy to confuse the terms sensing (sensing) and perception (perception). Sensing deals with the simple driver-level production of raw data.</p>"},{"location":"sensing/#camera","title":"Camera","text":"<p>A camera converts the light arriving at its sensor (e.g., CCD CMOS sensor) into an electronic signal, digitally. We can distinguish between mono, stereo, or depth-sensing cameras.</p> <ul> <li>Typical manufacturers: Allied Vision, Basler, Stereolabs, Orbbec, Intel</li> <li>Typical interface: GigE, USB3</li> <li>Typical <code>ROS 2</code> topic types: <code>sensor_msgs/msg/Image</code>, <code>sensor_msgs/msg/CameraInfo</code></li> </ul> <p></p>"},{"location":"sensing/#lidar","title":"LIDAR","text":"<p>A LIDAR (Light Detection and Ranging) sensor is a device that can determine distances using laser pulses and their reflection times. Its principle is similar to that of a laser rangefinder, but its measurement frequency and rate are much higher. For example, consider a rotating 64-channel LIDAR. It typically measures at <code>10</code> or <code>20</code> Hz, meaning it completes <code>10</code> or <code>20</code> full <code>360\u00b0</code> rotations per second. The <code>64</code> channels mean that <code>64</code> sensors are sensing simultaneously at any given moment. One full rotation typically means <code>512</code> / <code>1024</code> / <code>2048</code> measurements per channel. From this, the number of measurements per second can be calculated: e.g., <code>20*64*1024 = 1,310,720</code>. Thus, the device typically measures more than a million 3D points per second, with intensity, ambient, and reflective properties.</p> <ul> <li>Typical manufacturers: Velodyne, Ouster, Livox, SICK, Hokuy, Pioneer, Luminar, Hesai, Robosense, Ibeo, Innoviz, Quanenergy, Cepton, Blickfeld, Aeva</li> <li>Typical interface: GigE</li> <li>Typical <code>ROS 2</code> topic types: <code>sensor_msgs/msg/PointCloud2</code>, <code>sensor_msgs/msg/LaserScan</code></li> </ul> <p>A collection of LIDAR manufacturers, datasets, and algorithms: github.com/szenergy/awesome-lidar.</p> <p></p>"},{"location":"sensing/#radar","title":"Radar","text":"<ul> <li>Typical manufacturers: Aptiv, Bosch, Continental, Denso</li> <li>Typical interface: CAN bus</li> <li>Typical <code>ROS 2</code> topic types: <code>radar_msgs/msg/RadarTrack</code></li> </ul> <p>Comparison of LIDAR and camera characteristics</p>"},{"location":"sensing/#imu","title":"IMU","text":"<p>An IMU (Inertial Measurement Unit) is a sensor containing small electromechanical gyroscopes and accelerometers, as well as signal processing processors. They are often combined with other sensors, such as barometric altimeters, magnetometers, and compasses. Some GPS (GNSS) systems also include them.</p> <ul> <li>Typical manufacturers: Lord MicroStrain, Bosch, XSens</li> <li>Typical interface: Serial, Ethernet, USB, CAN bus</li> <li>Typical <code>ROS 2</code> topic types: <code>sensor_msgs/msg/Imu</code>, <code>sensor_msgs/msg/MagneticField</code></li> </ul> <p></p>"},{"location":"sensing/#gnss-gps","title":"GNSS (GPS)","text":"<p>GNSS (Global Navigation Satellite System) refers to a global satellite-based navigation system, commonly known as GPS. To be precise, GPS is just the first such technology; there are also GLONASS, BeiDou, Galileo, and QZSS systems, operated by different countries/alliances.</p> <ul> <li>Typical manufacturers: SwiftNavigation, VectorNav, Ublox, NovaTel</li> <li>Typical interface: GigE, CAN bus</li> <li>Typical <code>ROS 2</code> topic types: <code>sensor_msgs/msg/NavSatFix</code>, <code>geometry_msgs/msg/PoseStamped</code></li> </ul> <p></p> <p>A short but good description of GNSS accuracy: www.sbg-systems.com/news/mastering-accurac-gnss-and-its-errors-sources/</p>"},{"location":"sensing/#can-bus","title":"CAN bus","text":"<p>The CAN bus (Controller Area Network) is a typically automotive standard that allows microcontrollers and devices to communicate with each other without a central unit (host). Compared to Ethernet communication, it is simpler to implement, has lower bandwidth, and is more robust.</p> <ul> <li>Speed data query, reference signal</li> <li>Steering angle data query, reference signal</li> <li>Typical <code>ROS 2</code> topic types: <code>can_msgs/msg/Frame</code>, <code>geometry_msgs/msg/Twist</code></li> </ul> <p></p>"},{"location":"sensing/#ros-2-time-management","title":"<code>ROS 2</code> Time Management","text":"<p><code>ROS</code> uses Unix time or POSIX time for time management. This represents the number of seconds and nanoseconds elapsed since 00:00:00 UTC (Greenwich Mean Time) on January 1, 1970 (<code>int32 sec</code>, <code>int32 nsec</code>). This takes up relatively little space in memory and makes it easy to calculate the elapsed time between two points by simple subtraction.</p> <p>ros2time.ipynb  </p> <p>The disadvantage is that it is not very intuitive and not human-readable. For example, Foxglove Studio often converts it to a more readable format.</p> <p> </p> <p>Seconds and nanoseconds can be imagined as follows:</p> <p><pre><code>import rclpy\ncurrent_time = node.get_clock().now()\nprint(current_time.to_msg())\n\nOutput: \nsec=1694595162, nanosec=945886859\n</code></pre> The timestamp plays a role in several places:</p> <p><pre><code>ros2 topic echo --once /lexus3/gps/duro/current_pose\n\nheader:\n  stamp:\n    sec: 1694595162\n    nanosec: 945886859\n  frame_id: map\npose:\n  position:\n    x: 640142.9676535318\n    y: 5193606.439717201\n    z: 1.7999999523162842\n  orientation:\n    x: 0.008532664424537166\n    y: 0.0018914791588597107\n    z: 0.44068499630505714\n    w: 0.8976192678279703\n</code></pre> If you want to convert seconds and nanoseconds, you can do it as follows:</p> <pre><code>from datetime import datetime\ncurrent_time_float = current_time.to_msg().sec + current_time.to_msg().nanosec / 1e9 # 1e9 is 1,000,000,000: nanosec to sec\nprint(\"As a float:\\t%.5f\" % (current_time_float))\nprint(\"ISO format:\", end=\"\\t\")\nprint(datetime.utcfromtimestamp(current_time_float).isoformat())\n\n\nOutput:\nAs a float: 1694595162.94589\nISO format: 2023-09-13T08:52:42.945887\n</code></pre>"},{"location":"sensing/#sources","title":"Sources","text":"<ul> <li>Sensors in ROS (online google presentation in Hungarian)</li> <li>Understanding-ROS2-Topics</li> </ul>"},{"location":"sensing/practice/","title":"Practice","text":"<p>The practice works with Ubuntu 22.04 <code>ROS humble</code>, Windows 10/11 WSL <code>humble</code>. The description of the installation of different versions can be found here.</p> <p>Preliminary Check</p> <p>It is worth checking on your home computer before the practice to ensure that the appropriate <code>ROS 2</code> software packages are installed.</p> <p><pre><code>sudo apt install ros-humble-rosbag2 ros-humble-rosbag2-storage-mcap\n</code></pre> In the lab, we also check with <code>check_all.sh</code>: <pre><code>cd /mnt/kozos/script\n./bag_mcap.sh\n./check_all.sh\n</code></pre></p>"},{"location":"sensing/practice/#preparations","title":"Preparations","text":"<p>In the previous practice, we got acquainted with the following rosbag (in ROS 2, the format is already <code>.mcap</code>):</p> <p></p> <p>As a preparation, let's check if the <code>C:\\temp</code> directory exists</p> <p><pre><code>test -d \"/mnt/c/temp\" &amp;&amp; echo Letezik || echo Nem letezik\n</code></pre> or simply: <pre><code>ls /mnt/c/temp\n</code></pre></p> <ul> <li>If it does not exist (No such file or directory), create it: <code>mkdir /mnt/c/temp</code></li> <li>If it exists, there is nothing to do, proceed to the next step, and copy the <code>.mcap</code> files here In the classroom, the copying should be done with one of the following commands: <pre><code>rsync -avzh --progress /mnt/kozos/measurement_files/lexus3sample01.mcap  /mnt/c/temp/\nrsync -avzh --progress /mnt/kozos/measurement_files/lexus3sample02.mcap  /mnt/c/temp/\nrsync -avzh --progress /mnt/kozos/measurement_files/lexus3sample03.mcap  /mnt/c/temp/\nrsync -avzh --progress /mnt/kozos/measurement_files/lexus3sample04.mcap  /mnt/c/temp/\nrsync -avzh --progress /mnt/kozos/measurement_files/lexus3sample05.mcap  /mnt/c/temp/\n</code></pre> At home, you can download from the following link (green button) or as a command with <code>wget</code>: <pre><code>wget  -O lexus3sample02.mcap https://laesze-my.sharepoint.com/:u:/g/personal/herno_o365_sze_hu/EakTOhcjblNInqjRMfaGVmsB0diDv0SWpXw9rwo0MD7f3w?download=1\n</code></pre></li> </ul> <p>MCAP example  553 MB</p> <p>Download MCAP    300 MB</p> <p>List the appropriate copied <code>.mcap</code> file's basic information, similarly:</p> <pre><code>ros2 bag info /mnt/c/temp/lexus3sample06.mcap\n\nclosing.\n\nFiles:             /mnt/c/temp/lexus3sample06.mcap\nBag size:          286.7 MiB\nStorage id:        mcap\nDuration:          3.367s\nStart:             Jul 18 2023 15:37:09.211 (1689687429.211)\nEnd:               Jul 18 2023 15:38:03.314 (1689687483.314)\nMessages:          29598\nTopic information: \n  Topic: /lexus3/zed2i/zed_node/right_raw/image_raw_color/compressed | Type: sensor_msgs/msg/CompressedImage\n  Topic: /lexus3/os_left/points | Type: sensor_msgs/msg/PointCloud2\n  Topic: /lexus3/os_right/points | Type: sensor_msgs/msg/PointCloud2\n  Topic: /lexus3/os_center/imu | Type: sensor_msgs/msg/Imu\n  Topic: /tf_static | Type: tf2_msgs/msg/TFMessage\n  Topic: /lexus3/os_center/points | Type: sensor_msgs/msg/PointCloud2\n  Topic: /tf | Type: tf2_msgs/msg/TFMessage\n  Topic: /lexus3/gps/duro/mag | Type: sensor_msgs/msg/MagneticField\n  Topic: /lexus3/gps/duro/imu | Type: sensor_msgs/msg/Imu\n  Topic: /lexus3/gps/duro/status_string | Type: std_msgs/msg/String\n  Topic: /lexus3/gps/duro/current_pose | Type: geometry_msgs/msg/PoseStamped\n</code></pre>"},{"location":"sensing/practice/#play-back-the-mcap-file","title":"Play back the <code>.mcap</code> file","text":"<p>Next, we will play back the measurement data file and check what data appears, in what type, and at what speed. The <code>--loop</code> switch is for infinite repetition, and the <code>--clock</code> switch is for advertising a <code>/clock</code> topic, which adjusts the playback.</p> <p><pre><code>ros2 bag play /mnt/c/temp/lexus3sample06.mcap --clock --loop\n</code></pre> The same, but played back more slowly, e.g.: <pre><code>ros2 bag play /mnt/c/temp/lexus3sample06.mcap --clock --loop --rate 0.2\n</code></pre> The following topics appear:</p> <pre><code>ros2 topic list\n\n/clock\n/events/read_split\n/lexus3/gps/duro/current_pose\n/lexus3/gps/duro/imu\n/lexus3/gps/duro/mag\n/lexus3/gps/duro/status_string\n/lexus3/os_center/imu\n/lexus3/os_center/points\n/lexus3/os_left/points\n/lexus3/os_right/points\n/lexus3/zed2i/zed_node/right_raw/image_raw_color\n/parameter_events\n/rosout\n/tf\n/tf_static\n</code></pre> <p>The <code>ros2 topic hz</code> shows the frequency of the given topic. The position in this case is ~20Hz.</p> <pre><code>ros2 topic hz /lexus3/gps/duro/current_pose\naverage rate: 20.133\n        min: 0.002s max: 0.101s std dev: 0.03451s window: 22\n</code></pre>"},{"location":"sensing/practice/#ros-2-time-management","title":"<code>ROS 2</code> Time Management","text":"<p><code>ROS</code> uses Unix time, or POSIX time, for time management. This represents the number of seconds and nanoseconds that have elapsed since January 1, 1970, 00:00:00 UTC (Greenwich Mean Time) (<code>int32 sec</code>, <code>int32 nsec</code>). This format takes up relatively little memory and allows for easy calculation of the elapsed time between two points by simple subtraction.</p> <p>ros2time.ipynb</p> <p>The disadvantage is that it is not very intuitive and not human-readable. For example, Foxglove Studio often converts it to a more readable format for this reason.</p> <p> </p> <p>Seconds and nanoseconds can be imagined as follows:</p> <p><pre><code>import rclpy\ncurrent_time = node.get_clock().now()\nprint(current_time.to_msg())\n\nOutput: \nsec=1694595162, nanosec=945886859\n</code></pre> The timestamp plays a role in several places:</p> <pre><code>ros2 topic echo /clock --once\nclock:\n  sec: 1689687476\n  nanosec: 770421827\n</code></pre> <p><pre><code>ros2 topic echo --once /lexus3/gps/duro/current_pose\n\nheader:\n  stamp:\n    sec: 1694595162\n    nanosec: 945886859\n  frame_id: map\npose:\n  position:\n    x: 640142.9676535318\n    y: 5193606.439717201\n    z: 1.7999999523162842\n  orientation:\n    x: 0.008532664424537166\n    y: 0.0018914791588597107\n    z: 0.44068499630505714\n    w: 0.8976192678279703\n</code></pre> If we want to convert seconds and nanoseconds, we can do it as follows:</p> <pre><code>from datetime import datetime\ncurrent_time_float = current_time.to_msg().sec + current_time.to_msg().nanosec / 1e9 # 1e9 is 1,000,000,000: nanosec to sec\nprint(\"As a float:\\t%.5f\" % (current_time_float))\nprint(\"ISO format:\", end=\"\\t\")\nprint(datetime.utcfromtimestamp(current_time_float).isoformat())\n\n\nOutput:\nAs a float: 1694595162.94589\nISO format: 2023-09-13T08:52:42.945887\n</code></pre> <p>Reminder: A nanosecond is one billionth of a second (10^-9 s).</p>"},{"location":"sensing/practice/#global-navigation-satellite-system-gnss-global-positioning-system-gps","title":"Global Navigation Satellite System (GNSS) / Global Positioning System (GPS)","text":"<p>Global Navigation Satellite System (GNSS) / Global Positioning System (GPS) github.com/szenergy/duro_gps_driver When the GPS is connected to the computer via Ethernet and the ROS driver is started, it will advertise the following topics:</p> Topic Type <code>/gps/duro/current_pose</code> <code>[geometry_msgs/PoseStamped]</code> <code>/gps/duro/fix</code> <code>[sensor_msgs/NavSatFix]</code> <code>/gps/duro/imu</code> <code>[sensor_msgs/Imu]</code> <code>/gps/duro/mag</code> <code>[sensor_msgs/MagneticField]</code> <code>/gps/duro/odom</code> <code>[nav_msgs/Odometry]</code> <code>/gps/duro/rollpitchyaw</code> <code>[geometry_msgs/Vector3]</code> <code>/gps/duro/status_flag</code> <code>[std_msgs/UInt8]</code> <code>/gps/duro/status_string</code> <code>[std_msgs/String]</code> <code>/gps/duro/time_ref</code> <code>[sensor_msgs/TimeReference]</code>"},{"location":"sensing/practice/#inertial-measurement-unit-imu","title":"Inertial Measurement Unit (IMU)","text":"<p>Typical ROS 2 topic types: <code>sensor_msgs/msg/Imu</code>, <code>sensor_msgs/msg/MagneticField</code></p> <pre><code>ros2 topic echo --once /lexus3/gps/duro/imu\n\nheader:\n  stamp:\n    sec: 1695039048\n    nanosec: 44466475\n  frame_id: duro\norientation:\n  x: 0.0\n  y: 0.0\n  z: 0.7071067811865475\n  w: 0.7071067811865476\norientation_covariance:\n  - [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\nangular_velocity:\n  x: 0.01330030487804878\n  y: 0.015893864329268294\n  z: 0.037307355182926834\nangular_velocity_covariance:\n  - [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\nlinear_acceleration:\n  x: -0.5291185668945312\n  y: 0.031124621582031248\n  z: -9.610325463867188\nlinear_acceleration_covariance:\n  - [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n</code></pre>"},{"location":"sensing/practice/#camera","title":"Camera","text":"<p>Typical ROS 2 topic types: <code>sensor_msgs/msg/Image</code>, <code>sensor_msgs/msg/CameraInfo</code></p> <pre><code>ros2 topic echo --once /lexus3/zed2i/zed_node/right_raw/image_raw_color\n\nheader:\n  stamp:\n    sec: 1695039047\n    nanosec: 340698516\n  frame_id: zed2i_right_camera_optical_frame\nheight: 720\nwidth: 1280\nencoding: bgra8\nis_bigendian: 0\nstep: 5120\ndata: 21,66,93,255,21,66,94,255,25,69,94,255,14,63,90,255,31,55,80,255,19,49,75,255,26,55,76,255,24,57,80,255,35,51,72,255,30,52,74,255,57,73,88,255,55,74,90,255,64,74,93,255,52,66,86,255,56,61,76,255,25,34,48,255,25,31,52,255,16,24,43,255,14,22,41,255,19,27,46,255,13,20,38,255,23,28,45,255,31,41,65,255,36,37,59,255,23,59,82,255,45,71,91,255,51,84,116,255,70,94,122,255,57,105,141,255,42,84,117,255,42,90,126,255,36,81,116,255,..\n</code></pre>"},{"location":"sensing/practice/#lidar","title":"Lidar","text":"<p>Typical ROS 2 topic types: <code>sensor_msgs/msg/PointCloud2</code>, <code>sensor_msgs/msg/LaserScan</code></p> <pre><code>ros2 topic echo --once /lexus3/os_center/points\n\nheader:\n  stamp:\n    sec: 1695039048\n    nanosec: 390894137\n  frame_id: lexus3/os_center_a_laser_data_frame\nheight: 64\nwidth: 1024\nfields:\n- name: x, y, z, intensity, t, reflectivity, ring, ambient, range\ndata: 0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,63,0,0,16,65,96,211,241,2,0,0,0,0,12,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,63,0,0,16,65,116,145,242,2,0,0,0,0,0,3,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,0,128,63,0,0,32,65,18,92,243,2,0,0,0,0,253,2,0,0,...,\n</code></pre>"},{"location":"sensing/practice/#visualization","title":"Visualization","text":""},{"location":"sensing/practice/#rviz2","title":"RVIZ2","text":"<pre><code>ros2 run rviz2 rviz2\n</code></pre> <p>Set up a similar layout:</p> <p></p>"},{"location":"sensing/practice/#foxglove-studio","title":"Foxglove studio","text":"<pre><code>ros2 launch foxglove_bridge foxglove_bridge_launch.xml port:=8765\n</code></pre> <p>Set up a similar layout:</p> <p></p> <p>Source: foxglove.dev/blog/introducing-foxglove-studios-new-navigation</p>"},{"location":"sensing/practice/#create-the-simple_sub_cpp-package","title":"Create the <code>simple_sub_cpp</code> package","text":"<p>Next, we will create a simple subscriber node that subscribes to <code>geometry_msgs/PoseStamped</code>messages and prints the X and Y coordinates. The practice is based on the official ROS 2 tutorials</p> <p>Open a new terminal and source the installation so that the <code>ros2</code> commands work.</p> <p>Navigate to the already created <code>ros2_ws</code> directory.</p> <p>It is important to create the packages in the <code>src</code> directory, not in the root of the workspace. So navigate to the <code>ros2_ws/src</code> folder and run the package creation command:</p> <pre><code>cd ~/ros2_ws/src\nros2 pkg create --build-type ament_cmake simple_sub_cpp\n</code></pre> <p>The terminal will return a message confirming the creation of the <code>simple_sub_cpp</code> package and all necessary files and folders.</p>"},{"location":"sensing/practice/#write-the-subscriber-node-print_posecpp-simple_sub_node","title":"Write the subscriber node (<code>print_pose.cpp</code> &gt;&gt; <code>simple_sub_node</code>)","text":"<p>Navigate to the <code>ros2_ws/src/simple_sub_cpp/src</code> folder.</p> <p><pre><code>cd ~/ros2_ws/src/simple_sub_cpp/src\n</code></pre> This is the directory in every CMake package where the source files belong (e.g., with the <code>.cpp</code> extension).</p> <p>Download the example subscriber code:</p> <pre><code>wget -O print_pose.cpp https://raw.githubusercontent.com/sze-info/arj_packages/main/etc/print_pose.cpp\n</code></pre> <p>This command created the <code>print_pose.cpp</code> file.</p> <p>Navigate back one level to the <code>cd ~/ros2_ws/src/simple_sub_cpp</code> directory, where the <code>CMakeLists.txt</code> and <code>package.xml</code> files have already been created. Open the folder with VS Code, for example, using the <code>code .</code> command. Here, the . after <code>code</code> means the current folder. Tip: even if you are not in the directory, it is possible to open the entire directory, which simplifies some things later:</p> <pre><code>code ~/ros2_ws/src/simple_sub_cpp/\n</code></pre> <p></p> <pre><code>// ros2 topic type /lexus3/gps/duro/current_pose\n// geometry_msgs/msg/PoseStamped\n// ros2 interface show geometry_msgs/msg/PoseStamped\n\n#include &lt;memory&gt;\n#include \"rclcpp/rclcpp.hpp\"\n#include \"geometry_msgs/msg/pose_stamped.hpp\"\n\nusing std::placeholders::_1;\n\nclass SimplePoseSub : public rclcpp::Node\n{\npublic:\n  SimplePoseSub() : Node(\"simple_pose_sub\")\n  {\n    sub1_ = this-&gt;create_subscription&lt;geometry_msgs::msg::PoseStamped&gt;(\"/lexus3/gps/duro/current_pose\", 10, std::bind(&amp;SimplePoseSub::topic_callback, this, _1));\n  }\n\nprivate:\n  void topic_callback(const geometry_msgs::msg::PoseStamped &amp;msg) const\n  {\n    RCLCPP_INFO(this-&gt;get_logger(), \"x: %.3f, y: %.3f\", msg.pose.position.x, msg.pose.position.y);\n  }\n  rclcpp::Subscription&lt;geometry_msgs::msg::PoseStamped&gt;::SharedPtr sub1_;\n};\n\nint main(int argc, char *argv[])\n{\n  rclcpp::init(argc, argv);\n  rclcpp::spin(std::make_shared&lt;SimplePoseSub&gt;());\n  rclcpp::shutdown();\n  return 0;\n}\n</code></pre> <p>!!! important \"Python equivalent\" The C++ code also has a Python version available at github.com/sze-info/arj_packages c\u00edmen. \u00c9rdemes \u00f6sszehasonl\u00edtani a C++ \u00e9s a python k\u00f3dokat. It is worth comparing the C++ and Python codes.</p>"},{"location":"sensing/practice/#adding-dependencies","title":"Adding Dependencies","text":"<p>It is always advisable to fill in the <code>&lt;description&gt;</code>, <code>&lt;maintainer&gt;</code>, and <code>&lt;license&gt;</code>tags:</p> <pre><code>&lt;description&gt;Examples of minimal publisher/subscriber using rclcpp&lt;/description&gt;\n&lt;maintainer email=\"you@email.com\"&gt;Your Name&lt;/maintainer&gt;\n&lt;license&gt;Apache License 2.0&lt;/license&gt;\n</code></pre> <p>Add a new line after the <code>ament_cmake</code> build tool dependency and insert the following dependencies according to the node's include statements:</p> <pre><code>&lt;depend&gt;rclcpp&lt;/depend&gt;\n&lt;depend&gt;geometry_msgs&lt;/depend&gt;\n</code></pre> <p>This declares that the package requires <code>rclcpp</code> and <code>geometry_msgs</code> at build and runtime.</p>"},{"location":"sensing/practice/#cmakelists","title":"CMakeLists.","text":"<p>Now open the <code>CMakeLists.txt</code> file. Add the following lines under the existing <code>find_package(ament_cmake REQUIRED)</code>dependency:</p> <p><pre><code>find_package(rclcpp REQUIRED)\nfind_package(geometry_msgs REQUIRED)\n</code></pre> Then add the executable (which will only consist of <code>print_pose.cpp</code> for now) and name it simple_sub_node so that it can be run using <code>ros2 run</code>:</p> <pre><code>add_executable(simple_sub_node src/print_pose.cpp)\nament_target_dependencies(simple_sub_node rclcpp geometry_msgs)\n</code></pre> <p>Finally, add the <code>install(TARGETS...)</code> section so that <code>ros2</code> can find the executable we compiled:</p> <pre><code>install(TARGETS\nsimple_sub_node\nDESTINATION lib/${PROJECT_NAME})\n</code></pre> <p>The <code>CMakeLists.txt</code> can be cleaned up by removing some unnecessary sections and comments, resulting in the following:</p> <pre><code>cmake_minimum_required(VERSION 3.8)\nproject(simple_sub_cpp)\n\n# Default to C++14\nif(NOT CMAKE_CXX_STANDARD)\nset(CMAKE_CXX_STANDARD 14)\nendif()\n\nif(CMAKE_COMPILER_IS_GNUCXX OR CMAKE_CXX_COMPILER_ID MATCHES \"Clang\")\nadd_compile_options(-Wall -Wextra -Wpedantic)\nendif()\n\nfind_package(ament_cmake REQUIRED)\nfind_package(rclcpp REQUIRED)\nfind_package(geometry_msgs REQUIRED)\n\nadd_executable(simple_sub_node src/print_pose.cpp)\nament_target_dependencies(simple_sub_node rclcpp geometry_msgs)\n\ninstall(TARGETS\nsimple_sub_node\nDESTINATION lib/${PROJECT_NAME})\n\nament_package()\n</code></pre> <p>In summary, we made the following changes:</p> <p></p> <p></p>"},{"location":"sensing/practice/#build-and-run","title":"Build and Run","text":"<p>!!! success The package can now be built:</p> <pre><code>cd ~/ros2_ws/\ncolcon build --packages-select simple_sub_cpp\n</code></pre> <p>Run it as usual:</p> <pre><code>source ~/ros2_ws/install/setup.bash\nros2 run simple_sub_cpp simple_sub_node\n</code></pre> <p>Outputs: <pre><code>[simple_pose_sub]: x: 697201.725, y: 5285679.845\n[simple_pose_sub]: x: 697201.796, y: 5285679.548\n[simple_pose_sub]: x: 697201.838, y: 5285679.251\n[simple_pose_sub]: x: 697201.886, y: 5285678.949\n</code></pre></p>"},{"location":"sensing/practice/#sources","title":"Sources","text":"<ul> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Creating-Your-First-ROS2-Package.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Cpp-Publisher-And-Subscriber.html</li> <li>docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Writing-A-Simple-Py-Publisher-And-Subscriber.html</li> </ul>"},{"location":"simulation/","title":"Simulation","text":"<p>During simulation, we study the expected behavior of the system using a computer model.</p> <p></p> <p>The essence of simulation is that we do not start testing our initial, possibly untested program code in the real world on our self-driving car/robot. This can have obvious disadvantages. However, it is important to note that the simulator always simulates a simplified model of reality, so code that works well in the simulator may not always work perfectly in real life.</p> <p>So far, we have only used the 2D simulator called Turtlesim. It is popular due to its simplicity and educational nature, but the 3D world is naturally much more complex. Therefore, it may be advisable to use 3D simulators.</p> 2D 3D Turtlesim Gazebo, Carla, SVL, AWSIM, MVsim <p>The most supported simulator by ROS is Gazebo, but it is worth mentioning SVL, which we have our own version optimized for Nissan, Carla, or CoppeliaSim.</p>"},{"location":"simulation/#overview-video-on-simulators","title":"Overview Video on Simulators","text":"<p>Simulate robots like never before with Open 3D Engine from Open Robotics on Vimeo.</p>"},{"location":"simulation/#additional-simulators","title":"Additional Simulators","text":"<ul> <li>OSRF Gazebo - The most supported simulator by ROS, OGRE-based, ROS/ROS 2 compatible.<ul> <li>GitHub repository</li> </ul> </li> <li>CARLA - Unreal Engine-based automotive simulator. Compatible with Autoware, Baidu Apollo, ROS/ROS 2.<ul> <li>GitHub repository</li> <li>YouTube channel</li> </ul> </li> <li>LGSVL / SVL - Unity Engine-based automotive simulator, compatible with Autoware, Baidu Apollo, ROS/ROS 2. Note: LG has suspended active development of the SVL Simulator.<ul> <li>GitHub repository</li> <li>YouTube channel</li> </ul> </li> <li>OSSDC SIM - Unity Engine-based simulator for automotive applications, based on the suspended LGSVL simulator but actively developed. Compatible with Autoware, Baidu Apollo, and ROS/ROS 2.<ul> <li>GitHub repository</li> <li>YouTube video</li> </ul> </li> <li>AirSim - Unreal Engine-based simulator for drones and cars. ROS compatible.<ul> <li>GitHub repository</li> <li>YouTube video</li> </ul> </li> <li>AWSIM - Unity Engine-based simulator for automotive applications. Compatible with Autoware and ROS 2.<ul> <li>GitHub repository</li> <li>YouTube video</li> </ul> </li> <li>CoppeliaSim - Multi-platform, general-purpose robot simulator (formerly known as V-REP).<ul> <li>YouTube channel</li> </ul> </li> <li>MVSim<ul> <li>GitHub repository</li> <li>YouTube video</li> </ul> </li> <li>AutoDRIVE<ul> <li>GitHub repository</li> <li>YouTube channel</li> </ul> </li> </ul>"},{"location":"simulation/#gazebo-and-ros-compatibility","title":"Gazebo and ROS Compatibility","text":"<p>The selection of ROS and Gazebo versions is described based on the Picking the \"Correct\" Versions of ROS &amp; Gazebo link. Note: Versions of Gazebo 11 and earlier are referred to as Gazebo Classic, while those after are referred to as Ignition Gazebo or simply Ignition.</p> GZ Citadel (LTS) GZ Fortress (LTS) GZ Garden ROS 2 Rolling \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe1 ROS 2 Humble (LTS) \ud83d\udd34 \ud83d\udfe2 \ud83d\udfe1 ROS 2 Foxy (LTS) \ud83d\udfe2 \ud83d\udd34 \ud83d\udd34 ROS 1 Noetic (LTS) \ud83d\udfe2 \ud83d\udfe1 \ud83d\udd34 <ul> <li>\ud83d\udfe2 - Recommended combination</li> <li>\ud83d\udfe1 - Possible, but not recommended. With extra work, the two software can be made to work together.</li> <li>\ud83d\udd34 - Not compatible / not possible.</li> </ul>"},{"location":"simulation/carla/","title":"Carla","text":"<p>Link: github.com/carla-simulator/carla</p>"},{"location":"simulation/f1tenth_sim_a/","title":"<code>ROS 2</code> F1/10 Wheeltec Roboworks Gazebo simulation workshop","text":"<p>The workshop is ROS 2 compatible </p>"},{"location":"simulation/f1tenth_sim_a/#video","title":"Video","text":""},{"location":"simulation/f1tenth_sim_a/#requirements-high-level","title":"Requirements (high-level)","text":"<ol> <li>ROS 2 Humble: \ud83d\udfe0 see previous workshops or docs.ros.org/en/humble/Installation.html </li> <li>Gazebo Fortress: \u2705 current workshop gazebosim.org/docs/fortress/install_ubuntu</li> <li><code>ROS gz bridge</code>:  \u2705 current workshop, ROS integration. Install with a single command: <code>sudo apt install ros-humble-ros-gz-bridge</code>, gazebosim.org/docs/fortress/ros2_integration</li> <li>Build and run custom worlds and models  \u2705 current workshop (e.g. <code>F1/10</code> / <code>Wheeltec, Roboworks</code>) </li> </ol> Official F1/10 vehicle vs Wheeltec Roboworks Ackermann Rosbot mini vehicle"},{"location":"simulation/f1tenth_sim_a/#binary-installation-on-ubuntu","title":"Binary Installation on Ubuntu","text":"<p>Fortress binaries are provided for Ubuntu Bionic, Focal and Jammy. All of the Fortress binaries are hosted in the osrfoundation repository. To install all of them, the metapackage <code>ignition-fortress</code> can be installed. The following is based on gazebosim.org/docs/fortress/install_ubuntu.</p> <p>First install some necessary tools:</p> <p><pre><code>sudo apt-get update\n</code></pre> <pre><code>sudo apt-get install lsb-release wget gnupg\n</code></pre></p> <p>Then install Ignition Fortress:</p> <p><pre><code>sudo wget https://packages.osrfoundation.org/gazebo.gpg -O /usr/share/keyrings/pkgs-osrf-archive-keyring.gpg\n</code></pre> <pre><code>echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/pkgs-osrf-archive-keyring.gpg] http://packages.osrfoundation.org/gazebo/ubuntu-stable $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/gazebo-stable.list &gt; /dev/null\n</code></pre> <pre><code>sudo apt-get update\n</code></pre> <pre><code>sudo apt-get install ignition-fortress\n</code></pre></p> <p>All libraries should be ready to use and the <code>ign gazebo</code> app ready to be executed.</p>"},{"location":"simulation/f1tenth_sim_a/#gazebo-fortress-ros-2-integration","title":"Gazebo Fortress ROS 2 integration","text":"<p>Issue the following command:</p> <pre><code>sudo apt install ros-humble-ros-gz-bridge\n</code></pre>"},{"location":"simulation/f1tenth_sim_a/#additional-settings-to-wsl2","title":"Additional settings to WSL2","text":"<p>Warning - WSL2</p> <p>There is an issue, which can be set even in <code>~/.bashrc</code>:</p> <pre><code>export LIBGL_ALWAYS_SOFTWARE=1\n</code></pre> <p>Set it in <code>~/.bashrc</code>: <pre><code>echo \"export LIBGL_ALWAYS_SOFTWARE=1\" &gt;&gt; ~/.bashrc\n</code></pre></p>  Don't forget to source bashrc. <pre><code>source ~/.bashrc\n</code></pre> <p>After new terminal or <code>source</code>:</p> <pre><code>echo $LIBGL_ALWAYS_SOFTWARE\n</code></pre> <p>should print <code>1</code>. Alternatively </p> <p><pre><code>cat ~/.bashrc | grep LIBGL\n</code></pre> should print the line.</p>"},{"location":"simulation/f1tenth_sim_a/#check-the-installation","title":"Check the installation","text":"<p>Success</p> <p>Now the <code>ign gazebo</code> should work and the <code>ros2</code> commands should be available.</p> <p></p> <p>Try at least one of the following commands:</p> <pre><code>ign gazebo\n</code></pre> <pre><code>ign gazebo -v 4 -r ackermann_steering.sdf\n</code></pre> <pre><code>ign gazebo shapes.sdf\n</code></pre> <p></p> <pre><code>ign param --versions\n</code></pre>"},{"location":"simulation/f1tenth_sim_a/#packages-and-build","title":"Packages and build","text":"<p>Detailed description of the packages and build process.</p> <p>It is assumed that the workspace is <code>~/ros2_ws/</code>.</p> <pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/robotverseny/robotverseny_gazebo24\n</code></pre>"},{"location":"simulation/f1tenth_sim_a/#build","title":"Build","text":"<pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --symlink-install --packages-select robotverseny_application robotverseny_description robotverseny_bringup robotverseny_gazebo \n</code></pre> <p>Opcion\u00e1lis, de \u00e9rdemes feltenni az RViz 2D Overlay csomagot, amivel a debug sz\u00f6vegeket lehet megjelen\u00edteni a RViz2-ben:</p> <pre><code>sudo apt install ros-humble-rviz-2d-overlay*\n</code></pre>"},{"location":"simulation/f1tenth_sim_a/#run","title":"Run","text":"Don't forget to source before ROS commands. <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 launch robotverseny_bringup roboworks.launch.py\n</code></pre>"},{"location":"simulation/f1tenth_sim_a/#useful-commands","title":"Useful commands","text":"<p>Publish command topic: <pre><code>ros2 topic pub --once /roboworks/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.5, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: -0.01}}\"\n</code></pre></p> <p>Teleop twist keyboard: <pre><code>ros2 run teleop_twist_keyboard teleop_twist_keyboard --ros-args -r /cmd_vel:=/roboworks/cmd_vel\n</code></pre></p> <p>Ignition info topic: <pre><code>ign topic -i --topic /model/roboworks/cmd_vel\n</code></pre> Ignition echo topic:</p> <pre><code>ign topic -et /model/roboworks/cmd_vel\n</code></pre> <p>Topics:</p> <pre><code>ros2 topic list\n</code></pre>  Here are the topics. <pre><code>/clicked_point\n/clock\n/goal_pose\n/initialpose\n/joint_states\n/parameter_events\n/robot_description\n/roboworks/cmd_vel\n/roboworks/odometry\n/roboworks/scan\n/rosout\n/tf\n/tf_static\n</code></pre>"},{"location":"simulation/f1tenth_sim_a/#linkek","title":"Linkek","text":"<ul> <li>Angol nyelv\u0171 le\u00edr\u00e1s</li> <li>robotverseny.github.io</li> <li>Gazebo Fortress </li> </ul>"},{"location":"simulation/gazebo_f1_10/","title":"Gazebo F1/10","text":"<p>A sz\u00fck\u00e9sges csomagok (mint a TEB local planner, gazebo szimul\u00e1tor bizonyos csomagjai) \u00edgy telep\u00edthet\u0151ek: <pre><code>sudo apt-get -y install ros-melodic-ros-control ros-melodic-gazebo-ros-control ros-melodic-ros-controllers ros-melodic-navigation qt4-default ros-melodic-ackermann-msgs ros-melodic-serial ros-melodic-teb-local-planner*\n</code></pre></p> <p>K\u00e9sz\u00edts\u00fcnk egy k\u00fcl\u00f6n workspace-t, hogy k\u00e9s\u0151bb k\u00f6nnyen t\u00f6r\u00f6lhess\u00fck, ha m\u00e1r nem kell. A <code>git clone</code> parancs ut\u00e1ni <code>.</code> direkt van, \u00edgy plusz k\u00f6nyvt\u00e1r n\u00e9l\u00fcl kl\u00f3noz. A t\u00f6bbi parancs ismer\u0151s az el\u0151z\u0151 gyakorlatokr\u00f3l.</p> <pre><code>mkdir sim_ws\ncd sim_ws/\ngit clone https://github.com/linklab-uva/f1tenth_gtc_tutorial .\ncatkin init\ncatkin build\n</code></pre> <p>Hogy ne kelljen minden terminalban megadnunk a workspace-t, tegy\u00fck a bashrc-be. Ha ezt nem szeren\u00e9nk, el\u00e9g mindig kiadni a <code>source ~/sim_ws/devel/setup.bash</code> parancsot.</p> <p><pre><code>echo \"source ~/sim_ws/devel/setup.bash\" &gt;&gt; ~/.bashrc\nsource ~/.bashrc\n</code></pre> K\u00e9s\u0151bb a <code>bashrc</code>-b\u0151l t\u00f6r\u00f6lhet\u0151 ez a sor, nyissuk meg vs code-b\u00f3l: <code>code ~/.bashrc</code>.</p>"},{"location":"simulation/gazebo_f1_10/#egy-egyszerubb-pelda","title":"Egy egyszer\u0171bb p\u00e9lda","text":"<p>K\u00fcl\u00f6n terminalban <code>roscore</code> ut\u00e1n nyissuk meg a szimul\u00e1tort (az els\u0151 ind\u00edt\u00e1s gyakran lass\u00fa, de azt\u00e1n relat\u00edv gyors lesz):</p> <p><pre><code>roslaunch racecar_gazebo racecar.launch\n</code></pre> Szint\u00e9n k\u00fcl\u00f6n terminalban nyissunk meg egy egyszer\u0171 alkalmaz\u00e1st, amely alap\u00e9rtelmezetten a <code>/cmd_vel</code> parancsot publik\u00e1lja, \u00edgy ir\u00e1ny\u00edtva az aut\u00f3t.</p> <pre><code>rosrun rqt_robot_steering rqt_robot_steering\n</code></pre> <p>Szint\u00e9n k\u00fcl\u00f6n terminalban n\u00e9\u00e9z\u00fck meg <code>rqt_graph</code> seg\u00edts\u00e9g\u00e9vel, hogyan kommunki\u00e1lnak egym\u00e1ssal az ROS node-ok.</p> <pre><code>rosrun rqt_graph rqt_graph\n</code></pre> <p>T\u00f6bb n\u00e9zet is be\u00e1ll\u00edthat\u00f3, de valami hasonl\u00f3t fogunk l\u00e1tni:</p> <p></p>"},{"location":"simulation/gazebo_f1_10/#egy-osszetettebb-pelda","title":"Egy \u00f6sszetettebb p\u00e9lda","text":"<p>Nyissuk meg a szimul\u00e1tort:</p> <pre><code>roslaunch racecar_gazebo racecar.launch\n</code></pre> <p>A k\u00f6vetkez\u0151 a navigation stack ind\u00edt\u00e1sa. Ez a k\u00f6vetkez\u0151 r\u00e9szeket tartalmazza:</p> <ul> <li>AMCL (Adaptive Monte Carlo Localization)</li> <li>global planner based on global costmap</li> <li>TEB local planner based on local costmap</li> <li>robot controller</li> </ul> <pre><code>roslaunch platform navigation.launch\n</code></pre> <p>A k\u00f6vetkez\u0151 parancs ind\u00edtja az rviz-t is. Itt a 2D nav goal-ra kattintva a t\u00e9rk\u00e9p b\u00e1rmely r\u00e9sz\u00e9re elnavig\u00e1l a robot (TEB local planner-t haszn\u00e1lva).</p> <pre><code>roslaunch console navigation.launch\n</code></pre>"},{"location":"simulation/gazebo_fortress/","title":"Ignition Gazebo Fortress","text":"<p>Az Ignition Gazebo Fortress egy long-term support (LTS) release 2026 szeptember\u00e9ig t\u00e1mogatva. ROS 2 Humble kiad\u00e1ssal kompatibilis, l\u00e1sd a kompatibilt\u00e1si m\u00e1trixot.</p> <p></p>"},{"location":"simulation/gazebo_fortress/#telepites","title":"Telep\u00edt\u00e9s","text":"<p>Aj\u00e1nlott az Ubuntu \u00e9s a binary telep\u00edt\u00e9s: gazebosim.org/docs/fortress/install_ubuntu. Term\u00e9szetesen az el\u0151z\u0151 linken tov\u00e1bbkattintva el\u00e9rhet\u0151ek a Windowsos illetve a forr\u00e1sk\u00f3db\u00f3l ford\u00edtott verzi\u00f3k is.</p>"},{"location":"simulation/gazebo_fortress/#ros-2-integracio","title":"ROS 2 integr\u00e1ci\u00f3","text":"<ul> <li>gazebosim.org/docs/fortress/ros2_integration</li> <li>github.com/gazebosim/ros_gz/blob/ros2/ros_gz_bridge/README.md</li> </ul>"},{"location":"simulation/gazebo_fortress/#megjegyzes-wsl-eseten","title":"Megjegyz\u00e9s <code>WSL</code> eset\u00e9n","text":"<p>Gazebo szimul\u00e1tort \u00e9s Windows Subsystem for Linux-ot haszn\u00e1lva el\u0151fordulhat egy issue, ami egy egyszer\u0171 k\u00f6rnyezeti v\u00e1ltoz\u00f3 be\u00e1ll\u00edt\u00e1s\u00e1val jav\u00edthat\u00f3. A <code>~/.bashrc</code> f\u00e1jlba a k\u00f6vetkez\u0151t kell be\u00e1ll\u00edtani:</p> <pre><code>export LIBGL_ALWAYS_SOFTWARE=1 ### GAZEBO IGNITION \n</code></pre> <p>\u00daj termin\u00e1l vagy <code>source</code> ut\u00e1n a <code>echo $LIBGL_ALWAYS_SOFTWARE</code> parancsra <code>1</code>-et fog ki\u00edrni.</p>"},{"location":"simulation/gazebo_fortress/#pelda-gazebo-fortress-beepitett-vilagok-world","title":"P\u00e9lda: Gazebo Fortress be\u00e9p\u00edtett vil\u00e1gok (world)","text":"<p>WSL eset\u00e9n els\u0151 l\u00e9p\u00e9sk\u00e9nt ellen\u0151rizz\u00fck a be\u00e1ll\u00edt\u00e1sok helyess\u00e9g\u00e9t:</p> <pre><code>echo $LIBGL_ALWAYS_SOFTWARE \n</code></pre> <p>Amennyiben a parancsra <code>1</code>-et \u00edr v\u00e1laszk\u00e9nt, akkor helyes a be\u00e1ll\u00edt\u00e1sunk. </p> <p>N\u00e9zz\u00fck meg a telep\u00edtett verzi\u00f3t:</p> <pre><code>ign param --versions\n</code></pre> <p>A v\u00e1lasz pl <code>11.4.1</code> lehet.</p> <p>Ind\u00edtsuk el a Gazebo-t:</p> <pre><code>ign gazebo\n</code></pre> <p></p> <p>Nyissuk meg a <code>shapes.sdf</code> vil\u00e1got. Az SDF (Simulation Description Format), egy be\u00e9p\u00edtett XML le\u00edr\u00e1s. Ak\u00e1r egy parancsk\u00e9nt is ind\u00edthat\u00f3: <code>ign gazebo shapes.sdf</code>.</p> <p></p>"},{"location":"simulation/gazebo_fortress/#pelda-ackermann-robot","title":"P\u00e9lda: Ackermann robot","text":"<p>Ackermann robotnak a \"szem\u00e9lyaut\u00f3-szer\u0171\" el\u0151l k\u00e9t korm\u00e1nyzott, h\u00e1tul pedig k\u00e9t nem korm\u00e1nyzott ker\u00e9kkel rendelkez\u0151 j\u00e1rm\u0171vet / robotot nevezz\u00fck. Ebben a p\u00e9ld\u00e1ban egy ilyen robotot szeretn\u00e9nk mozgatni ROS 2-b\u0151l. Az <code>ign gazebo</code> parancsra a szimul\u00e1ci\u00f3-v\u00e1laszt\u00f3 fel\u00fclet indul. Egy paranccsal ind\u00edthat\u00f3 az Ackermann robot szimul\u00e1ci\u00f3:</p> <pre><code>ign gazebo -v 4 -r ackermann_steering.sdf\n</code></pre> <p></p> <p>Az Ignition Gazebo ROS 2-t\u0151l f\u00fcggetlen, de j\u00f3l t\u00e1mogatott, \u00edgy <code>ros_gz_bridge</code> package seg\u00edts\u00e9g\u00e9vel ind\u00edthat\u00f3 az a bridge, amin a szimul\u00e1ci\u00f3s topicok ROS 2 topick\u00e9nt l\u00e1tszanak, pl:</p> <pre><code>sudo apt update\n</code></pre> <pre><code>sudo apt install ros-humble-ros-gz -y\n</code></pre> <p>Tanteremben pedig:</p> <pre><code>cd /mnt/kozos/script\n</code></pre> <pre><code>./gz_bridge.sh\n</code></pre> <pre><code>ros2 run ros_gz_bridge parameter_bridge /model/vehicle_blue/cmd_vel@geometry_msgs/msg/Twist]ignition.msgs.Twist\n</code></pre> <pre><code>ros2 run ros_gz_bridge parameter_bridge /model/vehicle_blue/odometry@nav_msgs/msg/Odometry[ignition.msgs.Odometry --ros-args -r /model/vehicle_blue/odometry:=/odom\n</code></pre> <pre><code>ros2 run ros_gz_bridge parameter_bridge /world/ackermann_steering/pose/info@tf2_msgs/msg/TFMessage[ignition.msgs.Pose_V --ros-args -r /world/ackermann_steering/pose/info:=/tf\n</code></pre> <p>Ez a 3 parancs egy hossz\u00fa parancsk\u00e9nt is kiadhat\u00f3:</p> <pre><code>ros2 run ros_gz_bridge parameter_bridge /model/vehicle_blue/cmd_vel@geometry_msgs/msg/Twist]ignition.msgs.Twist /model/vehicle_blue/odometry@nav_msgs/msg/Odometry[ignition.msgs.Odometry /world/ackermann_steering/pose/info@tf2_msgs/msg/TFMessage[ignition.msgs.Pose_V --ros-args -r /world/ackermann_steering/pose/info:=/tf -r /model/vehicle_blue/odometry:=/odom\n</code></pre> <p>Hogy pontosan milyen szimul\u00e1ci\u00f3s topicok vannak, az ezekkel a parancsokkal ellen\u0151rizhet\u0151:</p> <pre><code>ign topic -l\n</code></pre> <pre><code>ign topic -et /model/vehicle_blue/tf\n</code></pre> <pre><code>ign topic -i --topic /model/vehicle_blue/tf\n</code></pre> <p>Billenty\u0171zetr\u0151l teleoper\u00e1lhatjuk a j\u00e1rm\u0171vet:</p> <pre><code>ros2 run teleop_twist_keyboard teleop_twist_keyboard --ros-args -r /cmd_vel:=/model/vehicle_blue/cmd_vel\n</code></pre>"},{"location":"simulation/gazebo_fortress/#linkek","title":"Linkek","text":"<ul> <li>gazebosim.org/docs/fortress</li> <li>gazebosim.org/docs/fortress/manipulating_models</li> </ul>"},{"location":"simulation/gazebo_prius/","title":"Gazebo Prius","text":"<pre><code>cd ~/sim_ws/src/\ngit clone https://github.com/osrf/car_demo\ncatkin build car_demo\nsource ~/.bashrc\n</code></pre>"},{"location":"simulation/gazebo_prius/#egy-egyszerubb-pelda-prius","title":"Egy egyszer\u0171bb p\u00e9lda Prius","text":"<p>Mivel gyakran nincs joystick (game_pad) a k\u00f6zelben \u00edrjuk \u00e1t a <code>joy</code> node helyett hasonl\u00f3an az el\u0151z\u0151h\u00f6z <code>rqt_robot_steering</code> m\u0171k\u00f6d\u00e9s\u0171re a Prius demo-t-</p> <p>Nyissuk meg VS code-ban a package-t. <pre><code>roscd car_demo\ncode .\n</code></pre> <code>Joy</code> node helyett a <code>demo.launch</code>-ba a k\u00f6vetkez\u0151k ker\u00fcljenek. </p> <pre><code>&lt;node pkg=\"car_demo\" type=\"robot_steering_translator.py\" name=\"robot_steering_translator1\" output=\"screen\"/&gt;\n&lt;node pkg=\"rqt_robot_steering\" type=\"rqt_robot_steering\" name=\"rqt_robot_st0\" /&gt;\n</code></pre> <p>K\u00e9sz\u00edts\u00fck el a <code>robot_steering_translator.py</code> node-ot, ami <code>/cmd_vel</code>-b\u0151l a <code>/prius</code> topicba k\u00fcld \u00fczeneteket.</p> <p><pre><code>#!/usr/bin/env python\nimport rospy\nfrom prius_msgs.msg import Control\nfrom geometry_msgs.msg import Twist\n\nclass Translator:\n    def __init__(self):\n        self.sub = rospy.Subscriber(\"cmd_vel\", Twist, self.callback)\n        self.pub = rospy.Publisher(\"prius\", Control, queue_size=1)\n        self.last_published_time = rospy.get_rostime()\n        self.last_published = None\n        self.timer = rospy.Timer(rospy.Duration(1./20.), self.timer_callback)\n\n    def timer_callback(self, event):\n        if self.last_published and self.last_published_time &lt; rospy.get_rostime() + rospy.Duration(1.0/20.):\n            self.callback(self.last_published)\n\n    def callback(self, message):\n        command = Control()\n        command.header.stamp = rospy.Time.now()\n        if message.linear.x &gt; 0.2:\n            command.throttle = message.linear.x\n            command.brake = 0.0\n        elif message.linear.x &lt; -0.1:\n            command.throttle = 0.0\n            command.brake = -1 * message.linear.x\n        else:\n            command.throttle = 0.0\n            command.brake = 0.0            \n        command.steer = message.angular.z\n        #rospy.loginfo(\"throttle and brake: %.1f %.1f\" %(command.throttle, command.brake))\n        self.last_published = message\n        self.pub.publish(command)\n\nif __name__ == '__main__':\n    rospy.init_node('robot_steering_translator')\n    rospy.loginfo(\"robot_steering_translator started\")\n    t = Translator()\n    rospy.spin()\n</code></pre> Ne felejts\u00fck a <code>sudo chmod +x nodes/robot_steering_translator.py</code> parancsot se.</p> <p>K\u00fcl\u00f6n terminalban <code>roscore</code> ut\u00e1n nyissuk meg a szimul\u00e1tort (az els\u0151 ind\u00edt\u00e1s gyakran lass\u00fa, de azt\u00e1n relat\u00edv gyors lesz):</p> <pre><code>roslaunch car_demo demo.launch \n</code></pre> <p>Vizsg\u00e1ljuk meg a topicokat plotjuggler seg\u00edts\u00e9g\u00e9vel. </p>"},{"location":"simulation/practice/","title":"Ignition Gazebo Practice","text":""},{"location":"simulation/practice/#creating-your-own-robot-simulation","title":"Creating Your Own Robot Simulation","text":"<p>In the following steps, we will create a simple environment (world) and a robot model. To do this, create a <code>simulation</code> folder and within it, a file named <code>building_robot.sdf</code>. The folder can be created anywhere, and the file name is also freely selectable, but it is recommended to follow the given method for consistency.</p> <pre><code>mkdir simulation\ncd simulation\ntouch building_robot.sdf\n</code></pre>"},{"location":"simulation/practice/#creating-the-environment","title":"Creating the Environment","text":"<p>Open the created file in Visual Studio Code and paste the following code snippet:</p> <pre><code>&lt;?xml version=\"1.0\" ?&gt;\n&lt;sdf version=\"1.10\"&gt;\n    &lt;world name=\"car_world\"&gt;\n        &lt;physics name=\"1ms\" type=\"ignored\"&gt;\n            &lt;max_step_size&gt;0.001&lt;/max_step_size&gt;\n            &lt;real_time_factor&gt;1.0&lt;/real_time_factor&gt;\n        &lt;/physics&gt;\n        &lt;plugin\n            filename=\"gz-sim-physics-system\"\n            name=\"gz::sim::systems::Physics\"&gt;\n        &lt;/plugin&gt;\n        &lt;plugin\n            filename=\"gz-sim-user-commands-system\"\n            name=\"gz::sim::systems::UserCommands\"&gt;\n        &lt;/plugin&gt;\n        &lt;plugin\n            filename=\"gz-sim-scene-broadcaster-system\"\n            name=\"gz::sim::systems::SceneBroadcaster\"&gt;\n        &lt;/plugin&gt;\n\n        &lt;light type=\"directional\" name=\"sun\"&gt;\n            &lt;cast_shadows&gt;true&lt;/cast_shadows&gt;\n            &lt;pose&gt;0 0 10 0 0 0&lt;/pose&gt;\n            &lt;diffuse&gt;0.8 0.8 0.8 1&lt;/diffuse&gt;\n            &lt;specular&gt;0.2 0.2 0.2 1&lt;/specular&gt;\n            &lt;attenuation&gt;\n                &lt;range&gt;1000&lt;/range&gt;\n                &lt;constant&gt;0.9&lt;/constant&gt;\n                &lt;linear&gt;0.01&lt;/linear&gt;\n                &lt;quadratic&gt;0.001&lt;/quadratic&gt;\n            &lt;/attenuation&gt;\n            &lt;direction&gt;-0.5 0.1 -0.9&lt;/direction&gt;\n        &lt;/light&gt;\n\n        &lt;model name=\"ground_plane\"&gt;\n            &lt;static&gt;true&lt;/static&gt;\n            &lt;link name=\"link\"&gt;\n                &lt;collision name=\"collision\"&gt;\n                &lt;geometry&gt;\n                    &lt;plane&gt;\n                    &lt;normal&gt;0 0 1&lt;/normal&gt;\n                    &lt;/plane&gt;\n                &lt;/geometry&gt;\n                &lt;/collision&gt;\n                &lt;visual name=\"visual\"&gt;\n                &lt;geometry&gt;\n                    &lt;plane&gt;\n                    &lt;normal&gt;0 0 1&lt;/normal&gt;\n                    &lt;size&gt;100 100&lt;/size&gt;\n                    &lt;/plane&gt;\n                &lt;/geometry&gt;\n                &lt;material&gt;\n                    &lt;ambient&gt;0.8 0.8 0.8 1&lt;/ambient&gt;\n                    &lt;diffuse&gt;0.8 0.8 0.8 1&lt;/diffuse&gt;\n                    &lt;specular&gt;0.8 0.8 0.8 1&lt;/specular&gt;\n                &lt;/material&gt;\n                &lt;/visual&gt;\n            &lt;/link&gt;\n        &lt;/model&gt;\n    &lt;/world&gt;\n&lt;/sdf&gt;\n</code></pre> <p>The above code snippet defines an empty environment with only a plane (ground) and default lighting (sunlight). Save the code and start the simulation as follows from the <code>simulation</code> folder:</p> <p><pre><code>cd ~/simulation\n</code></pre> <pre><code>ign gazebo building_robot.sdf\n</code></pre></p> <p>After starting, you should see an empty environment as described:</p> <p></p>"},{"location":"simulation/practice/#creating-the-robot-model","title":"Creating the Robot Model","text":"<p>Continue editing the <code>building_robot.sdf</code> file after the <code>&lt;/model&gt;</code> tag:</p> <pre><code>&lt;model name='vehicle_blue' canonical_link='chassis'&gt;\n    &lt;pose relative_to='world'&gt;0 0 0 0 0 0&lt;/pose&gt;\n&lt;/model&gt;\nA robot model name in this case is `vehicle_blue`. The name can be freely chosen, but it is important to ensure that the name is unique among the models used within the same environment.\n\nThe components that make up the model (e.g., chassis, wheels, etc.) will be referred to as links.\n\nEach model can have a single `canonical_link` element. All other links used within the model will connect to this. If no `canonical_link` element is defined, the first link will be the default `canonical` type.\n\nThe `&lt;pose&gt;` tag is used to specify the position and orientation of a link. The `relative_to` attribute after the tag specifies what the link's position and orientation are defined relative to. Without the attribute, the position is given relative to the environment. The format for specifying position and orientation is `&lt;pose&gt;X Y Z R P Y&lt;/pose&gt;`, where X, Y, and Z are the position coordinates within the frame, and R, P, and Y specify the orientation in radians. When defining the robot, we set all parameters to zero, so the robot and the environment frame coincide.\n\nEach model (robot) consists of `links` connected by `joints`.\n\n## Defining the Links that Make Up the Robot\n\nWhen creating each link, the following must be specified:\n1. Link name and position\n2. Link inertial properties (mass and inertia matrix)\n3. Visual and simplified (collision) geometry\n\n- Chassis\n\nCreating the link:\n\n``` xml\n&lt;link name='chassis'&gt;\n    &lt;pose relative_to='__model__'&gt;0.5 0 0.4 0 0 0&lt;/pose&gt;\n&lt;/link&gt;\n</code></pre> <p>Inertial properties (units are in SI):</p> <pre><code>&lt;inertial&gt;\n    &lt;mass&gt;1.14395&lt;/mass&gt;\n    &lt;inertia&gt;\n    &lt;ixx&gt;0.095329&lt;/ixx&gt;\n    &lt;ixy&gt;0&lt;/ixy&gt;\n    &lt;ixz&gt;0&lt;/ixz&gt;\n    &lt;iyy&gt;0.381317&lt;/iyy&gt;\n    &lt;iyz&gt;0&lt;/iyz&gt;\n    &lt;izz&gt;0.476646&lt;/izz&gt;\n    &lt;/inertia&gt;\n&lt;/inertial&gt;\n</code></pre> <p>Specifying visual and simplified (collision) geometry:</p> <pre><code>&lt;visual name='visual'&gt;\n    &lt;geometry&gt;\n    &lt;box&gt;\n        &lt;size&gt;2.0 1.0 0.5&lt;/size&gt;\n    &lt;/box&gt;\n    &lt;/geometry&gt;\n    &lt;material&gt;\n    &lt;ambient&gt;0.0 0.0 1.0 1&lt;/ambient&gt;\n    &lt;diffuse&gt;0.0 0.0 1.0 1&lt;/diffuse&gt;\n    &lt;specular&gt;0.0 0.0 1.0 1&lt;/specular&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n</code></pre> <pre><code>&lt;collision name='collision'&gt;\n    &lt;geometry&gt;\n    &lt;box&gt;\n        &lt;size&gt;2.0 1.0 0.5&lt;/size&gt;\n    &lt;/box&gt;\n    &lt;/geometry&gt;\n&lt;/collision&gt;\n</code></pre> <p>Start the simulation again:</p> <p><pre><code>cd ~/simulation\n</code></pre> <pre><code>ign gazebo building_robot.sdf\n</code></pre></p> <p>After this, you should see the robot chassis in the simulator:</p> <p></p> <ul> <li>Right and Left Wheel</li> </ul> <p>Create the links for the robot's right and left (driven) wheels. This should be done within the <code>&lt;model&gt;</code> tags defining the robot, as all link definitions within the same model (robot) belong here.</p> <p>We will create the wheels using cylinders. The wheels need to rotate around the Y-axis, so we must specify their correct orientation.</p> <pre><code>&lt;link name='left_wheel'&gt;\n    &lt;pose relative_to=\"chassis\"&gt;-0.5 0.6 0 -1.5707 0 0&lt;/pose&gt;\n    &lt;inertial&gt;\n    &lt;mass&gt;1&lt;/mass&gt;\n    &lt;inertia&gt;\n        &lt;ixx&gt;0.043333&lt;/ixx&gt;\n        &lt;ixy&gt;0&lt;/ixy&gt;\n        &lt;ixz&gt;0&lt;/ixz&gt;\n        &lt;iyy&gt;0.043333&lt;/iyy&gt;\n        &lt;iyz&gt;0&lt;/iyz&gt;\n        &lt;izz&gt;0.08&lt;/izz&gt;\n    &lt;/inertia&gt;\n    &lt;/inertial&gt;\n</code></pre> <p>Specifying visual and simplified (collision) geometry:</p> <p><pre><code>&lt;visual name='visual'&gt;\n    &lt;geometry&gt;\n        &lt;cylinder&gt;\n        &lt;radius&gt;0.4&lt;/radius&gt;\n        &lt;length&gt;0.2&lt;/length&gt;\n        &lt;/cylinder&gt;\n    &lt;/geometry&gt;\n    &lt;material&gt;\n        &lt;ambient&gt;1.0 0.0 0.0 1&lt;/ambient&gt;\n        &lt;diffuse&gt;1.0 0.0 0.0 1&lt;/diffuse&gt;\n        &lt;specular&gt;0.0 0.0 1.0 1&lt;/specular&gt;\n    &lt;/material&gt;\n&lt;/visual&gt;\n    &lt;collision name='collision'&gt;\n        &lt;geometry&gt;\n            &lt;cylinder&gt;\n                &lt;radius&gt;0.4&lt;/radius&gt;\n                &lt;length&gt;0.2&lt;/length&gt;\n            &lt;/cylinder&gt;\n        &lt;/geometry&gt;\n    &lt;/collision&gt;\n&lt;/link&gt;\n</code></pre> The caster wheel is defined in a similar manner, differing only in position (and of course the link name) from the right wheel definition:</p> <pre><code>&lt;link name='right_wheel'&gt;\n    &lt;pose relative_to=\"chassis\"&gt;-0.5 -0.6 0 -1.5707 0 0&lt;/pose&gt;\n    &lt;inertial&gt;\n        &lt;mass&gt;1&lt;/mass&gt;\n        &lt;inertia&gt;\n            &lt;ixx&gt;0.043333&lt;/ixx&gt;\n            &lt;ixy&gt;0&lt;/ixy&gt;\n            &lt;ixz&gt;0&lt;/ixz&gt;\n            &lt;iyy&gt;0.043333&lt;/iyy&gt;\n            &lt;iyz&gt;0&lt;/iyz&gt;\n            &lt;izz&gt;0.08&lt;/izz&gt;\n        &lt;/inertia&gt;\n    &lt;/inertial&gt;\n    &lt;visual name='visual'&gt;\n        &lt;geometry&gt;\n            &lt;cylinder&gt;\n                &lt;radius&gt;0.4&lt;/radius&gt;\n                &lt;length&gt;0.2&lt;/length&gt;\n            &lt;/cylinder&gt;\n        &lt;/geometry&gt;\n        &lt;material&gt;\n            &lt;ambient&gt;1.0 0.0 0.0 1&lt;/ambient&gt;\n            &lt;diffuse&gt;1.0 0.0 0.0 1&lt;/diffuse&gt;\n            &lt;specular&gt;1.0 0.0 0.0 1&lt;/specular&gt;\n        &lt;/material&gt;\n    &lt;/visual&gt;\n    &lt;collision name='collision'&gt;\n        &lt;geometry&gt;\n            &lt;cylinder&gt;\n                &lt;radius&gt;0.4&lt;/radius&gt;\n                &lt;length&gt;0.2&lt;/length&gt;\n            &lt;/cylinder&gt;\n        &lt;/geometry&gt;\n    &lt;/collision&gt;\n&lt;/link&gt;\n</code></pre>"},{"location":"simulation/practice/#adding-a-caster-wheel","title":"Adding a Caster Wheel","text":"<p>We can also create custom frames, which we will do when building the caster wheel:</p> <pre><code>&lt;frame name=\"caster_frame\" attached_to='chassis'&gt;\n    &lt;pose&gt;0.8 0 -0.2 0 0 0&lt;/pose&gt;\n&lt;/frame&gt;\n</code></pre> <p>The created frame is named <code>caster_frame</code>, which is attached to the <code>chassis</code> link. The <code>&lt;pose&gt;</code> tag specifies its position and orientation relative to this link, but the <code>relative_to</code> attribute is not needed for custom frames.</p> <p>Continue defining the caster wheel:</p> <pre><code>&lt;link name='caster'&gt;\n    &lt;pose relative_to='caster_frame'/&gt;\n    &lt;inertial&gt;\n        &lt;mass&gt;1&lt;/mass&gt;\n        &lt;inertia&gt;\n            &lt;ixx&gt;0.016&lt;/ixx&gt;\n            &lt;ixy&gt;0&lt;/ixy&gt;\n            &lt;ixz&gt;0&lt;/ixz&gt;\n            &lt;iyy&gt;0.016&lt;/iyy&gt;\n            &lt;iyz&gt;0&lt;/iyz&gt;\n            &lt;izz&gt;0.016&lt;/izz&gt;\n        &lt;/inertia&gt;\n    &lt;/inertial&gt;\n    &lt;visual name='visual'&gt;\n        &lt;geometry&gt;\n            &lt;sphere&gt;\n                &lt;radius&gt;0.2&lt;/radius&gt;\n            &lt;/sphere&gt;\n        &lt;/geometry&gt;\n        &lt;material&gt;\n            &lt;ambient&gt;0.0 1 0.0 1&lt;/ambient&gt;\n            &lt;diffuse&gt;0.0 1 0.0 1&lt;/diffuse&gt;\n            &lt;specular&gt;0.0 1 0.0 1&lt;/specular&gt;\n        &lt;/material&gt;\n    &lt;/visual&gt;\n    &lt;collision name='collision'&gt;\n        &lt;geometry&gt;\n            &lt;sphere&gt;\n                &lt;radius&gt;0.2&lt;/radius&gt;\n            &lt;/sphere&gt;\n        &lt;/geometry&gt;\n    &lt;/collision&gt;\n&lt;/link&gt;\n</code></pre>"},{"location":"simulation/practice/#defining-joints","title":"Defining Joints","text":"<p>We need to define the relationships between the previously defined links. These relationships will specify how the links can move relative to each other.</p> <ul> <li>Left Wheel Joint</li> </ul> <p>Specify the joint name and type. The wheel needs to rotate, so we choose the <code>revolute</code> type.</p> <pre><code>&lt;joint name='left_wheel_joint' type='revolute'&gt;\n    &lt;pose relative_to='left_wheel'/&gt;\n    &lt;parent&gt;chassis&lt;/parent&gt;\n    &lt;child&gt;left_wheel&lt;/child&gt;\n    &lt;axis&gt;\n        &lt;xyz expressed_in='__model__'&gt;0 1 0&lt;/xyz&gt;\n        &lt;limit&gt;\n            &lt;lower&gt;-1.79769e+308&lt;/lower&gt;    &lt;!--negative infinity--&gt;\n            &lt;upper&gt;1.79769e+308&lt;/upper&gt;     &lt;!--positive infinity--&gt;\n        &lt;/limit&gt;\n    &lt;/axis&gt;\n&lt;/joint&gt;\n</code></pre> <ul> <li>Right Wheel Joint</li> </ul> <p>The right wheel joint is defined similarly to the left wheel joint:</p> <pre><code>&lt;joint name='right_wheel_joint' type='revolute'&gt;\n    &lt;pose relative_to='right_wheel'/&gt;\n    &lt;parent&gt;chassis&lt;/parent&gt;\n    &lt;child&gt;right_wheel&lt;/child&gt;\n    &lt;axis&gt;\n        &lt;xyz expressed_in='__model__'&gt;0 1 0&lt;/xyz&gt;\n        &lt;limit&gt;\n            &lt;lower&gt;-1.79769e+308&lt;/lower&gt;    &lt;!--negative infinity--&gt;\n            &lt;upper&gt;1.79769e+308&lt;/upper&gt;     &lt;!--positive infinity--&gt;\n        &lt;/limit&gt;\n    &lt;/axis&gt;\n&lt;/joint&gt;\n</code></pre> <ul> <li>Caster Wheel Joint</li> </ul> <p>Since the caster wheel is a sphere, it can rotate around all axes. Therefore, we use a different joint type:</p> <pre><code>&lt;joint name='caster_wheel' type='ball'&gt;\n    &lt;parent&gt;chassis&lt;/parent&gt;\n    &lt;child&gt;caster&lt;/child&gt;\n&lt;/joint&gt;\n</code></pre> <p>Start the simulation again:</p> <pre><code>cd ~/simulation\nign gazebo building_robot.sdf\n</code></pre> <p>After this, you should see the robot in the simulator:</p> <p></p> <p>The content of the XML descriptor file presented so far: <pre><code>&lt;?xml version=\"1.0\" ?&gt;\n&lt;sdf version=\"1.8\"&gt;\n    &lt;world name=\"car_world\"&gt;\n        &lt;physics name=\"1ms\" type=\"ignored\"&gt;\n            &lt;max_step_size&gt;0.001&lt;/max_step_size&gt;\n            &lt;real_time_factor&gt;1.0&lt;/real_time_factor&gt;\n        &lt;/physics&gt;\n        &lt;plugin\n            filename=\"gz-sim-physics-system\"\n            name=\"gz::sim::systems::Physics\"&gt;\n        &lt;/plugin&gt;\n        &lt;plugin\n            filename=\"gz-sim-user-commands-system\"\n            name=\"gz::sim::systems::UserCommands\"&gt;\n        &lt;/plugin&gt;\n        &lt;plugin\n            filename=\"gz-sim-scene-broadcaster-system\"\n            name=\"gz::sim::systems::SceneBroadcaster\"&gt;\n        &lt;/plugin&gt;\n\n        &lt;light type=\"directional\" name=\"sun\"&gt;\n            &lt;cast_shadows&gt;true&lt;/cast_shadows&gt;\n            &lt;pose&gt;0 0 10 0 0 0&lt;/pose&gt;\n            &lt;diffuse&gt;0.8 0.8 0.8 1&lt;/diffuse&gt;\n            &lt;specular&gt;0.2 0.2 0.2 1&lt;/specular&gt;\n            &lt;attenuation&gt;\n                &lt;range&gt;1000&lt;/range&gt;\n                &lt;constant&gt;0.9&lt;/constant&gt;\n                &lt;linear&gt;0.01&lt;/linear&gt;\n                &lt;quadratic&gt;0.001&lt;/quadratic&gt;\n            &lt;/attenuation&gt;\n            &lt;direction&gt;-0.5 0.1 -0.9&lt;/direction&gt;\n        &lt;/light&gt;\n\n        &lt;model name=\"ground_plane\"&gt;\n            &lt;static&gt;true&lt;/static&gt;\n            &lt;link name=\"link\"&gt;\n                &lt;collision name=\"collision\"&gt;\n                &lt;geometry&gt;\n                    &lt;plane&gt;\n                    &lt;normal&gt;0 0 1&lt;/normal&gt;\n                    &lt;/plane&gt;\n                &lt;/geometry&gt;\n                &lt;/collision&gt;\n                &lt;visual name=\"visual\"&gt;\n                &lt;geometry&gt;\n                    &lt;plane&gt;\n                    &lt;normal&gt;0 0 1&lt;/normal&gt;\n                    &lt;size&gt;100 100&lt;/size&gt;\n                    &lt;/plane&gt;\n                &lt;/geometry&gt;\n                &lt;material&gt;\n                    &lt;ambient&gt;0.8 0.8 0.8 1&lt;/ambient&gt;\n                    &lt;diffuse&gt;0.8 0.8 0.8 1&lt;/diffuse&gt;\n                    &lt;specular&gt;0.8 0.8 0.8 1&lt;/specular&gt;\n                &lt;/material&gt;\n                &lt;/visual&gt;\n            &lt;/link&gt;\n        &lt;/model&gt;\n\n        &lt;model name='vehicle_blue' canonical_link='chassis'&gt;\n            &lt;pose relative_to='world'&gt;0 0 0 0 0 0&lt;/pose&gt;   &lt;!--alapbe\u00e1ll\u00edt\u00e1s szerint a megadott p\u00f3z a vil\u00e1g koordin\u00e1t\u00e1ihoz k\u00e9pest \u00e9rtend\u0151--&gt;\n\n            &lt;!--karossz\u00e9ria--&gt;\n            &lt;link name='chassis'&gt;\n                &lt;pose relative_to='__model__'&gt;0.5 0 0.4 0 0 0&lt;/pose&gt;\n                &lt;inertial&gt;\n                    &lt;mass&gt;1.14395&lt;/mass&gt;\n                    &lt;inertia&gt;\n                        &lt;ixx&gt;0.095329&lt;/ixx&gt;\n                        &lt;ixy&gt;0&lt;/ixy&gt;\n                        &lt;ixz&gt;0&lt;/ixz&gt;\n                        &lt;iyy&gt;0.381317&lt;/iyy&gt;\n                        &lt;iyz&gt;0&lt;/iyz&gt;\n                        &lt;izz&gt;0.476646&lt;/izz&gt;\n                    &lt;/inertia&gt;\n                &lt;/inertial&gt;\n                &lt;visual name='visual'&gt;\n                    &lt;geometry&gt;\n                        &lt;box&gt;\n                            &lt;size&gt;2.0 1.0 0.5&lt;/size&gt;\n                        &lt;/box&gt;\n                    &lt;/geometry&gt;\n                    &lt;!--Az \u00f6sszetev\u0151 anyagjellemz\u0151i (sz\u00edne)--&gt;\n                    &lt;material&gt;\n                        &lt;ambient&gt;0.0 0.0 1.0 1&lt;/ambient&gt;\n                        &lt;diffuse&gt;0.0 0.0 1.0 1&lt;/diffuse&gt;\n                        &lt;specular&gt;0.0 0.0 1.0 1&lt;/specular&gt;\n                    &lt;/material&gt;\n                &lt;/visual&gt;\n                &lt;collision name='collision'&gt;\n                    &lt;geometry&gt;\n                        &lt;box&gt;\n                            &lt;size&gt;2.0 1.0 0.5&lt;/size&gt;\n                        &lt;/box&gt;\n                    &lt;/geometry&gt;\n                &lt;/collision&gt;\n            &lt;/link&gt;\n\n            &lt;!--Bal ker\u00e9k--&gt;\n            &lt;link name='left_wheel'&gt;\n                &lt;pose relative_to=\"chassis\"&gt;-0.5 0.6 0 -1.5707 0 0&lt;/pose&gt;\n                &lt;inertial&gt;\n                    &lt;mass&gt;1&lt;/mass&gt;\n                    &lt;inertia&gt;\n                        &lt;ixx&gt;0.043333&lt;/ixx&gt;\n                        &lt;ixy&gt;0&lt;/ixy&gt;\n                        &lt;ixz&gt;0&lt;/ixz&gt;\n                        &lt;iyy&gt;0.043333&lt;/iyy&gt;\n                        &lt;iyz&gt;0&lt;/iyz&gt;\n                        &lt;izz&gt;0.08&lt;/izz&gt;\n                    &lt;/inertia&gt;\n                &lt;/inertial&gt;\n                &lt;visual name='visual'&gt;\n                    &lt;geometry&gt;\n                        &lt;cylinder&gt;\n                            &lt;radius&gt;0.4&lt;/radius&gt;\n                            &lt;length&gt;0.2&lt;/length&gt;\n                        &lt;/cylinder&gt;\n                    &lt;/geometry&gt;\n                    &lt;material&gt;\n                        &lt;ambient&gt;1.0 0.0 0.0 1&lt;/ambient&gt;\n                        &lt;diffuse&gt;1.0 0.0 0.0 1&lt;/diffuse&gt;\n                        &lt;specular&gt;1.0 0.0 0.0 1&lt;/specular&gt;\n                    &lt;/material&gt;\n                &lt;/visual&gt;\n                &lt;collision name='collision'&gt;\n                    &lt;geometry&gt;\n                        &lt;cylinder&gt;\n                            &lt;radius&gt;0.4&lt;/radius&gt;\n                            &lt;length&gt;0.2&lt;/length&gt;\n                        &lt;/cylinder&gt;\n                    &lt;/geometry&gt;\n                &lt;/collision&gt;\n            &lt;/link&gt;\n\n            &lt;!--Jobb ker\u00e9k (ugyanaz, mint a bal ker\u00e9k, a poz\u00edci\u00f3 t\u00fckr\u00f6z\u00e9s\u00e9vel)--&gt;\n            &lt;link name='right_wheel'&gt;\n                &lt;pose relative_to=\"chassis\"&gt;-0.5 -0.6 0 -1.5707 0 0&lt;/pose&gt;\n                &lt;inertial&gt;\n                    &lt;mass&gt;1&lt;/mass&gt;\n                    &lt;inertia&gt;\n                        &lt;ixx&gt;0.043333&lt;/ixx&gt;\n                        &lt;ixy&gt;0&lt;/ixy&gt;\n                        &lt;ixz&gt;0&lt;/ixz&gt;\n                        &lt;iyy&gt;0.043333&lt;/iyy&gt;\n                        &lt;iyz&gt;0&lt;/iyz&gt;\n                        &lt;izz&gt;0.08&lt;/izz&gt;\n                    &lt;/inertia&gt;\n                &lt;/inertial&gt;\n                &lt;visual name='visual'&gt;\n                    &lt;geometry&gt;\n                        &lt;cylinder&gt;\n                            &lt;radius&gt;0.4&lt;/radius&gt;\n                            &lt;length&gt;0.2&lt;/length&gt;\n                        &lt;/cylinder&gt;\n                    &lt;/geometry&gt;\n                    &lt;material&gt;\n                        &lt;ambient&gt;1.0 0.0 0.0 1&lt;/ambient&gt;\n                        &lt;diffuse&gt;1.0 0.0 0.0 1&lt;/diffuse&gt;\n                        &lt;specular&gt;1.0 0.0 0.0 1&lt;/specular&gt;\n                    &lt;/material&gt;\n                &lt;/visual&gt;\n                &lt;collision name='collision'&gt;\n                    &lt;geometry&gt;\n                        &lt;cylinder&gt;\n                            &lt;radius&gt;0.4&lt;/radius&gt;\n                            &lt;length&gt;0.2&lt;/length&gt;\n                        &lt;/cylinder&gt;\n                    &lt;/geometry&gt;\n                &lt;/collision&gt;\n            &lt;/link&gt;\n\n            &lt;!--Tetsz\u0151leges frame--&gt;\n            &lt;frame name=\"caster_frame\" attached_to='chassis'&gt;\n                &lt;pose&gt;0.8 0 -0.2 0 0 0&lt;/pose&gt;\n            &lt;/frame&gt;\n\n            &lt;!--T\u00e1maszt\u00f3g\u00f6rg\u0151--&gt;\n            &lt;link name='caster'&gt;\n                &lt;pose relative_to='caster_frame'/&gt;\n                &lt;inertial&gt;\n                    &lt;mass&gt;1&lt;/mass&gt;\n                    &lt;inertia&gt;\n                        &lt;ixx&gt;0.016&lt;/ixx&gt;\n                        &lt;ixy&gt;0&lt;/ixy&gt;\n                        &lt;ixz&gt;0&lt;/ixz&gt;\n                        &lt;iyy&gt;0.016&lt;/iyy&gt;\n                        &lt;iyz&gt;0&lt;/iyz&gt;\n                        &lt;izz&gt;0.016&lt;/izz&gt;\n                    &lt;/inertia&gt;\n                &lt;/inertial&gt;\n                &lt;visual name='visual'&gt;\n                    &lt;geometry&gt;\n                        &lt;sphere&gt;\n                            &lt;radius&gt;0.2&lt;/radius&gt;\n                        &lt;/sphere&gt;\n                    &lt;/geometry&gt;\n                    &lt;material&gt;\n                        &lt;ambient&gt;0.0 1 0.0 1&lt;/ambient&gt;\n                        &lt;diffuse&gt;0.0 1 0.0 1&lt;/diffuse&gt;\n                        &lt;specular&gt;0.0 1 0.0 1&lt;/specular&gt;\n                    &lt;/material&gt;\n                &lt;/visual&gt;\n                &lt;collision name='collision'&gt;\n                    &lt;geometry&gt;\n                        &lt;sphere&gt;\n                            &lt;radius&gt;0.2&lt;/radius&gt;\n                        &lt;/sphere&gt;\n                    &lt;/geometry&gt;\n                &lt;/collision&gt;\n            &lt;/link&gt;\n\n            &lt;!--Bal ker\u00e9k joint--&gt;\n            &lt;joint name='left_wheel_joint' type='revolute'&gt;\n                &lt;pose relative_to='left_wheel'/&gt;\n                &lt;parent&gt;chassis&lt;/parent&gt;\n                &lt;child&gt;left_wheel&lt;/child&gt;\n                &lt;axis&gt;\n                    &lt;xyz expressed_in='__model__'&gt;0 1 0&lt;/xyz&gt; \n                    &lt;limit&gt;\n                        &lt;lower&gt;-1.79769e+308&lt;/lower&gt;    &lt;!--negat\u00edv v\u00e9gtelen--&gt;\n                        &lt;upper&gt;1.79769e+308&lt;/upper&gt;     &lt;!--pozit\u00edv v\u00e9gtelen--&gt;\n                    &lt;/limit&gt;\n                &lt;/axis&gt;\n            &lt;/joint&gt;\n\n            &lt;!--Jobb ker\u00e9k joint--&gt;\n            &lt;joint name='right_wheel_joint' type='revolute'&gt;\n                &lt;pose relative_to='right_wheel'/&gt;\n                &lt;parent&gt;chassis&lt;/parent&gt;\n                &lt;child&gt;right_wheel&lt;/child&gt;\n                &lt;axis&gt;\n                    &lt;xyz expressed_in='__model__'&gt;0 1 0&lt;/xyz&gt;\n                    &lt;limit&gt;\n                        &lt;lower&gt;-1.79769e+308&lt;/lower&gt;    &lt;!--negat\u00edv v\u00e9gtelen--&gt;\n                        &lt;upper&gt;1.79769e+308&lt;/upper&gt;     &lt;!--pozit\u00edv v\u00e9gtelen--&gt;\n                    &lt;/limit&gt;\n                &lt;/axis&gt;\n            &lt;/joint&gt;\n\n            &lt;!--T\u00e1maszt\u00f3g\u00f6rg\u0151 joint--&gt;\n            &lt;joint name='caster_wheel' type='ball'&gt;\n                &lt;parent&gt;chassis&lt;/parent&gt;\n                &lt;child&gt;caster&lt;/child&gt;\n            &lt;/joint&gt;\n        &lt;/model&gt;\n    &lt;/world&gt;\n&lt;/sdf&gt;\n</code></pre></p>"},{"location":"simulation/practice/#moving-the-robot-platform","title":"Moving the Robot Platform","text":"<p>To move the robot we previously assembled, we will use a plugin, specifically the <code>diff_drive</code> plugin.</p> <p>Open the previously created <code>building_robot.sdf</code> file and within the <code>vehicle_blue</code> <code>&lt;model&gt;</code> tags, invoke the plugin and define the basic parameters needed for its use:</p> <pre><code>&lt;plugin\n    filename=\"libignition-gazebo-diff-drive-system.so\"\n    name=\"ignition::gazebo::systems::DiffDrive\"&gt;\n    &lt;left_joint&gt;left_wheel_joint&lt;/left_joint&gt;\n    &lt;right_joint&gt;right_wheel_joint&lt;/right_joint&gt;\n    &lt;wheel_separation&gt;1.2&lt;/wheel_separation&gt;\n    &lt;wheel_radius&gt;0.4&lt;/wheel_radius&gt;\n    &lt;odom_publish_frequency&gt;1&lt;/odom_publish_frequency&gt;\n    &lt;topic&gt;cmd_vel&lt;/topic&gt;\n&lt;/plugin&gt;\n</code></pre> <p>The <code>&lt;plugin&gt;</code> tag has two attributes. One is the name of the library from which the plugin originates (<code>filename</code>), and the other is the plugin name (<code>name</code>). The additional tags define the characteristics of the differential drive robot: - <code>&lt;left_joint&gt;</code> and <code>&lt;right_joint&gt;</code>: the joints that define the connection between the robot's left and right wheels and the robot chassis. - <code>&lt;wheel_separation&gt;</code>: the distance between the driven wheels, i.e., the track width. Since we previously specified that the positions of the right and left wheels along the Y-axis are -0.6m and 0.6m, the wheel distance is 1.2m. - <code>&lt;wheel_radius&gt;</code>: the radius of the driven wheels. - <code>&lt;odom_publish_frequency&gt;</code>: the frequency at which we want to publish the odometry calculated by the plugin.</p> <p>With these parameters set, our model is ready to move. The next step is to send commands to it, which can be done using the <code>cmd_vel</code> topic.</p> <ol> <li> <p>Start the robot with manual command input</p> </li> <li> <p>In one terminal, start the simulation: <pre><code>ign gazebo building_robot.sdf\n</code></pre></p> </li> <li> <p>From another terminal, send a command to the robot: <pre><code>ign topic -t \"/cmd_vel\" -m ignition.msgs.Twist -p \"linear: {x: 0.5}, angular: {z: 0.05}\"\n</code></pre></p> </li> <li> <p>Press the play button in the simulator.</p> </li> </ol> <p>Following these steps, the robot model should start moving.</p> <ol> <li>Move the robot using the keyboard</li> </ol> <p>Now we will control the robot by reading the keyboard, also using a ROS2 topic. This will require two additional plugins: <code>KeyPublisher</code> and <code>TriggeredPublisher</code>.</p> <p>The <code>KeyPublisher</code> is an <code>ign-gui</code> plugin that reads keyboard key presses and sends them to the <code>/keyboard/keypress</code> topic. Let's try this plugin:</p> <ul> <li>Again, start the simulator in one terminal:</li> </ul> <pre><code>ign gazebo building_robot.sdf\n</code></pre> <ul> <li> <p>In the top right corner of the simulator window, click on the <code>plugins</code> dropdown list, then select the <code>Key Publisher</code> option.</p> </li> <li> <p>In another terminal, enter the following to print all keyboard presses:</p> </li> </ul> <pre><code>ign topic -e -t /keyboard/keypress\n</code></pre> <p>The next step is to map the key presses to commands suitable for controlling the robot. We will use the <code>TriggeredPublisher</code> plugin for this.</p> <p>The <code>TriggeredPublisher</code> plugin creates an output based on a given input in a way we define. In the <code>building_robot.sdf</code> file, within the <code>&lt;world&gt;</code> tags, specify the following mapping:</p> <pre><code>&lt;plugin filename=\"libignition-gazebo-triggered-publisher-system.so\"\n        name=\"ignition::gazebo::systems::TriggeredPublisher\"&gt;\n    &lt;input type=\"ignition.msgs.Int32\" topic=\"/keyboard/keypress\"&gt;\n        &lt;match field=\"data\"&gt;16777235&lt;/match&gt;\n    &lt;/input&gt;\n    &lt;output type=\"ignition.msgs.Twist\" topic=\"/cmd_vel\"&gt;\n        linear: {x: 0.5}, angular: {z: 0.0}\n    &lt;/output&gt;\n&lt;/plugin&gt;\n</code></pre> <p>Try controlling the robot:</p> <ul> <li>Start the simulator again:</li> </ul> <pre><code>ign gazebo building_robot.sdf\n</code></pre> <ul> <li> <p>Select the <code>Key Publisher</code> plugin.</p> </li> <li> <p>Ensure the simulation is running, press the Play button if necessary.</p> </li> <li> <p>Press the <code>Up</code> (\u2191) arrow key. The robot should start moving forward.</p> </li> </ul>"},{"location":"simulation/practice/#independent-task","title":"Independent Task","text":"<p>Create the functions for all arrow keys by extending the previous code snippet. The task can be solved analogously by modifying the parameters using the following mappings:</p> <ul> <li>Left arrow, value: <code>16777234</code>, parameters: <code>linear: {x: 0.0}, angular: {z: 0.5}</code></li> <li>Up arrow, value: <code>16777235</code>, parameters: <code>linear: {x: 0.5}, angular: {z: 0.0}</code></li> <li>Right arrow, value: <code>16777236</code>, parameters: <code>linear: {x: 0.0}, angular: {z: -0.5}</code></li> <li>Down arrow, value: <code>16777237</code>, parameters: <code>linear: {x: 0.5}, angular: {z: 0.0}</code></li> </ul>"},{"location":"simulation/practice/#extending-the-environment","title":"Extending the Environment","text":"<p>The simulated environment created so far only contains a ground plane and sunlight. Let's create additional environmental elements by adding primitive static elements. Start by creating a single rectangular \"wall\":</p> <pre><code>&lt;model name='wall'&gt;\n    &lt;static&gt;true&lt;/static&gt;\n    &lt;pose&gt;5 0 0 0 0 0&lt;/pose&gt;&lt;!--pose relative to the world--&gt;\n    &lt;link name='box'&gt;\n        &lt;pose/&gt;\n        &lt;visual name='visual'&gt;\n            &lt;geometry&gt;\n                &lt;box&gt;\n                    &lt;size&gt;0.5 10.0 2.0&lt;/size&gt;\n                &lt;/box&gt;\n            &lt;/geometry&gt;\n            &lt;!--add material (color)--&gt;\n            &lt;material&gt;\n                &lt;ambient&gt;0.0 0.0 1.0 1&lt;/ambient&gt;\n                &lt;diffuse&gt;0.0 0.0 1.0 1&lt;/diffuse&gt;\n                &lt;specular&gt;0.0 0.0 1.0 1&lt;/specular&gt;\n            &lt;/material&gt;\n        &lt;/visual&gt;\n        &lt;collision name='collision'&gt;\n            &lt;geometry&gt;\n                &lt;box&gt;\n                    &lt;size&gt;0.5 10.0 2.0&lt;/size&gt;\n                &lt;/box&gt;\n            &lt;/geometry&gt;\n        &lt;/collision&gt;\n    &lt;/link&gt;\n&lt;/model&gt;\n</code></pre>"},{"location":"simulation/practice/#independent-task_1","title":"Independent Task","text":"<p>Add two more elements to the environment with the following parameters: 1. Element     - name: wall1     - pose: (0 12 0 0 0 1.5707)     - size: (0.5 10.0 2.0)     - material, color: optional</p> <ol> <li>Element<ul> <li>name: wall2</li> <li>pose: (0 -12 0 0 0 1.5707)</li> <li>size: (0.5 10.0 2.0)</li> <li>material, color: optional</li> </ul> </li> </ol>"},{"location":"simulation/practice/#adding-a-sensor","title":"Adding a Sensor","text":"<p>In the previous sections, we created a movable robot simulation, but for autonomous operation, some sensor simulation is necessary. In the following steps, we will add an IMU (Inertial Measurement Unit) sensor and a LiDAR sensor to the previously created robot.</p> <ul> <li>IMU Sensor</li> </ul> <p>The IMU sensor provides three distinct pieces of information: - The sensor's orientation in quaternion format. - The sensor's angular velocity around the (X, Y, Z) axes. - The sensor's linear acceleration along the (X, Y, Z) axes.</p> <p>The IMU sensor can also be added using a plugin. Define the IMU sensor by editing the previously created file within the <code>&lt;world&gt;</code> tags:</p> <pre><code>&lt;plugin filename=\"libignition-gazebo-imu-system.so\"\n        name=\"ignition::gazebo::systems::Imu\"&gt;\n&lt;/plugin&gt;\n</code></pre> <p>After defining the plugin, define the parameters for the sensor. The sensor will return the parameters of the link to which it is assigned. Since we want to measure the robot, or more specifically the robot chassis, we specify this link:</p> <pre><code>&lt;sensor name=\"imu_sensor\" type=\"imu\"&gt;\n    &lt;always_on&gt;1&lt;/always_on&gt;\n    &lt;update_rate&gt;1&lt;/update_rate&gt;\n    &lt;visualize&gt;true&lt;/visualize&gt;\n    &lt;topic&gt;imu&lt;/topic&gt;\n&lt;/sensor&gt;\n</code></pre> <p>The applied parameters are: - <code>&lt;always_on&gt;</code>: if the value is 1, the sensor will always update its output data according to the update rate. - <code>&lt;update_rate&gt;</code>: the update frequency of the output data. - <code>&lt;visualize&gt;</code>: if the value is 1, the sensor representation will be visually displayed. - <code>&lt;topic&gt;</code>: the name of the topic containing the output data.</p> <p>Try the created sensor.</p> <ul> <li>After saving, start the simulator:</li> </ul> <pre><code>ign gazebo building_robot.sdf\n</code></pre> <ul> <li>In another terminal, print the IMU data. If you move the robot with the keyboard, changes will be observed in the sensor data:</li> </ul> <pre><code>ign topic -e -t /imu\n</code></pre>"},{"location":"simulation/practice/#sources","title":"Sources","text":"<ul> <li>gazebosim.org/docs/fortress/sdf_worlds</li> <li>gazebosim.org/docs/fortress/building_robot</li> <li>gazebosim.org/docs/fortress/moving_robot</li> </ul>"},{"location":"telepites/","title":"Telep\u00edt\u00e9s","text":"<p>ROS 2</p> <p>ROS 1 verzi\u00f3kat csak t\u00f6rt\u00e9nelmi okokb\u00f3l t\u00e1rgyalunk, a jelenlegi fejleszt\u00e9sekhez a ROS 2-t aj\u00e1nljuk.</p> <p><code>ROS 1</code> alapvet\u0151en Linux rendszereken t\u00e1mogatott, b\u00e1r voltak pr\u00f3b\u00e1lkoz\u00e1sok m\u00e1s oper\u00e1ci\u00f3s rendszerekre is. Ezzel szemben az <code>ROS 2</code> m\u00e1r t\u00e1mogatja a nat\u00edv Windows, Mac OS vagy egy\u00e9b Real-Time oper\u00e1ci\u00f3s rendszen t\u00f6rt\u00e9n\u0151 futtat\u00e1st. Teh\u00e1t alapvet\u0151en n\u00e9gy lehet\u0151s\u00e9g adott:</p> <ol> <li>Dual boot, Windows mell\u00e9 telep\u00edtett nat\u00edv Linux (legink\u00e1bb Ubuntu) \u2705 le\u00edr\u00e1s</li> <li>Windows WSL2, k\u00f6nny\u0171s\u00faly\u00fa Linux virtu\u00e1lis g\u00e9p \u2705 le\u00edr\u00e1s</li> <li>Virtu\u00e1lis g\u00e9p Windowsra \ud83d\udfe0</li> <li>Windows build \ud83d\udfe0</li> </ol> <p>Ebb\u0151l a 4 lehet\u0151s\u00e9gb\u0151l az els\u0151 kett\u0151t aj\u00e1nljuk, de telm\u00e9szetesen a t\u00f6bbi sem tiltott. A dual boot betekint\u00e9st ny\u00fajt a Linux vil\u00e1gba, ami egy m\u00e9rn\u00f6kn\u00e9l hasznos tud\u00e1st jelent manaps\u00e1g. Telep\u00edt\u00e9sn\u00e9l k\u00f6r\u00fcltekint\u0151en kell elj\u00e1rni, hiszen egy rossz be\u00e1ll\u00edt\u00e1s adatveszt\u00e9st okoz, \u00edgy a biztons\u00e1gi ment\u00e9s is aj\u00e1nlott. A WSL (Windows Subsystem for Linux) egy k\u00f6nny\u0171s\u00faly\u00fa kompatibilit\u00e1si r\u00e9teg Linux-alap\u00fa elemek futtat\u00e1s\u00e1hoz Windows 10, vagy Windows 11 alap\u00fa rendszereken. Ahogy a k\u00f6vetkez\u0151 \u00e1br\u00e1n is l\u00e1tszik, a Linux kernel ugyanolyan egyszer\u0171en \u00e9rheti el a hardverelemeket (CPU, mem\u00f3ria, GPU), mint a Windows kernel. Ehhez k\u00e9pest a virtu\u00e1lis g\u00e9p (3. lehet\u0151s\u00e9g) egy j\u00f3val lassabb , t\u00f6bb absztrakci\u00f3s r\u00e9teget haszn\u00e1l\u00f3 megold\u00e1s, annak aj\u00e1nlott, akinek vagy nagyon modern, gyors g\u00e9pe van, vagy m\u00e1r eleve telep\u00edtett ilyen rendszereket. A nat\u00edv Windows build (4. lehet\u0151s\u00e9g) elvileg adott, de mivel a dokumen\u00e1ti\u00f3 t\u00falnyom\u00f3 r\u00e9sze Linuxra \u00e9rhet\u0151 el, \u00edgy nagyon sok extra munk\u00e1t fog jelenteni.</p> <p>Az els\u0151 h\u00e1rom opci\u00f3 szeml\u00e9ltet\u00e9se:</p> <p></p>"},{"location":"telepites/#tamogatott-operacios-rendszerek-es-ros-disztibuciok","title":"T\u00e1mogatott oper\u00e1ci\u00f3s rendszerek \u00e9s <code>ROS</code> disztib\u00faci\u00f3k","text":"Oper\u00e1ci\u00f3s rendszer t\u00e1mogatott t\u00e1mogatott t\u00e1mogatott Ubuntu 18.04 ROS melodic Ubuntu 20.04 ROS noetic ROS2 humble Ubuntu 22.04 ROS2 humble Windows 10 (nat\u00edv) ROS2 humble Windows 11 (nat\u00edv) ROS2 humble Windows 10 (WSL2) ROS melodic ROS noetic ROS2 humble Windows 11 (WSL2) ROS melodic ROS noetic ROS2 humble <p>Tip</p> <p>Az ROS 1 melodic python 2.7-et t\u00e1mogat, ez nem aj\u00e1nlott.</p>"},{"location":"telepites/#ubuntu-es-python","title":"Ubuntu \u00e9s Python","text":"<ul> <li>Ubuntu <code>18.04.6 LTS</code> Python <code>2.7.17</code></li> <li>Ubuntu <code>20.04.4 LTS</code> Python <code>3.8.10</code></li> <li>Ubuntu <code>22.04.1 LTS</code> Python <code>3.10.6</code></li> </ul>"},{"location":"telepites/ros_humble/","title":"ROS 2 humble","text":"<p>Egyszer\u0171 telep\u00edt\u00e9s</p> <p>A telep\u00edt\u00e9s l\u00e9p\u00e9sr\u0151l-l\u00e9p\u00e9sre is v\u00e9grehajthat\u00f3, de k\u00e9sz\u00edtett\u00fcnk egy egyszer\u0171 shell script alap\u00fa telep\u00edt\u00e9st is.</p> <p>Ahogy abevezet\u0151ben \u00edrtuk, alapvet\u0151en n\u00e9gy lehet\u0151s\u00e9g adott <code>ROS 2 Humble</code> telep\u00edt\u00e9s\u00e9re:</p> <ol> <li>Dual boot, Windows mell\u00e9 telep\u00edtett nat\u00edv Linux (legink\u00e1bb Ubuntu) \u2705 le\u00edr\u00e1s</li> <li>Windows WSL2, k\u00f6nny\u0171s\u00faly\u00fa Linux virtu\u00e1lis g\u00e9p \u2705 le\u00edr\u00e1s</li> <li>Virtu\u00e1lis g\u00e9p Windowsra \ud83d\udfe0</li> <li>Windows build \ud83d\udfe0</li> </ol> <p>Ebb\u0151l a 4 lehet\u0151s\u00e9gb\u0151l az els\u0151 kett\u0151t aj\u00e1nljuk, de telm\u00e9szetesen a t\u00f6bbi sem tiltott. A dual boot betekint\u00e9st ny\u00fajt a Linux vil\u00e1gba, ami egy m\u00e9rn\u00f6kn\u00e9l hasznos tud\u00e1st jelent manaps\u00e1g. Telep\u00edt\u00e9sn\u00e9l k\u00f6r\u00fcltekint\u0151en kell elj\u00e1rni, hiszen egy rossz be\u00e1ll\u00edt\u00e1s adatveszt\u00e9st okoz, \u00edgy a biztons\u00e1gi ment\u00e9s is aj\u00e1nlott. A WSL (Windows Subsystem for Linux) egy k\u00f6nny\u0171s\u00faly\u00fa kompatibilit\u00e1si r\u00e9teg Linux-alap\u00fa elemek futtat\u00e1s\u00e1hoz Windows 10, vagy Windows 11 alap\u00fa rendszereken. Ahogy a k\u00f6vetkez\u0151 \u00e1br\u00e1n is l\u00e1tszik, a Linux kernel ugyanolyan egyszer\u0171en \u00e9rheti el a hardverelemeket (CPU, mem\u00f3ria, GPU stb), mint a Windows kernel. Ehhez k\u00e9pest a virtu\u00e1lis g\u00e9p (3. lehet\u0151s\u00e9g) egy j\u00f3val lassabb, t\u00f6bb absztrakci\u00f3s r\u00e9teget haszn\u00e1l\u00f3 megold\u00e1s, annak aj\u00e1nlott, akinek vagy nagyon modern, gyors g\u00e9pe van, vagy m\u00e1r eleve telep\u00edtett ilyen rendszereket. A nat\u00edv Windows build (4. lehet\u0151s\u00e9g) elvileg adott, de mivel a dokumen\u00e1ti\u00f3 t\u00falnyom\u00f3 r\u00e9sze Linuxra \u00e9rhet\u0151 el, \u00edgy nagyon sok extra munk\u00e1t fog jelenteni.</p> <p>Az els\u0151 h\u00e1rom opci\u00f3 szeml\u00e9ltet\u00e9se:</p> <p></p>"},{"location":"telepites/ros_humble/#telepites","title":"Telep\u00edt\u00e9s","text":"<p>A k\u00f6vetkez\u0151 le\u00edr\u00e1s Ubuntu 22.04 Jammyre vonatkozik. Megjegyz\u00e9s, hogy m\u00e1s verzi\u00f3k is t\u00e1mogatottak, ezekre vonatkoz\u00f3 telep\u00edt\u00e9s \u00e9s le\u00edr\u00e1sok el\u00e9rhet\u0151ek itt: docs.ros.org/en/humble/Installation/Alternatives.html</p> <p>A k\u00f6vetkez\u0151 le\u00edr\u00e1s a docs.ros.org/en/humble/Installation.html alapszik.</p>"},{"location":"telepites/ros_humble/#nyelv-beallitasa","title":"Nyelv be\u00e1ll\u00edt\u00e1sa","text":"<p>Note</p> <p>Ez a l\u00e9p\u00e9s \u00e1ltal\u00e1ban kihagyhat\u00f3</p> <p>Gy\u0151z\u0151dj\u00f6n meg arr\u00f3l, hogy olyan ter\u00fcleti be\u00e1ll\u00edt\u00e1ssal rendelkezik, amely t\u00e1mogatja az UTF-8 szabv\u00e1nyt. </p> <pre><code>locale # UTF-8 ellen\u0151rz\u00e9se\n\nsudo apt update &amp;&amp; sudo apt install locales\nsudo locale-gen en_US en_US.UTF-8\nsudo update-locale LC_ALL=en_US.UTF-8 LANG=en_US.UTF-8\nexport LANG=en_US.UTF-8\n\nlocale # be\u00e1ll\u00edt\u00e1sok ellen\u0151rz\u00e9se\n</code></pre>"},{"location":"telepites/ros_humble/#forrasok-beallitasa","title":"Forr\u00e1sok be\u00e1ll\u00edt\u00e1sa","text":"<p>Hozz\u00e1 kell adnia a ROS 2 apt t\u00e1rol\u00f3t a rendszer\u00e9hez.</p> <p>El\u0151sz\u00f6r gy\u0151z\u0151dj\u00f6n meg arr\u00f3l, hogy az Ubuntu Universe adatt\u00e1r enged\u00e9lyezve van.</p> <pre><code>sudo apt install software-properties-common\nsudo add-apt-repository universe\n</code></pre> <p>ROS 2 GPG kulcs hozz\u00e1ad\u00e1sa, <code>apt</code>-vel.</p> <pre><code>sudo apt update &amp;&amp; sudo apt install curl -y\nsudo curl -sSL https://raw.githubusercontent.com/ros/rosdistro/master/ros.key -o /usr/share/keyrings/ros-archive-keyring.gpg\n</code></pre> <p>Ezut\u00e1n k\u00f6vetkezik a t\u00e1rol\u00f3 hozz\u00e1ad\u00e1sa a forr\u00e1slist\u00e1hoz.</p> <pre><code>echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/ros-archive-keyring.gpg] http://packages.ros.org/ros2/ubuntu $(. /etc/os-release &amp;&amp; echo $UBUNTU_CODENAME) main\" | sudo tee /etc/apt/sources.list.d/ros2.list &gt; /dev/null\n</code></pre>"},{"location":"telepites/ros_humble/#ros-2-csomagok-telepitese","title":"ROS 2 csomagok telep\u00edt\u00e9se","text":"<p>Friss\u00edt\u00e9s:</p> <pre><code>sudo apt update\n</code></pre> <p>A ROS 2 csomagok gyakran friss\u00edtett Ubuntu rendszerekre \u00e9p\u00fclnek. Mindig aj\u00e1nlott, hogy \u00faj csomagok telep\u00edt\u00e9se el\u0151tt meggy\u0151z\u0151dni arr\u00f3l, hogy rendszere naprak\u00e9sz-e. <pre><code>sudo apt upgrade\n</code></pre></p> <p>Desktop telep\u00edt\u00e9s: ROS, RViz, dem\u00f3k, oktat\u00f3anyagok telep\u00edt\u00e9se: <pre><code>sudo apt install ros-humble-desktop\n</code></pre></p> <p>Fejleszt\u0151eszk\u00f6z\u00f6k, ford\u00edt\u00f3k \u00e9s egy\u00e9b eszk\u00f6z\u00f6k ROS-csomagok k\u00e9sz\u00edt\u00e9s\u00e9hez:  <pre><code>sudo apt install ros-dev-tools\n</code></pre></p>"},{"location":"telepites/ros_humble/#source","title":"Source","text":"<p>\u00c1ll\u00edtsa be k\u00f6rnyezet\u00e9t a k\u00f6vetkez\u0151 f\u00e1jl source-ol\u00e1s\u00e1val:</p> <pre><code>source /opt/ros/humble/setup.bash\n</code></pre> <p>Tipp: ezt meg lehet tenni a <code>.bashrc</code> f\u00e1jlban is <code>echo \"source /opt/ros/humble/setup.bash\" &gt;&gt; ~/.bashrc</code>.</p>"},{"location":"telepites/ros_humble/#telepites-ellenorzese","title":"Telep\u00edt\u00e9s ellen\u0151rz\u00e9se","text":"<p>Ellen\u0151rizz\u00fck a telep\u00edt\u00e9s helyess\u00e9g\u00e9t, a <code>ros2 topic list</code> paranccsal. </p> <pre><code>$ ros2 topic list\n\n/parameter_events\n/rosout \n</code></pre> <p>Ha minden rendben, akkor a fenti k\u00e9t topicnak kell megjelennie. Ezut\u00e1n lehet megismerni az egyszer\u0171 p\u00e9lda node-ok haszn\u00e1lat\u00e1t: docs.ros.org/en/humble/Tutorials/Beginner-CLI-Tools.html</p>"},{"location":"telepites/ros_humble/#telepites-utani-ajanlott-beallitasok","title":"Telep\u00edt\u00e9s ut\u00e1ni aj\u00e1nlott be\u00e1ll\u00edt\u00e1sok","text":""},{"location":"telepites/ros_humble/#konzol-szinek","title":"Konzol sz\u00ednek","text":"<p>Alap\u00e9rtelmez\u00e9s szerint a konzol kimenet nem sz\u00ednezett, de ezt c\u00e9lszer\u0171 be\u00e1ll\u00edtani az <code>RCUTILS_COLORIZED_OUTPUT</code> k\u00f6rnyezeti v\u00e1ltoz\u00f3val (ak\u00e1r <code>bashrc</code>-be \u00edrva). P\u00e9ld\u00e1ul:</p> <pre><code>export RCUTILS_COLORIZED_OUTPUT=1 \n</code></pre> <p></p> <p>R\u00e9szletek: docs.ros.org/en/humble/Tutorials/Demos/Logging-and-logger-configuration.html#id14</p>"},{"location":"telepites/ros_humble/#colcon_cd","title":"<code>colcon_cd</code>","text":"<p>Szint\u00e9n c\u00e9lszer\u0171 be\u00e1ll\u00edtani a <code>colcon_cd</code> paranccsot, \u00edgy gyorsan v\u00e1lthatunk munkak\u00f6nyvt\u00e1r\u00e1t egy csomag k\u00f6nyvt\u00e1r\u00e1ra. P\u00e9ldak\u00e9nt a <code>colcon_cd some_ros_package</code> parancsra gyorsan a <code>~/ros2_ws/src/some_ros_package</code> k\u00f6nyvt\u00e1rba ugorhatunk.</p> <p>R\u00e9szletek: docs.ros.org/en/humble/Tutorials/Beginner-Client-Libraries/Colcon-Tutorial.html#setup-colcon-cd</p>"},{"location":"telepites/ros_humble/#otthoni-geptermi-telepites","title":"Otthoni / g\u00e9ptermi telep\u00edt\u00e9s","text":"<p>G\u00e9pteremben a k\u00f6vetkez\u0151 <code>install_humble.sh</code> f\u00e1jlt (shell scriptet) futtatuk minden g\u00e9pen.</p> <p><pre><code>wget https://raw.githubusercontent.com/sze-info/arj/main/docs/telepites/install_humble.sh\n</code></pre> <pre><code>sudo chmod +x install_humble.sh\n</code></pre></p> <p>Otthon: <pre><code>./install_humble.sh\n</code></pre> G\u00e9pteremben: <pre><code>./install_humble.sh campus\n</code></pre></p>"},{"location":"telepites/ros_humble/#workspace-reset","title":"Workspace reset","text":"<p>Ha szeretn\u00e9nk a teljes <code>ros2_ws</code>-t t\u00f6r\u00f6lni, majd \u00fajra kl\u00f3nozni \u00e9s buildelni (~5 percig eltart), akkor a k\u00f6vetkez\u0151 egyetlen hosz\u00fa paranccsal megtehetj\u00fck:</p> <pre><code>cd ~ ; rm ws_reset.sh; wget https://raw.githubusercontent.com/sze-info/arj/main/docs/telepites/ws_reset.sh; sudo chmod +x ws_reset.sh; ./ws_reset.sh\n</code></pre>"},{"location":"telepites/ubuntu/","title":"Ubuntu dual boot","text":""},{"location":"telepites/win10/","title":"Windows WSL2","text":"<p>A Windows Subsystem for Linux egy kompatibilit\u00e1si r\u00e9teg Linux-alap\u00fa elemek nat\u00edv futtat\u00e1s\u00e1hoz Windows 10, vagy Windows 11 alap\u00fa rendszereken. Akkor \u00e9rdemes v\u00e1lasztani a WSL haszn\u00e1lat\u00e1t, ha nem szeretn\u00e9tek nat\u00edv Ubuntu-t (pl 18.04 / 22.04) telep\u00edteni a sz\u00e1m\u00edt\u00f3g\u00e9peitekre.</p> <p>A WSL telep\u00edt\u00e9s\u00e9t bemutat\u00f3 Windows 11-es vide\u00f3 (Windows 10 lejjebb, de nagyr\u00e9szt ugyanez):</p> <p>A vide\u00f3 l\u00e9p\u00e9sei sz\u00f6vegesen:</p> <ul> <li>Rendszergazdak\u00e9nt futtatva nyissatok egy PowerShell ablakot.</li> <li>M\u00e1solj\u00e1tok be az al\u00e1bbi parancsot. Ezzel enged\u00e9lyezitek a WSL haszn\u00e1lat\u00e1t. <pre><code>Enable-WindowsOptionalFeature -Online -FeatureName Microsoft-Windows-Subsystem-Linux\n</code></pre></li> <li>Ind\u00edts\u00e1tok \u00fajra a sz\u00e1m\u00edt\u00f3g\u00e9pet az <code>Y</code> bet\u0171 be\u00edr\u00e1s\u00e1val. (opcion\u00e1lis)</li> <li>Nyiss\u00e1tok meg a Microsoft Store-t, \u00e9s keressetek r\u00e1 a Windows Subsystem for Linux Preview-ra. Telep\u00edts\u00e9tek.</li> <li>Szint\u00e9n a Microsoft Store-ban keressetek r\u00e1 az Ubuntu 22.04-re, \u00e9s telep\u00edts\u00e9tek, vagy PowerShell (Admin): <pre><code>wsl --install -d Ubuntu-22.04\n</code></pre></li> <li>A k\u00f6nnyebb kezelhet\u0151s\u00e9g \u00e9rdek\u00e9ben \u00e9rdemes telep\u00edteni a Windows Terminal programot is. Szint\u00e9n a Microsoft Store-ban keressetek r\u00e1 a Windows Terminal-ra, \u00e9s telep\u00edts\u00e9tek.</li> <li>Ind\u00edts\u00e1tok el a Windows Terminal programot, \u00e9s a Ctrl+, (Control \u00e9s vessz\u0151) billenty\u0171kombin\u00e1ci\u00f3val nyiss\u00e1tok meg a be\u00e1ll\u00edt\u00e1sokat. A Default Profile be\u00e1ll\u00edt\u00e1si sor leg\u00f6rd\u00fcl\u0151 list\u00e1j\u00e1b\u00f3l v\u00e1lassz\u00e1tok az Ubuntu 22.04-et. </li> <li>Ind\u00edts\u00e1tok \u00fajra a Windows Terminal-t. Az els\u0151 indul\u00e1skor adjatok meg tetsz\u0151leges felhaszn\u00e1l\u00f3nevet \u00e9s jelsz\u00f3t. </li> <li>A megold\u00e1s kidolgoz\u00e1s\u00e1hoz a VS Code szerkeszt\u0151t javasoljuk. Telep\u00edts\u00e9tek innen: code.visualstudio.com/download</li> <li>V\u00e9g\u00fcl telep\u00edts\u00e9tek a VS Code Remote Development kieg\u00e9sz\u00edt\u0151j\u00e9t, hogy WSL haszn\u00e1lat\u00e1val is el\u00e9rhet\u0151 legyen: marketplace.visualstudio.com/items?itemName=ms-vscode-remote.vscode-remote-extensionpack</li> </ul> <p>A WSL telep\u00edt\u00e9s\u00e9t bemutat\u00f3 Windows 10-es vide\u00f3 itt \u00e9rhet\u0151 el: </p> <p>A VS Code telep\u00edt\u00e9s\u00e9hez itt tal\u00e1ltok \u00fatmutat\u00f3t: </p>"},{"location":"transformations/","title":"Introduction","text":"<p>In ROS (and generally in robotics), transforms determine where things are located relative to a given reference point (frame). Multiple transforms can describe, for example, the movement of a robotic arm or the position of a vehicle and its sensors in space.</p>"},{"location":"transformations/#rigid-body-motion","title":"Rigid Body Motion","text":"<p>A body is considered rigid if the distances between its points do not change during motion, meaning the distance between any two points remains constant over time.</p> <ul> <li>The shape and volume of a rigid body are constant.</li> <li>The spatial position of a rigid body can be specified by the positions of any 3 non-collinear points.</li> <li>The position of the body can be more intuitively specified by the 3 coordinates of an arbitrary point (position) and the orientation of the body.</li> <li>The motions of rigid bodies consist of two elementary types of motion: translational motion (translation) and rotation around an axis (rotation)<ul> <li>During translational motion, every point of the body follows parallel, congruent paths, and the orientation of the body does not change.</li> <li>During rotation, the positions of the points on the rotation axis do not change, while the other points of the body move in circular paths in planes perpendicular to the rotation axis.</li> </ul> </li> </ul> <p></p> <p>Illustration of rotation Source: University of Illinois</p> <p>Below is a short (~9 minutes) but useful video on the topic:</p>"},{"location":"transformations/#transformations","title":"Transformations","text":"<p>A pose is the combination of position (location) and orientation (direction). When a spatial pose is transformed (moved and rotated), another pose is created. These two poses are relative to each other in two transformation frames. Such transformation frames describe the entire robotic system.</p> <ul> <li>Position: 3-element offset vector (<code>x</code>, <code>y</code>, and <code>z</code> in 3D).</li> <li>Orientation: several representations can be used:<ul> <li>4-element quaternion (more on this later)</li> <li>3-element Euler angles: roll (\u03c8), pitch (\u03b8), yaw (\u03c6) wolfram alpha</li> <li>3 x 3 rotation matrix</li> </ul> </li> </ul> <p>For example, the following important frames can be found relative to the <code>base_link</code> frame of a Nissan Leaf:</p> <p> Frames on the vehicle</p> <p>In vehicle and mobile robot environments, we often want to adhere to the convention that the global map is called the <code>map</code> frame, and the rear axle of the vehicle/robot is called the <code>base_link</code>. The correspondence between the <code>map</code> and the <code>base_link</code> can be established using GPS, NDT matching, Kalman filter, odometry, and many other methods. This is illustrated in the following example:</p> <pre><code>graph TD\n        %% Define first column\n                direction TB\n                map1([  /map]):::light\n                gps([ /gps]):::light\n                base_link1([ /base_link]):::light\n                velodyne_left([ /velodyne_left]):::light\n                zed_front([ /zed_front]):::light\n                laser([ /laser]):::light\n\n                %% Connections for the first column\n                map1 -.-&gt;|dynamic| gps\n                gps --&gt;|static| base_link1\n                base_link1 --&gt;|static| velodyne_left\n                base_link1 --&gt;|static| zed_front\n                base_link1 --&gt;|static| laser\n\n        %% Define second column\n                direction TB\n                map2([ /map]):::light\n                ndt_map([ ndt_map]):::light\n                base_link2([ base_link]):::light\n                sensor_a([ sensor_a]):::light\n                sensor_b([ sensor_b]):::light\n\n                %% Additional sensors can be represented by dots\n                dots2([ ...]):::light\n\n                %% Connections for the second column\n                map2 -.-&gt;|dynamic| ndt_map\n                ndt_map --&gt; base_link2\n                base_link2 --&gt; sensor_a\n                base_link2 --&gt; sensor_b\n                base_link2 --&gt; dots2\n\n        %% Define third column\n                direction TB\n                map3([ lexus3/map]):::light\n                kalman_f([ lexus3/kalman_f]):::light\n                base_link3([ lexus3/base_link]):::light\n\n                %% Representing additional connections with dots\n                dots3a([ lexus3/...]):::light\n                dots3b([ lexus3/...]):::light\n                dots3c([ lexus3/...]):::light\n                dots3d([ lexus3/...]):::light\n\n                %% Connections for the third column\n                map3 -.-&gt;|dynamic| kalman_f\n                kalman_f --&gt; base_link3\n                base_link3 --&gt; dots3a\n                base_link3 --&gt; dots3b\n                base_link3 --&gt; dots3c\n                dots3c --&gt; dots3d\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre> <p> Example TF tree</p> <p>When using GPS, the frames can be roughly imagined based on the following example. The <code>map</code> is the global map, but we also know the position of the <code>gps</code> relative to it. (Note: In the <code>2020.A</code> sensor setup, there are 2 GPS units located in different places, measuring in parallel, but only one transform can determine the position of the <code>base_link</code>. This is indicated by the dashed arrows in Figure 1.) From here, a further (static) transformation can be obtained for the <code>base_link</code> (the rear axle). Additional static transformations can be obtained for the sensors, as shown in the example with the <code>left_os1/os1_sensor</code>.</p> <p> The TF tree in a 2D coordinate system, visual example</p> <p>Transforms are advertised on the <code>tf</code> topic, but for example, the MPC controller uses a topic called <code>current_pose</code> for control implementation. We solved this by advertising the <code>base_link</code> frame values as the <code>current_pose</code> topic. The translation of the frame is the position of the topic, and the rotation of the frame is the orientation of the topic.</p> <p>For large transforms, the RVIZ viewer does not work accurately (https://github.com/ros-visualization/rviz/issues/502). Since ROS uses SI units, including meters, it is advisable to use the UTM (wikipedia-utm) coordinate system for GPS. This naturally involves large coordinate values. To resolve this contradiction, it is advisable to display smaller transforms. For example, a fixed static transform can be advertised for Gy\u0151r (<code>map_gyor_0</code>) and Zala (<code>map_zala_0</code>), relative to which the RVIZ viewer works well. The following diagram illustrates this and shows a slightly more detailed sensor system.</p> <pre><code>graph TB\n        %% Define main components\n        map([ map]):::red\n        map_gyor_0([ map_gyor_0]):::dark\n        map_zala_0([ map_zala_0]):::dark\n        gps([ gps]):::light\n        base_link([ base_link]):::red\n\n        %% Define sensors and other components\n        velodyne_left([ velodyne_left]):::light\n        velodyne_right([ velodyne_right]):::light\n        laser([ laser]):::light\n        zed_camera_front([ zed_camera_front]):::light\n        duro_gps_imu([ duro_gps_imu]):::light\n\n        %% OS1 sensors and their subcomponents\n        left_os1_sensor([ left_os1/os1_sensor]):::light\n        left_os1_lidar([ left_os1/os1_lidar]):::light\n        left_os1_imu([ left_os1/os1_imu]):::light\n\n        right_os1_sensor([ right_os1/os1_sensor]):::light\n        right_os1_lidar([ ...]):::light\n        right_os1_imu([ ...]):::light\n\n        %% Connections among main components\n        map --&gt; map_gyor_0\n        map --&gt; map_zala_0\n        map ---&gt; gps\n        gps --&gt; base_link\n\n        %% Connections from base_link to sensors\n        base_link ---&gt; velodyne_left\n        base_link ---&gt; velodyne_right\n        base_link ---&gt; laser\n        base_link --&gt; zed_camera_front\n        base_link --&gt; duro_gps_imu\n        base_link ----&gt; left_os1_sensor\n        base_link ----&gt; right_os1_sensor\n\n        %% Connections for OS1 sensors\n        left_os1_sensor --&gt; left_os1_lidar\n        left_os1_sensor --&gt; left_os1_imu\n\n        right_os1_sensor --&gt; right_os1_lidar\n        right_os1_sensor --&gt; right_os1_imu\n\nclassDef light fill:#34aec5,stroke:#152742,stroke-width:2px,color:#152742  \nclassDef dark fill:#152742,stroke:#34aec5,stroke-width:2px,color:#34aec5\nclassDef white fill:#ffffff,stroke:#152742,stroke-width:2px,color:#152742\nclassDef red fill:#ef4638,stroke:#152742,stroke-width:2px,color:#fff</code></pre> <p> TF tree displayed by <code>rqt_tf_tree</code></p> <p>In the diagram, only the <code>map</code> <code>gps</code> transform is variable, the others are static. To advertise a static transform in a launch file, for example, between <code>/base_link</code> and <code>left_os1/os1_sensor</code>, it can be done as follows (see Figure 3):</p> ROS 2ROS 1 <pre><code>``` py linenums=\"0\"\nNode(\n        package='tf2_ros',\n        executable='static_transform_publisher',\n        name='ouster_left_tf_publisher',\n        output='screen',\n        arguments=[\n                '--x',  '1.769',\n                '--y',  '0.58',\n                '--z',  '1.278',\n                '--roll', '3.1415926535', # or use math.pi\n                '--pitch', '0.0',\n                '--yaw', '0.0',\n                '--frame-id',      '/base_link',\n                '--child-frame-id','left_os1/os1_sensor'\n        ],\n),\n```\n</code></pre> <pre><code>``` xml linenums=\"0\"\n&lt;node \n    args=\"1.769 0.58 1.278 3.1415926535 0.0 0.0 /base_link left_os1/os1_sensor 50\"\n    name=\"ouster_left_tf_publisher\" \n    pkg=\"tf\" \n    type=\"static_transform_publisher\"\n/&gt; \n```\n</code></pre> <p>The same commands issued from the terminal:</p> ROS 2ROS 1 <pre><code>``` py linenums=\"0\"\nros2 run tf2_ros static_transform_publisher \\\n--x 1.769 --y 0.58 --z 1.278 \\\n--roll 0.0 --pitch 0.0 --yaw 3.1415926535 \\\n--frame-id left_os1/os1_sensor --child-frame-id base_link\n```\n</code></pre> <pre><code>``` c++ linenums=\"0\"\nrosrun tf static_transform_publisher \\\n1.769 0.58 1.278 \\\n3.1415926535 0.0 0.0 \\\n/base_link left_os1/os1_sensor 50  \n```\n</code></pre> <p>In <code>ROS 1</code>, the last argument is 50 ms, meaning it advertised the same transformation at 20 Hz. This is not ideal; <code>ROS 2</code> has improved in this regard, where it is sufficient to advertise the same transformation once.</p> <p>Example of a static transform launch file: tf_static.launch</p>"},{"location":"transformations/#matrix-multiplication","title":"Matrix Multiplication","text":"<p>3D transformations (and 2D as well) can be described using a matrix, specifically matrix multiplication. For example, if we move an object a certain distance, it can be described using a rotation matrix. The rotation matrix in 3 dimensions is a 3x3 matrix that specifies the direction and magnitude of the rotation.</p> <p>Source: Robotic Systems, University of Illinois</p> <p>matrixmultiplication.xyz</p> <p>Python notebook</p> <p>Danger</p> <pre><code>The Python notebook and matrix multiplication visualization are linked for educational purposes. In ROS 2, the `tf2` and related solutions provide many functions, so there is no need to manually write translations and rotations. Transformations can be queried between 2 frames without knowing exactly how many frames they are connected through. ROS 2 conveniently provides this. [Read more about it here](https://docs.ros.org/en/humble/Tutorials/Intermediate/Tf2/Tf2-Main.html)\n</code></pre>"},{"location":"transformations/#homogeneous-coordinates","title":"Homogeneous Coordinates","text":"<p>Homogeneous coordinates provide a convenient representation for rigid body transformations as an extension of linear transformations in space. They compactly represent the difference between position-dependent and direction-dependent quantities. The idea is to augment each point with an additional homogeneous coordinate, which is 1 if position-dependent and 0 if direction-dependent. This operation is denoted by the \"hat\" operator (<code>^</code>).</p>"},{"location":"transformations/#quaternion","title":"Quaternion","text":"<p>An alternative to roll, pitch, yaw (Euler angles), with an extension similar to complex numbers.</p> <p>Demonstration: www.quaternions.online</p> <p>Advantages: - Numerical Stability: Small numerical errors from floating-point representation can accumulate into significant errors with repeated Euler angle rotations. For example, a rotation with a few hundredths of a degree inaccuracy can accumulate into a significant error with thousands or tens of thousands of repetitions. Quaternions have much smaller errors due to their complex representation and normalized form. - Fast Computation: Quaternions efficiently represent 3D spatial rotations and can often be faster and more stable than other representation methods, such as Euler angles. - Accuracy: - Not Sensitive to \"Gimbal Lock\": With Euler angles, there can be a situation where rotations become sensitive in certain directions, limiting the accuracy of calculations. Quaternions avoid this problem. - Easily Interpolated: Quaternions allow easy interpolation between two rotations, which is important for maintaining smooth animations. They can also be used for non-linear interpolations. Quaternions enable non-linear interpolations, useful for creating animations where rotation changes non-linearly over time.</p> <p>Disadvantage: - Not Intuitive for Humans: They are harder to understand compared to Euler angles, which we are accustomed to for rotation around 3 axes.</p> \\[tan(\\frac{\\pi}{2}) = \\infty \\] <p>In <code>ROS 2</code>, for example, roll, pitch, yaw values can be converted to quaternion as follows:</p> <pre><code>#include &lt;tf2_geometry_msgs/tf2_geometry_msgs.hpp&gt;\ntf2::Quaternion tf2_quat;\ntf2_quat.setRPY(roll, pitch, yaw);\n</code></pre> <p>More information on this can be found here.</p>"},{"location":"transformations/#conventions","title":"Conventions","text":""},{"location":"transformations/#coordinate-systems-gpsgnss","title":"Coordinate Systems (GPS/GNSS)","text":"<p>The <code>WGS84</code> or World Geodetic System 1984 is a global reference system used in cartography, geolocation, navigation, and the GPS (Global Positioning System) system. It is a standard coordinate system used to specify geographic latitude, longitude, and altitude above sea level. Latitude circles run horizontally and specify a point's location on the Earth's surface in degrees north or south of the equator (0 degrees latitude). Longitude circles run vertically and specify a point's location on the Earth's surface in degrees east or west of the prime meridian (0 degrees longitude). The prime meridian is located at 0 degrees longitude and passes through Greenwich, London. Longitude values range from -180 degrees to +180 degrees, with the 180-degree line connecting the Eastern and Western Hemispheres. The measurement data file's navsatfix topic (sensor_msgs/msg/NavSatFix) is saved in this format.</p> <p>An alternative to this is the <code>UTM</code> projection system, which uses meters instead of degrees. The <code>UTM</code>, or Universal Transverse Mercator, is a map projection system used for map-making and navigation. Different zones of the world are represented on a series of specialized cylindrical maps where longitude and latitude lines are straight. As shown below, Hungary falls into 4 <code>UTM</code> zones: <code>33U</code>, <code>34U</code>, <code>33T</code>, and <code>34T</code>. The UTM zones are divided into 6-degree wide longitudinal strips, where each strip is represented on a transverse Mercator projection-based cylindrical map. The advantage of the UTM system is that it provides a simple coordinate system with minimal distortion within the zones. Therefore, it is often used in military maps, topographic maps, navigation systems, and other mapping applications. For example, in measurement data, the topic typically ending with current_pose (<code>geometry_msgs/msg/PoseStamped</code>) receives data in this format.</p> <p></p>"},{"location":"transformations/#sources","title":"Sources","text":"<ul> <li>articulatedrobotics.xyz/ready-for-ros-6-tf</li> <li>Kris Hauser: Robotic Systems University of Illinois at Urbana-Champaign</li> <li>\u00d3budai Egyetem ABC-iRobotics</li> <li>docs.ros.org/en/humble/Tutorials/Intermediate/Tf2/Tf2-Main.html</li> <li>docs.ros.org/en/humble/Tutorials/Intermediate/Tf2/Quaternion-Fundamentals.html</li> <li>mathworld.wolfram.com/EulerAngles.html</li> </ul>"},{"location":"transformations/practice/","title":"Practice","text":"<p>The following practice illustrates handling transformations in ROS2 using C++.</p> <p>Python Equivalent</p> <p>The Python version of the C++ code is also available at github.com/sze-info/arj_packages. It is worth comparing the C++ and Python codes.</p> <p>Let's update the <code>arj_packages</code> repo to the latest version. If it updates or you get the <code>Already up to date.</code> message, you don't need to clone it. If you get the <code>~/ros2_ws/src/arj_packages: No such file or directory</code> message after running <code>cd ~/ros2_ws/src/arj_packages</code>, then clone the repo.</p> <p><pre><code>cd ~/ros2_ws/src/arj_packages\n</code></pre> <pre><code>git pull\n</code></pre></p> <p>If you get the <code>No such file or directory</code> message, clone it with the following commands:</p> <p>Warning</p> <p>The following two commands are only needed if <code>arj_packages</code> does not exist:</p> <p><pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/sze-info/arj_packages\n</code></pre></p> <p>If it already exists, just update it instead of the previous step.</p> <p><pre><code>cd ~/ros2_ws/src/arj_packages/\n</code></pre> <pre><code>git status\n</code></pre> The <code>git checkout -- .</code>: Discards all unstaged changes locally. In VS Code, this is similar to the \"discard all changes\" command. <pre><code>git checkout -- .\n</code></pre> <pre><code>git pull\n</code></pre></p> <p>After that, you can build:</p> <p><pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --packages-select arj_transforms_cpp\n</code></pre></p> <p>It is advisable to source in a new terminal and then run:</p> <p><pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 run arj_transforms_cpp pub_transforms\n</code></pre></p> <p>Let's examine the raw output:</p> <pre><code>ros2 topic echo /tf\n</code></pre> <p>The response will be similar to this:</p> <pre><code>transforms:\n- header:\n    stamp:\n      sec: 1693475112\n      nanosec: 95339579\n    frame_id: orbit1\n  child_frame_id: orbit2\n  transform:\n    translation:\n      x: -2.487199068069458\n      y: 0.25266680121421814\n      z: 0.0\n    rotation:\n      x: 0.0\n      y: 0.0\n      z: 0.0\n      w: 1.0\n---\ntransforms:\n- header:\n    stamp:\n      sec: 1693475112\n      nanosec: 145005518\n    frame_id: map\n  child_frame_id: orbit1\n  transform:\n    translation:\n      x: -4.109088897705078\n      y: 2.8487515449523926\n      z: 0.0\n    rotation:\n      x: 0.0\n      y: 0.0\n      z: -0.46381551598382736\n      w: 0.8859318072699817\n</code></pre> <p>As we can see, the <code>map</code> frame's <code>child_frame_id</code> is <code>orbit1</code>. The <code>orbit1</code> frame's <code>child_frame_id</code> is <code>orbit2</code>. So, if we consider <code>map</code> as the grandparent, then <code>orbit2</code> is the grandchild. It is more illustrative to examine this using <code>rqt_tf_tree</code>.</p> <pre><code>ros2 run rqt_tf_tree rqt_tf_tree\n</code></pre> <p></p> <p>If the above command does not work, it can be installed with <code>sudo apt install ros-humble-rqt-tf-tree</code>. This should not be necessary on lab computers.</p> <p>Let's look at it using RVIZ2, it will look like this:</p> <pre><code>ros2 launch arj_transforms_cpp rviz1.launch.py\n</code></pre> <p></p> <p>Let's examine the <code>pub_transforms.cpp</code> file. (For Python, the <code>transforms.py</code> file in the <code>_py</code> package.)</p> <pre><code>cd ~/ros2_ws/src/arj_packages/arj_transforms_cpp\n</code></pre> <pre><code>code .\n</code></pre> <p>The most interesting part now is probably the <code>loop</code> function. According to the Pythagorean theorem, <code>tr1.transform.translation.x</code> and <code>y</code> will always lie on a circle due to the sine and cosine trigonometric functions. The <code>loop_count_</code> variable continuously increases, so it makes the circle in the direction of the clock hands according to the <code>speed1</code> value, which can be accelerated using <code>rqt_reconfigure</code> (we will look at this later). The size of the circle, the distance from the origin, can be increased using <code>distance1</code>. A similar situation applies to <code>tr2.transform</code>, which gives the <code>orbit1</code> -&gt; <code>orbit2</code> transform. The <code>tr1.transform</code> also represents an additional rotation using a quaternion. We only rotate around the Z-axis from the roll, pitch, yaw values.</p> <pre><code>void loop()\n{\n    // Publish transforms\n    tr1.header.stamp = this-&gt;get_clock()-&gt;now();\n    tr1.header.frame_id = \"map\";\n    tr1.child_frame_id = \"orbit1\";\n    tr1.transform.translation.x = sin(loop_count_ * speed1) * distance1;\n    tr1.transform.translation.y = cos(loop_count_ * speed1) * distance1;\n    tf2::Quaternion quaternion1;\n    quaternion1.setRPY(0.0, 0.0, loop_count_ * speed1);\n    quaternion1=quaternion1.normalize();\n    tr1.transform.rotation.x = quaternion1.x();\n    tr1.transform.rotation.y = quaternion1.y();\n    tr1.transform.rotation.z = quaternion1.z();\n    tr1.transform.rotation.w = quaternion1.w();\n    tf_broadcaster_-&gt;sendTransform(tr1);\n    tr2.header.stamp = this-&gt;get_clock()-&gt;now();\n    tr2.header.frame_id = \"orbit1\";\n    tr2.child_frame_id = \"orbit2\";\n    tr2.transform.translation.x = sin(loop_count_ * speed2) * distance2;\n    tr2.transform.translation.y = cos(loop_count_ * speed2) * distance2;\n    tf_broadcaster_-&gt;sendTransform(tr2);\n    loop_count_++;\n}\n</code></pre> <p>Let's add <code>orbit3</code> with a static transform:</p> <pre><code>ros2 run tf2_ros static_transform_publisher --x 1.0 --y 0.2 --z 1.4 --qx 0.0 --qy 0.0 --qz 0.0 --qw 1.0 --frame-id orbit2 --child-frame-id orbit3\n</code></pre> <p>Set the speeds and distances:</p> <pre><code>ros2 run rqt_reconfigure rqt_reconfigure\n</code></pre> <p></p> <p>Advertise a marker and add it in RVIZ2. This command advertises a green cube on <code>orbit2</code>:</p> <pre><code>ros2 topic pub --rate 40 --print 40 /marker_topic2 visualization_msgs/msg/Marker '{header: {frame_id: \"orbit2\"}, ns: \"markers2\", id: 2, type: 1, action: 0, pose: {position: {x: 0.0, y: 0.0, z: 0.0}, orientation: {x: 0.0, y: 0.0, z: 0.0, w: 1.0}}, scale: {x: 1.0, y: 1.0, z: 1.0}, color: {r: 0.2, g: 0.4, b: 0.3, a: 1.0}}'\n</code></pre> <p>This command advertises a red arrow on <code>orbit1</code>:</p> <pre><code>ros2 topic pub --rate 40 --print 40 /marker_topic3 visualization_msgs/msg/Marker '{header: {frame_id: \"orbit1\"}, ns: \"markers3\", id: 3, type: 0, action: 0, pose: {position: {x: 0.0, y: 0.0, z: 0.0}, orientation: {x: 0.0, y: 0.0, z: 0.0, w: 1.0}}, scale: {x: 1.8, y: 0.4, z: 0.4}, color: {r: 0.8, g: 0.2, b: 0.2, a: 1.0}}'\n</code></pre> <p>The <code>Marker</code> message's <code>type</code> attribute specifies whether the marker is, for example, <code>ARROW=0</code> or <code>CUBE=1</code>:</p> <pre><code>ros2 interface show  visualization_msgs/msg/Marker\n\n...\ntype:\nint32 ARROW=0\nint32 CUBE=1\nint32 SPHERE=2\nint32 CYLINDER=3\nint32 LINE_STRIP=4\nint32 LINE_LIST=5\nint32 CUBE_LIST=6\nint32 SPHERE_LIST=7\nint32 POINTS=8\nint32 TEXT_VIEW_FACING=9\nint32 MESH_RESOURCE=10\nint32 TRIANGLE_LIST=11\n\n...\n</code></pre> <p>For more color examples, see below. For more on colors: github.com/jkk-research/colors.</p> . . .  0.96 0.26 0.21   0.53 0.05 0.31   0.19 0.11 0.57   0.73 0.87 0.98   0.13 0.59 0.95    0.00 0.59 0.53    0.78 0.90 0.79   0.30 0.69 0.31    0.80 0.86 0.22    1.00 0.93 0.70   1.00 0.76 0.03    1.00 0.44 0.00   0.84 0.80 0.78   0.47 0.33 0.28    0.24 0.15 0.14   0.96 0.96 0.96   0.62 0.62 0.62    0.13 0.13 0.13"},{"location":"transformations/practice/#independent-task","title":"Independent Task","text":"<p>As an independent task, create a package named <code>my_launch_pkg</code>, in which a <code>run_transforms_and_markers.launch.py</code> starts:</p> <ul> <li>the node that publishes the <code>map</code>, <code>orbit1</code>, and <code>orbit2</code> frames (<code>ros2 run arj_transforms_cpp pub_transforms</code>)</li> <li>the <code>rqt_reconfigure</code> (<code>ros2 run rqt_reconfigure rqt_reconfigure</code>)</li> <li>the static <code>orbit3</code> frame (<code>ros2 run tf2_ros static_transform_publisher --x 1.0 --y 0.2 --z 1.4 --qx 0.0 --qy 0.0 --qz 0.0 --qw 1.0 --frame-id orbit2 --child-frame-id orbit3</code>)</li> <li>and the launch that starts Rviz2 (<code>ros2 launch arj_transforms_cpp rviz1.launch.py</code>)</li> </ul> <p>Check the correct operation in rviz2.</p> <p>So, at the end of the independent task, it should be startable with the following command:</p> <pre><code>ros2 launch my_launch_pkg run_transforms_and_markers.launch.py\n</code></pre> <p>Solution: available among the independent tasks</p>"},{"location":"transformations/practice/#help-for-the-independent-task","title":"Help for the Independent Task","text":"<p>The <code>ros2 run tf2_ros static_transform_publisher --x 1.0 --y 0.2 --z 1.4 --qx 0.0 --qy 0.0 --qz 0.0 --qw 1.0 --frame-id orbit2 --child-frame-id orbit3</code> can be easily assembled based on previous lessons:</p> <pre><code>Node(\n    package='tf2_ros',\n    executable='static_transform_publisher',\n    arguments=['1.0', '0.2', '1.4','0', '0', '0', '1', 'orbit2','orbit3'],\n),     \n</code></pre> <p>Warning</p> <p>We have a harder time with Rviz2, as we need to call a launch file, not a node.</p> <p>The first, but less elegant option is to copy the original launch file and extend it:</p> <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\nimport os\nfrom ament_index_python.packages import get_package_share_directory\n\ndef generate_launch_description():\n\n    pkg_name = 'arj_transforms_cpp'\n    pkg_dir = get_package_share_directory(pkg_name)\n\n    return LaunchDescription([\n        Node(\n            package='rviz2',\n            namespace='',\n            executable='rviz2',\n            name='rviz2',\n            arguments=['-d', [os.path.join(pkg_dir, 'rviz', 'rviz1.rviz')]]\n        )\n    ])\n</code></pre> <p>The second, much more elegant option is to include the launch file in the launch file:</p> <pre><code>from launch import LaunchDescription\nfrom launch_ros.actions import Node\nfrom launch.actions import IncludeLaunchDescription\nfrom launch.launch_description_sources import PythonLaunchDescriptionSource\nfrom launch_ros.substitutions import FindPackageShare\n\ndef generate_launch_description():\n    return LaunchDescription([\n        # ros2 launch arj_transforms_cpp rviz1.launch.py\n        IncludeLaunchDescription(\n            PythonLaunchDescriptionSource([\n                FindPackageShare(\"arj_transforms_cpp\"), '/launch/', 'rviz1.launch.py'])\n        ),\n    ])\n</code></pre>"},{"location":"transformations/practice/#further-reading","title":"Further Reading","text":"<p>Python notebook transform</p> <p>Python notebook quaternion</p> <p>gps_utm.ipynb </p> <p></p> <p></p>"},{"location":"transformations/practice/#reading-material","title":"Reading Material","text":"<ul> <li>articulatedrobotics.xyz/ready-for-ros-6-tf</li> </ul>"},{"location":"workshops/f1tenth_real_a/","title":"<code>ROS 2</code> F1/10 hands-on workshop","text":"<ul> <li>A small overview of the <code>Bavarian-Hungarian Self-driving vehicles</code> workshop.</li> <li>Date: 2024.06.08. </li> <li>Place: Gy\u0151r, Hungary.</li> </ul>"},{"location":"workshops/f1tenth_real_a/#a-ros-2-package","title":"A <code>ROS 2</code> package","text":""},{"location":"workshops/f1tenth_real_a/#hands-on","title":"Hands-on","text":"<p><code>ROS 2</code> humble </p>"},{"location":"workshops/f1tenth_sim_a/","title":"<code>ROS 2</code> F1/10 Wheeltec Gazebo simulation workshop","text":"<p>The workshop is ROS 2 compatible </p>"},{"location":"workshops/f1tenth_sim_a/#video","title":"Video","text":""},{"location":"workshops/f1tenth_sim_a/#requirements-high-level","title":"Requirements (high-level)","text":"<ol> <li>ROS 2 Humble: \ud83d\udfe0 see previous workshops or docs.ros.org/en/humble/Installation.html </li> <li>Gazebo Fortress: \u2705 current workshop gazebosim.org/docs/fortress/install_ubuntu</li> <li><code>ROS gz bridge</code>:  \u2705 current workshop, ROS integration. Install with a single command: <code>sudo apt install ros-humble-ros-gz-bridge</code>, gazebosim.org/docs/fortress/ros2_integration</li> <li>Build and run custom worlds and models  \u2705 current workshop (e.g. <code>F1/10</code> / <code>Wheeltec, Roboworks</code>) </li> </ol> Official F1/10 vehicle vs Wheeltec Roboworks Ackermann Rosbot mini vehicle"},{"location":"workshops/f1tenth_sim_a/#binary-installation-on-ubuntu","title":"Binary Installation on Ubuntu","text":"<p>Fortress binaries are provided for Ubuntu Bionic, Focal and Jammy. All of the Fortress binaries are hosted in the osrfoundation repository. To install all of them, the metapackage <code>ignition-fortress</code> can be installed. The following is based on gazebosim.org/docs/fortress/install_ubuntu.</p> <p>First install some necessary tools:</p> <p><pre><code>sudo apt-get update\n</code></pre> <pre><code>sudo apt-get install lsb-release wget gnupg\n</code></pre></p> <p>Then install Ignition Fortress:</p> <p><pre><code>sudo wget https://packages.osrfoundation.org/gazebo.gpg -O /usr/share/keyrings/pkgs-osrf-archive-keyring.gpg\n</code></pre> <pre><code>echo \"deb [arch=$(dpkg --print-architecture) signed-by=/usr/share/keyrings/pkgs-osrf-archive-keyring.gpg] http://packages.osrfoundation.org/gazebo/ubuntu-stable $(lsb_release -cs) main\" | sudo tee /etc/apt/sources.list.d/gazebo-stable.list &gt; /dev/null\n</code></pre> <pre><code>sudo apt-get update\n</code></pre> <pre><code>sudo apt-get install ignition-fortress\n</code></pre></p> <p>All libraries should be ready to use and the <code>ign gazebo</code> app ready to be executed.</p>"},{"location":"workshops/f1tenth_sim_a/#gazebo-fortress-ros-2-integration","title":"Gazebo Fortress ROS 2 integration","text":"<p>Issue the following command:</p> <pre><code>sudo apt install ros-humble-ros-gz-bridge\n</code></pre>"},{"location":"workshops/f1tenth_sim_a/#additional-settings-to-wsl2","title":"Additional settings to WSL2","text":"<p>Warning - WSL2</p> <p>There is an issue, which can be set even in <code>~/.bashrc</code>:</p> <pre><code>export LIBGL_ALWAYS_SOFTWARE=1\n</code></pre> <p>Set it in <code>~/.bashrc</code>: <pre><code>echo \"export LIBGL_ALWAYS_SOFTWARE=1\" &gt;&gt; ~/.bashrc\n</code></pre></p>  Don't forget to source bashrc. <pre><code>source ~/.bashrc\n</code></pre> <p>After new terminal or <code>source</code>:</p> <pre><code>echo $LIBGL_ALWAYS_SOFTWARE\n</code></pre> <p>should  print <code>1</code>. Alternatively </p> <p><pre><code>cat ~/.bashrc | grep LIBGL\n</code></pre> should print the line.</p>"},{"location":"workshops/f1tenth_sim_a/#check-the-installation","title":"Check the installation","text":"<p>Success</p> <p>Now the <code>ign gazebo</code> should work and the <code>ros2</code> commands should be available.</p> <p></p> <p>Try at least one of the following commands:</p> <pre><code>ign gazebo\n</code></pre> <pre><code>ign gazebo -v 4 -r ackermann_steering.sdf\n</code></pre> <pre><code>ign gazebo shapes.sdf\n</code></pre> <p></p> <pre><code>ign param --versions\n</code></pre>"},{"location":"workshops/f1tenth_sim_a/#packages-and-build","title":"Packages and build","text":"<p>Detailed description of the packages and build process.</p> <p>It is assumed that the workspace is <code>~/ros2_ws/</code>.</p> <pre><code>cd ~/ros2_ws/src\n</code></pre> <pre><code>git clone https://github.com/rudolfkrecht/robotverseny\n</code></pre>"},{"location":"workshops/f1tenth_sim_a/#build","title":"Build","text":"<pre><code>cd ~/ros2_ws\n</code></pre> <pre><code>colcon build --symlink-install --packages-select robotverseny_application robotverseny_description robotverseny_bringup robotverseny_gazebo \n</code></pre>"},{"location":"workshops/f1tenth_sim_a/#run","title":"Run","text":"Don't forget to source before ROS commands. <pre><code>source ~/ros2_ws/install/setup.bash\n</code></pre> <pre><code>ros2 launch robotverseny_bringup roboworks.launch.py\n</code></pre>"},{"location":"workshops/f1tenth_sim_a/#useful-commands","title":"Useful commands","text":"<p>Publish command topic: <pre><code>ros2 topic pub --once /roboworks/cmd_vel geometry_msgs/msg/Twist \"{linear: {x: 2.5, y: 0.0, z: 0.0}, angular: {x: 0.0, y: 0.0, z: -0.01}}\"\n</code></pre></p> <p>Teleop twist keyboard: <pre><code>ros2 run teleop_twist_keyboard teleop_twist_keyboard --ros-args -r /cmd_vel:=/roboworks/cmd_vel\n</code></pre></p> <p>Ignition info topic: <pre><code>ign topic -i --topic /model/roboworks/cmd_vel\n</code></pre> Ignition echo topic:</p> <pre><code>ign topic -et /model/roboworks/cmd_vel\n</code></pre> <p>Topics:</p> <pre><code>ros2 topic list\n</code></pre>  Here are the topics. <pre><code>/clicked_point\n/clock\n/goal_pose\n/initialpose\n/joint_states\n/parameter_events\n/robot_description\n/roboworks/cmd_vel\n/roboworks/odometry\n/roboworks/scan\n/rosout\n/tf\n/tf_static\n</code></pre>"},{"location":"workshops/ros2_a/","title":"<code>ROS 2</code> hands-on workshop","text":"<ul> <li>A small overview of the <code>Bavarian-Hungarian Self-driving vehicles</code> workshop.</li> <li>Date: 2024.06.08. </li> <li>Place: Gy\u0151r, Hungary.</li> </ul>"},{"location":"workshops/ros2_a/#a-ros-2-package","title":"A <code>ROS 2</code> package","text":""},{"location":"workshops/wheeltec_real_a/","title":"<code>ROS 1</code> real robot workshop","text":"<ul> <li>A small overview of the <code>Bavarian-Hungarian Self-driving vehicles</code> workshop.</li> <li>Date: 2023.11.03. </li> <li>Place: Gy\u0151r, Hungary.</li> </ul>"},{"location":"workshops/wheeltec_real_a/#the-megoldas_zala23-ros-1-package","title":"The <code>megoldas_zala23</code> ROS 1 package","text":"<p>\ud83e\udd16 In the following a very simple wall/gap following approach will be presented and described. The origin of he code is based on the work of Suresh Babu (University of Virginia, license). Link to the original code: github.com/linklab-uva/f1tenth_gtc_tutorial.</p> <p>The name of the package is a comes from a hungarian expression (<code>megoldas</code>: solution / L\u00f6sung).</p>"},{"location":"workshops/wheeltec_real_a/#the-robot-used-in-the-competition","title":"The robot used in the competition","text":"<p>Wheeltec / Roboworks Rosbot mini Ackermann robot </p> <p>On-board computer - Nvidia Jetson Nano</p> <p>Sensors - Orbbec Depth Camera - LSN10 LIDAR</p>"},{"location":"workshops/wheeltec_real_a/#video","title":"Video","text":""},{"location":"workshops/wheeltec_real_a/#usage","title":"Usage","text":"<p>Prerequisites: - WiFi-enabled computer with Ubuntu 18.04 / 20.04 operating system and ROS Melodic / Noetic installation - Internet access (Ethernet cable or WiFi)</p> <ol> <li>Turn on the robot platform.</li> <li>Use the computer to connect to the WiFi network created by the robot. The name of the WiFi network is unique for each robot platform, the <code>#</code> at the end of the SSID changes according to the number of the robot platform: <pre><code>SSID: WHEELTEC_CAR_5.5_#\nPassword: dongguan\n</code></pre></li> <li>Use SSH to connect to the on-board computer of the robot platform with the following terminal command: <pre><code>ssh wheeltec@192.168.0.100\n</code></pre> A password will be required, the default password is <code>dongguan</code></li> </ol>"},{"location":"workshops/wheeltec_real_a/#internet-access-on-the-robot-platform","title":"Internet access on the robot platform","text":"<p>Software packages can be downloaded to the on-board computer of the robot platform, which requires internet access.</p> <ul> <li>Ethernet: connect the Ethernet cable to the Ethernet port of the on-board computer of the robot platform.</li> <li>WiFi: after issuing the <code>nmtui</code> terminal command, connect to the available WiFi network. <pre><code>nmtui\n</code></pre></li> </ul> <p></p>"},{"location":"workshops/wheeltec_real_a/#install-the-ros-1-package","title":"Install the <code>ROS 1</code> package","text":"<p>After installation, the functions of the robot platform can be accessed using ROS. The sample solution of the competition can also be deployed by ROS.</p> <p>Create a workspace and install the sample solution on the robot:</p> <pre><code>mkdir -p ~/workshop_ws/src\n</code></pre> <pre><code>cd ~/workshop_ws/\n</code></pre> <pre><code>catkin init\n</code></pre> <pre><code>cd ~/workshop_ws/src/\n</code></pre> <pre><code>git clone https://github.com/robotverseny/megoldas_zala23\n</code></pre> <pre><code>cd ~/workshop_ws/\n</code></pre> <pre><code>catkin build megoldas_zala23\n</code></pre> <pre><code>echo \"source /home/wheeltec/workshop_ws/devel/setup.bash\" &gt;&gt; ~/.bashrc\n</code></pre> <pre><code>source ~/.bashrc\n</code></pre> <p>Install <code>screen</code> <pre><code>sudo apt install mc screen\n</code></pre></p> <p>Install jks visualization rviz plugin: depending on ROS 1 version (melodic / noetic):</p> <pre><code>sudo apt install ros-melodic-jsk-rviz-plugins\n</code></pre> <pre><code>sudo apt install ros-noetic-jsk-rviz-plugins\n</code></pre>"},{"location":"workshops/wheeltec_real_a/#usage_1","title":"Usage","text":""},{"location":"workshops/wheeltec_real_a/#start-solution-using-screen-recommended","title":"Start solution using screen (recommended)","text":"<p>The script <code>verseny_start.sh</code> sets the required environmental variables, starts the ROS nodes and finally after 2 minutes stops everything. Have a look at the code: verseny_start.sh </p> <pre><code>rosrun megoldas_zala23 verseny_start.sh\n</code></pre> <p>The <code>verseny_start.sh</code> shell script usually launches several virtual terminals, such as: <code>roscore</code>, <code>turn_on_wheeltec_robot</code>, <code>lsn10_lidar</code>, <code>megoldas1.launch</code>. All components of the solution can be stopped with the following command: <pre><code>rosrun megoldas_zala23 stop_all.sh\n</code></pre></p> <p>Further commands:</p> <ul> <li>list screen: <code>screen -ls</code></li> <li>restore screen: <code>screen -r roscore</code> / <code>screen -r turn_on_wheeltec_robot</code> / <code>screen -r megoldas1</code></li> <li>detach: <code>Ctrl-a</code> + <code>Ctrl-d</code></li> </ul>"},{"location":"workshops/wheeltec_real_a/#ros-connection","title":"ROS connection","text":"<p>The ROS topics advertised by the robot platform are also available on the computer connected to the platform, with the appropriate setting of the <code>ROS_MASTER_URI</code> variable: <pre><code>export ROS_MASTER_URI=http://192.168.0.100:11311\n</code></pre> After the appropriate setting of the variable, the topics can be listed and visualized using Rviz: <pre><code>rostopic list\n</code></pre> <pre><code>rosrun rviz rviz\n</code></pre></p>"},{"location":"workshops/wheeltec_real_a/#some-explanatory-animations","title":"Some explanatory animations","text":"<pre><code>roslaunch megoldas_zala23 rviz1.launch\n</code></pre>"},{"location":"workshops/wheeltec_real_a/#start-solution-per-component","title":"Start solution per component","text":"<p>The solution can also be started per component, not just as a single shell script. This requires four terminal windows on the on-board computer of the robot platform and issuing the following commands per terminal:</p> <pre><code>roscore\n</code></pre> <pre><code>roslaunch turn_on_wheeltec_robot turn_on_wheeltec_robot.launch\n</code></pre> <pre><code>roslaunch lsn10 lsn10.launch\n</code></pre> <pre><code>roslaunch megoldas_zala23 megoldas1.launch\n</code></pre>"},{"location":"workshops/wheeltec_real_a/#additional-information","title":"Additional information","text":""},{"location":"workshops/wheeltec_real_a/#workspaces","title":"Workspaces","text":"<pre><code>~/wheeltec_robot/src\n~/catkin_workspace/src\n~/workshop_ws/src/\n</code></pre>"},{"location":"workshops/wheeltec_real_a/#topic-management","title":"Topic management","text":"<pre><code>rostopic hz /scan\nrostopic echo /scan -n1\nrostopic type /scan\n</code></pre> <pre><code>sensor_msgs/LaserScan\n</code></pre>"},{"location":"workshops/wheeltec_real_a/#robot-platform-language-settings","title":"Robot platform language settings","text":"<pre><code>sudo dpkg-reconfigure locales\n</code></pre> <p>reboot</p>"},{"location":"workshops/wheeltec_real_a/#rosbag-management","title":"Rosbag management","text":"<p><pre><code>cd ~/rosbags\nrosbag record -a -o test1\n</code></pre> <pre><code>rsync -avzh --progress wheeltec@192.168.0.100:/home/wheeltec/rosbags/ /mnt/c/bag/wheeltec/\nrosbag info test1_2023-03-30-12-37-22.bag\nrosbag play test1_2023-03-30-12-37-22.bag\n</code></pre></p> <p>You can even visualize rosbags in Foxglove studio:</p> <p></p> <p>Download rosbags</p> <ul> <li>Further explanation ipynotebook</li> <li>Competition homepage</li> <li>Foxglove studio</li> </ul>"}]}